{"version":3,"sources":["tf-backend-cpu.node.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar tfjsCore = require('@tensorflow/tfjs-core');\nvar seedrandom = require('seedrandom');\n\nfunction _interopNamespace(e) {\n    if (e && e.__esModule) return e;\n    var n = Object.create(null);\n    if (e) {\n        Object.keys(e).forEach(function (k) {\n            if (k !== 'default') {\n                var d = Object.getOwnPropertyDescriptor(e, k);\n                Object.defineProperty(n, k, d.get ? d : {\n                    enumerable: true,\n                    get: function () {\n                        return e[k];\n                    }\n                });\n            }\n        });\n    }\n    n['default'] = e;\n    return n;\n}\n\nvar seedrandom__namespace = /*#__PURE__*/_interopNamespace(seedrandom);\n\n/*! *****************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise */\nvar extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b)\n            if (b.hasOwnProperty(p))\n                d[p] = b[p]; };\n    return extendStatics(d, b);\n};\nfunction __extends(d, b) {\n    extendStatics(d, b);\n    function __() { this.constructor = d; }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\nfunction __awaiter(thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try {\n            step(generator.next(value));\n        }\n        catch (e) {\n            reject(e);\n        } }\n        function rejected(value) { try {\n            step(generator[\"throw\"](value));\n        }\n        catch (e) {\n            reject(e);\n        } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n}\nfunction __generator(thisArg, body) {\n    var _ = { label: 0, sent: function () { if (t[0] & 1)\n            throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f)\n            throw new TypeError(\"Generator is already executing.\");\n        while (_)\n            try {\n                if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done)\n                    return t;\n                if (y = 0, t)\n                    op = [op[0] & 2, t.value];\n                switch (op[0]) {\n                    case 0:\n                    case 1:\n                        t = op;\n                        break;\n                    case 4:\n                        _.label++;\n                        return { value: op[1], done: false };\n                    case 5:\n                        _.label++;\n                        y = op[1];\n                        op = [0];\n                        continue;\n                    case 7:\n                        op = _.ops.pop();\n                        _.trys.pop();\n                        continue;\n                    default:\n                        if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n                            _ = 0;\n                            continue;\n                        }\n                        if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) {\n                            _.label = op[1];\n                            break;\n                        }\n                        if (op[0] === 6 && _.label < t[1]) {\n                            _.label = t[1];\n                            t = op;\n                            break;\n                        }\n                        if (t && _.label < t[2]) {\n                            _.label = t[2];\n                            _.ops.push(op);\n                            break;\n                        }\n                        if (t[2])\n                            _.ops.pop();\n                        _.trys.pop();\n                        continue;\n                }\n                op = body.call(thisArg, _);\n            }\n            catch (e) {\n                op = [6, e];\n                y = 0;\n            }\n            finally {\n                f = t = 0;\n            }\n        if (op[0] & 5)\n            throw op[1];\n        return { value: op[0] ? op[1] : void 0, done: true };\n    }\n}\nfunction __values(o) {\n    var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n    if (m)\n        return m.call(o);\n    if (o && typeof o.length === \"number\")\n        return {\n            next: function () {\n                if (o && i >= o.length)\n                    o = void 0;\n                return { value: o && o[i++], done: !o };\n            }\n        };\n    throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\nfunction __read(o, n) {\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n    if (!m)\n        return o;\n    var i = m.call(o), r, ar = [], e;\n    try {\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)\n            ar.push(r.value);\n    }\n    catch (error) {\n        e = { error: error };\n    }\n    finally {\n        try {\n            if (r && !r.done && (m = i[\"return\"]))\n                m.call(i);\n        }\n        finally {\n            if (e)\n                throw e.error;\n        }\n    }\n    return ar;\n}\nfunction __spread() {\n    for (var ar = [], i = 0; i < arguments.length; i++)\n        ar = ar.concat(__read(arguments[i]));\n    return ar;\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction assertNotComplex(tensor, opName) {\n    if (!Array.isArray(tensor)) {\n        tensor = [tensor];\n    }\n    tensor.forEach(function (t) {\n        if (t != null) {\n            tfjsCore.util.assert(t.dtype !== 'complex64', function () { return opName + \" does not support complex64 tensors in the CPU backend.\"; });\n        }\n    });\n}\n\nvar whereImpl = tfjsCore.kernel_impls.whereImpl;\nvar MathBackendCPU = /** @class */ (function (_super) {\n    __extends(MathBackendCPU, _super);\n    function MathBackendCPU() {\n        var _this = _super.call(this) || this;\n        _this.blockSize = 48;\n        _this.firstUse = true;\n        _this.data = new tfjsCore.DataStorage(_this, tfjsCore.engine());\n        return _this;\n    }\n    MathBackendCPU.prototype.nextDataId = function () {\n        return MathBackendCPU.nextDataId++;\n    };\n    MathBackendCPU.prototype.write = function (values, shape, dtype) {\n        if (this.firstUse) {\n            this.firstUse = false;\n            if (tfjsCore.env().get('IS_NODE')) {\n                tfjsCore.backend_util.warn('\\n============================\\n' +\n                    'Hi there . Looks like you are running TensorFlow.js in ' +\n                    'Node.js. To speed things up dramatically, install our node ' +\n                    'backend, which binds to TensorFlow C++, by running ' +\n                    'npm i @tensorflow/tfjs-node, ' +\n                    'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n                    'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n                    'suffix for CUDA) at the start of your program. ' +\n                    'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n                    '\\n============================');\n            }\n        }\n        var dataId = { id: this.nextDataId() };\n        this.data.set(dataId, { values: values, dtype: dtype, refCount: 1 });\n        return dataId;\n    };\n    /**\n     * Create a data bucket in cpu backend.\n     * @param shape Shape of the `TensorInfo`.\n     * @param dtype DType of the `TensorInfo`.\n     * @param values The value of the `TensorInfo` stored as a flattened array.\n     */\n    MathBackendCPU.prototype.makeTensorInfo = function (shape, dtype, values) {\n        var outId;\n        if (dtype === 'string' && values != null && values.length > 0 &&\n            tfjsCore.util.isString(values[0])) {\n            var encodedValues = values.map(function (d) { return tfjsCore.util.encodeString(d); });\n            outId = this.write(encodedValues, shape, dtype);\n        }\n        else {\n            outId = this.write(values, shape, dtype);\n        }\n        return { dataId: outId, shape: shape, dtype: dtype };\n    };\n    /** Return refCount of a `TensorData`. */\n    MathBackendCPU.prototype.refCount = function (dataId) {\n        if (this.data.has(dataId)) {\n            var tensorData = this.data.get(dataId);\n            return tensorData.refCount;\n        }\n        return 0;\n    };\n    /** Increase refCount of a `TensorData`. */\n    MathBackendCPU.prototype.incRef = function (dataId) {\n        var tensorData = this.data.get(dataId);\n        tensorData.refCount++;\n    };\n    /** Decrease refCount of a `TensorData`. */\n    MathBackendCPU.prototype.decRef = function (dataId) {\n        if (this.data.has(dataId)) {\n            var tensorData = this.data.get(dataId);\n            tensorData.refCount--;\n        }\n    };\n    MathBackendCPU.prototype.move = function (dataId, values, shape, dtype, refCount) {\n        this.data.set(dataId, { values: values, dtype: dtype, refCount: refCount });\n    };\n    MathBackendCPU.prototype.numDataIds = function () {\n        return this.data.numDataIds();\n    };\n    MathBackendCPU.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_b) {\n                return [2 /*return*/, this.readSync(dataId)];\n            });\n        });\n    };\n    MathBackendCPU.prototype.readSync = function (dataId) {\n        var _b = this.data.get(dataId), dtype = _b.dtype, complexTensorInfos = _b.complexTensorInfos;\n        if (dtype === 'complex64') {\n            var realValues = this.readSync(complexTensorInfos.real.dataId);\n            var imagValues = this.readSync(complexTensorInfos.imag.dataId);\n            return tfjsCore.backend_util.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        return this.data.get(dataId).values;\n    };\n    MathBackendCPU.prototype.bufferSync = function (t) {\n        var data = this.readSync(t.dataId);\n        var decodedData = data;\n        if (t.dtype === 'string') {\n            try {\n                // Decode the bytes into string.\n                decodedData = data.map(function (d) { return tfjsCore.util.decodeString(d); });\n            }\n            catch (_a) {\n                throw new Error('Failed to decode encoded string bytes into utf-8');\n            }\n        }\n        return tfjsCore.buffer(t.shape, t.dtype, decodedData);\n    };\n    MathBackendCPU.prototype.makeOutput = function (values, shape, dtype) {\n        var dataId = this.write(values, shape, dtype);\n        return tfjsCore.engine().makeTensorFromDataId(dataId, shape, dtype, this);\n    };\n    /**\n     * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n     * is released or memory is not managed in this backend, false if memory is\n     * not cleared.\n     * @param dataId\n     * @oaram force Optional, remove the data regardless of refCount\n     */\n    MathBackendCPU.prototype.disposeData = function (dataId, force) {\n        if (force === void 0) { force = false; }\n        if (this.data.has(dataId)) {\n            this.data.get(dataId).refCount--;\n            if (!force && this.data.get(dataId).refCount > 0) {\n                return false;\n            }\n            var complexTensorInfos = this.data.get(dataId).complexTensorInfos;\n            if (complexTensorInfos != null) {\n                this.disposeData(complexTensorInfos.real.dataId, true);\n                this.disposeData(complexTensorInfos.imag.dataId, true);\n            }\n            this.data.delete(dataId);\n        }\n        return true;\n    };\n    MathBackendCPU.prototype.disposeIntermediateTensorInfo = function (tensorInfo) {\n        this.disposeData(tensorInfo.dataId);\n    };\n    MathBackendCPU.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, kernelMs;\n            return __generator(this, function (_b) {\n                start = tfjsCore.util.now();\n                f();\n                kernelMs = tfjsCore.util.now() - start;\n                return [2 /*return*/, { kernelMs: kernelMs }];\n            });\n        });\n    };\n    MathBackendCPU.prototype.memory = function () {\n        return {\n            // Unreliable due to automatic gc. The numbers above are cumulative.\n            unreliable: true,\n            reasons: ['The reported memory is an upper bound. Due to automatic garbage ' +\n                    'collection, the true allocated memory may be less.']\n        };\n    };\n    MathBackendCPU.prototype.where = function (condition) {\n        assertNotComplex([condition], 'where');\n        var condVals = this.readSync(condition.dataId);\n        return whereImpl(condition.shape, condVals);\n    };\n    MathBackendCPU.prototype.dispose = function () { };\n    MathBackendCPU.prototype.floatPrecision = function () {\n        return 32;\n    };\n    /** Returns the smallest representable number.  */\n    MathBackendCPU.prototype.epsilon = function () {\n        return _super.prototype.epsilon.call(this);\n    };\n    return MathBackendCPU;\n}(tfjsCore.KernelBackend));\nMathBackendCPU.nextDataId = 0;\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction simpleAbsImpl(vals) {\n    var resultValues = new Float32Array(vals.length);\n    for (var i = 0; i < vals.length; ++i) {\n        resultValues[i] = Math.abs(vals[i]);\n    }\n    return resultValues;\n}\nvar abs = function (args) {\n    var x = args.inputs.x;\n    var cpuBackend = args.backend;\n    assertNotComplex(x, 'abs');\n    var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(x.shape));\n    var values = cpuBackend.data.get(x.dataId).values;\n    resultValues = simpleAbsImpl(values);\n    return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);\n};\nvar absConfig = {\n    kernelName: tfjsCore.Abs,\n    backendName: 'cpu',\n    kernelFunc: abs,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nfunction createSimpleBinaryKernelImpl(op) {\n    return function (aShape, bShape, aVals, bVals, dtype) {\n        var newShape = tfjsCore.backend_util.assertAndGetBroadcastShape(aShape, bShape);\n        var resultRank = newShape.length;\n        var resultStrides = tfjsCore.util.computeStrides(newShape);\n        var resultSize = tfjsCore.util.sizeFromShape(newShape);\n        var result = tfjsCore.util.getTypedArrayFromDType(dtype, resultSize);\n        var aRank = aShape.length;\n        var bRank = bShape.length;\n        var aStrides = tfjsCore.util.computeStrides(aShape);\n        var bStrides = tfjsCore.util.computeStrides(bShape);\n        var aBroadcastDims = tfjsCore.backend_util.getBroadcastDims(aShape, newShape);\n        var bBroadcastDims = tfjsCore.backend_util.getBroadcastDims(bShape, newShape);\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < result.length; ++i) {\n                result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n            }\n        }\n        else {\n            var _loop_1 = function (i) {\n                var loc = tfjsCore.util.indexToLoc(i, resultRank, resultStrides);\n                var aLoc = loc.slice(-aRank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = tfjsCore.util.locToIndex(aLoc, aRank, aStrides);\n                var bLoc = loc.slice(-bRank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = tfjsCore.util.locToIndex(bLoc, bRank, bStrides);\n                result[i] = op(aVals[aIndex], bVals[bIndex]);\n            };\n            for (var i = 0; i < result.length; ++i) {\n                _loop_1(i);\n            }\n        }\n        return [result, newShape];\n    };\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction complex(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var real = inputs.real, imag = inputs.imag;\n    var realVals = backend.data.get(real.dataId).values;\n    var imagVals = backend.data.get(imag.dataId).values;\n    var complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n    var complex = backend.data.get(complexInfo.dataId);\n    // The complex tensor owns the underlying real and imag tensorInfos, only the\n    // complex tensor tracks refCount, when complexData is disposed the\n    // underlying tensorData will be disposed.\n    complex.complexTensorInfos = {\n        real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n        imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n    };\n    return complexInfo;\n}\nvar complexConfig = {\n    kernelName: tfjsCore.Complex,\n    backendName: 'cpu',\n    kernelFunc: complex\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Generates a tensorInfo with all zeros value.\n * @param backend cpu backend.\n * @param shape Shape for the zeros tensor.\n * @param dtype Optional. If set, the result has this dtype.\n */\nfunction zeros(backend, shape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (dtype === 'complex64') {\n        var real = zeros(backend, shape, 'float32');\n        var imag = zeros(backend, shape, 'float32');\n        return complex({ inputs: { real: real, imag: imag }, backend: backend });\n    }\n    var values = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(shape), dtype);\n    return backend.makeTensorInfo(shape, dtype, values);\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction identity(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x;\n    backend.incRef(x.dataId);\n    return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };\n}\nvar identityConfig = {\n    kernelName: tfjsCore.Identity,\n    backendName: 'cpu',\n    kernelFunc: identity\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction real(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var input = inputs.input;\n    var real = backend.data.get(input.dataId).complexTensorInfos.real;\n    var realVal = backend.data.get(real.dataId).values;\n    // When complex tensor is disposed, its underlying parts will be disposed too.\n    // Make new tensor out of the real value of the complex. This makes sure the\n    // value is still accessible even if complex tensor is disposed.\n    return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\nvar realConfig = {\n    kernelName: tfjsCore.Real,\n    backendName: 'cpu',\n    kernelFunc: real\n};\n\nfunction cast(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var dtype = attrs.dtype;\n    // Casting to complex64.\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return identity({ inputs: { x: x }, backend: backend });\n        }\n        var zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n        var floatX = cast({ inputs: { x: x }, backend: backend, attrs: { dtype: 'float32' } });\n        var result = complex({ inputs: { real: floatX, imag: zerosTensorInfo }, backend: backend });\n        backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n        backend.disposeIntermediateTensorInfo(floatX);\n        return result;\n    }\n    // Casting from complex64\n    if (x.dtype === 'complex64') {\n        var realPart = real({ inputs: { input: x }, backend: backend });\n        var result = cast({ inputs: { x: realPart }, backend: backend, attrs: { dtype: dtype } });\n        backend.disposeIntermediateTensorInfo(realPart);\n        return result;\n    }\n    if (!tfjsCore.util.hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        var result = identity({ inputs: { x: x }, backend: backend });\n        return { dataId: result.dataId, shape: result.shape, dtype: dtype };\n    }\n    if (dtype === 'int32') {\n        var values = backend.data.get(x.dataId).values;\n        var resultValues = Int32Array.from(values);\n        return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n    }\n    if (dtype === 'bool') {\n        // This is essentially the result of notEqual(x, 0). We avoid using\n        // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n        // cast -> notEqual -> binary_utils.\n        var xVals = backend.data.get(x.dataId).values;\n        var zero = tfjsCore.util.toTypedArray([0], x.dtype);\n        var _a = __read(createSimpleBinaryKernelImpl(function (a, b) { return (a !== b) ? 1 : 0; })(x.shape, [], xVals, zero, 'bool'), 2), resultData = _a[0], resultShape = _a[1];\n        return backend.makeTensorInfo(resultShape, 'bool', resultData);\n    }\n    throw new Error(\"Error in Cast: failed to cast \" + x.dtype + \" to \" + dtype);\n}\nvar castConfig = {\n    kernelName: tfjsCore.Cast,\n    backendName: 'cpu',\n    kernelFunc: cast\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nfunction binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {\n    if (complexImpl == null) {\n        return function (_a) {\n            var inputs = _a.inputs, backend = _a.backend;\n            var a = inputs.a, b = inputs.b;\n            var cpuBackend = backend;\n            assertNotComplex([a, b], name);\n            var aVals = cpuBackend.data.get(a.dataId).values;\n            var bVals = cpuBackend.data.get(b.dataId).values;\n            var decodedAVals = a.dtype === 'string' ?\n                // tslint:disable-next-line: no-any\n                tfjsCore.backend_util.fromUint8ToStringArray(aVals) :\n                aVals;\n            var decodedBVals = a.dtype === 'string' ?\n                // tslint:disable-next-line: no-any\n                tfjsCore.backend_util.fromUint8ToStringArray(bVals) :\n                bVals;\n            var $dtype = dtype || a.dtype;\n            var _b = __read(simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype), 2), resultData = _b[0], resultShape = _b[1];\n            return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n        };\n    }\n    return function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var a = inputs.a, b = inputs.b;\n        var cpuBackend = backend;\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            var $aComplex = cast({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: 'complex64' } });\n            var $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n            var aReal = $aComplexVals.complexTensorInfos.real;\n            var aImag = $aComplexVals.complexTensorInfos.imag;\n            var aRealVals = cpuBackend.data.get(aReal.dataId).values;\n            var aImagVals = cpuBackend.data.get(aImag.dataId).values;\n            var $bComplex = cast({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: 'complex64' } });\n            var $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n            var bReal = $bComplexVals.complexTensorInfos.real;\n            var bImag = $bComplexVals.complexTensorInfos.imag;\n            var bRealVals = cpuBackend.data.get(bReal.dataId).values;\n            var bImagVals = cpuBackend.data.get(bImag.dataId).values;\n            var _b = __read(complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals), 3), resultRealData = _b[0], resultImagData = _b[1], resultShape = _b[2];\n            var resultReal = cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n            var resultImag = cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n            var result = complex({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });\n            cpuBackend.disposeIntermediateTensorInfo($aComplex);\n            cpuBackend.disposeIntermediateTensorInfo($bComplex);\n            cpuBackend.disposeIntermediateTensorInfo(resultReal);\n            cpuBackend.disposeIntermediateTensorInfo(resultImag);\n            return result;\n        }\n        else {\n            var aVals = cpuBackend.data.get(a.dataId).values;\n            var bVals = cpuBackend.data.get(b.dataId).values;\n            var $dtype = dtype || a.dtype;\n            var _c = __read(simpleImpl(a.shape, b.shape, aVals, bVals, $dtype), 2), resultData = _c[0], resultShape = _c[1];\n            return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n        }\n    };\n}\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nfunction createComplexBinaryKernelImpl(op) {\n    return function (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) {\n        var resultShape = tfjsCore.backend_util.assertAndGetBroadcastShape(aShape, bShape);\n        var resultSize = tfjsCore.util.sizeFromShape(resultShape);\n        var resultRank = resultShape.length;\n        var resultStrides = tfjsCore.util.computeStrides(resultShape);\n        var resultRealVals = tfjsCore.util.getTypedArrayFromDType('float32', resultSize);\n        var resultImagVals = tfjsCore.util.getTypedArrayFromDType('float32', resultSize);\n        var aBroadcastDims = tfjsCore.backend_util.getBroadcastDims(aShape, resultShape);\n        var bBroadcastDims = tfjsCore.backend_util.getBroadcastDims(bShape, resultShape);\n        var aVals = tfjsCore.backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n        var bVals = tfjsCore.backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n        var aRank = aShape.length;\n        var aStrides = tfjsCore.util.computeStrides(aShape);\n        var bRank = bShape.length;\n        var bStrides = tfjsCore.util.computeStrides(bShape);\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < resultRealVals.length; i++) {\n                var aIdx = i % aVals.length;\n                var bIdx = i % bVals.length;\n                var result = op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);\n                resultRealVals[i] = result.real;\n                resultImagVals[i] = result.imag;\n            }\n        }\n        else {\n            var _loop_1 = function (i) {\n                var loc = tfjsCore.util.indexToLoc(i, resultRank, resultStrides);\n                var aLoc = loc.slice(-aRank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = tfjsCore.util.locToIndex(aLoc, aRank, aStrides);\n                var bLoc = loc.slice(-bRank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = tfjsCore.util.locToIndex(bLoc, bRank, bStrides);\n                var opResult = op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);\n                resultRealVals[i] = opResult.real;\n                resultImagVals[i] = opResult.imag;\n            };\n            for (var i = 0; i < resultRealVals.length; i++) {\n                _loop_1(i);\n            }\n        }\n        return [resultRealVals, resultImagVals, resultShape];\n    };\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar addImpl = createSimpleBinaryKernelImpl((function (a, b) { return a + b; }));\nvar addComplexImpl = createComplexBinaryKernelImpl((function (aReal, aImag, bReal, bImag) {\n    return { real: aReal + bReal, imag: aImag + bImag };\n}));\nvar add = binaryKernelFunc(tfjsCore.Add, addImpl, addComplexImpl);\nvar addConfig = {\n    kernelName: tfjsCore.Add,\n    backendName: 'cpu',\n    kernelFunc: add\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {\n    var weightsSize = tfjsCore.util.sizeFromShape(weightsShape);\n    var outVals = tfjsCore.util.makeZerosTypedArray(size, weightsDtype);\n    for (var i = 0; i < xVals.length; i++) {\n        var value = xVals[i];\n        if (value < 0) {\n            throw new Error('Input x must be non-negative!');\n        }\n        if (value >= size) {\n            continue;\n        }\n        if (weightsSize > 0) {\n            outVals[value] += weightsVals[i];\n        }\n        else {\n            outVals[value] += 1;\n        }\n    }\n    return outVals;\n}\nfunction bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput) {\n    if (binaryOutput === void 0) { binaryOutput = false; }\n    var numRows = xBuf.shape[0];\n    var numCols = xBuf.shape[1];\n    var outBuf = tfjsCore.buffer([numRows, size], weightsBuf.dtype);\n    for (var i = 0; i < numRows; i++) {\n        for (var j = 0; j < numCols; j++) {\n            var value = xBuf.get(i, j);\n            if (value < 0) {\n                throw new Error('Input x must be non-negative!');\n            }\n            if (value >= size) {\n                continue;\n            }\n            if (binaryOutput) {\n                outBuf.set(1, i, value);\n            }\n            else {\n                if (weightsBuf.size > 0) {\n                    outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n                }\n                else {\n                    outBuf.set(outBuf.get(i, value) + 1, i, value);\n                }\n            }\n        }\n    }\n    return outBuf;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Template that creates implementation for unary op.\n */\nfunction createSimpleUnaryImpl(op) {\n    return function (values, dtype, attrs) {\n        var newValues = tfjsCore.util.getTypedArrayFromDType(dtype, values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = op(values[i], attrs);\n        }\n        return newValues;\n    };\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nfunction unaryKernelFunc(name, op, dtype) {\n    return function (_a) {\n        var inputs = _a.inputs, attrs = _a.attrs, backend = _a.backend;\n        var x = inputs.x;\n        assertNotComplex(x, name);\n        if (x.dtype === 'string' || dtype === 'string') {\n            throw new Error('unaryKernelFunc does not support string input/output');\n        }\n        var cpuBackend = backend;\n        var values = cpuBackend.data.get(x.dataId).values;\n        var xSize = tfjsCore.util.sizeFromShape(x.shape);\n        var $dtype = dtype || x.dtype;\n        var newValues = tfjsCore.util.getArrayFromDType($dtype, xSize);\n        for (var i = 0; i < xSize; ++i) {\n            newValues[i] = op(values[i], attrs);\n        }\n        return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n    };\n}\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nfunction unaryKernelFuncFromImpl(name, unaryImpl, dtype) {\n    return function (_a) {\n        var inputs = _a.inputs, attrs = _a.attrs, backend = _a.backend;\n        var x = inputs.x;\n        assertNotComplex(x, name);\n        if (x.dtype === 'string' || dtype === 'string') {\n            throw new Error('unaryKernelFunc does not support string input/output');\n        }\n        var cpuBackend = backend;\n        var values = cpuBackend.data.get(x.dataId).values;\n        var $dtype = dtype || x.dtype;\n        var newValues = unaryImpl(values, $dtype, attrs);\n        return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n    };\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar ceilImpl = createSimpleUnaryImpl(function (xi) { return Math.ceil(xi); });\nvar ceil = unaryKernelFuncFromImpl(tfjsCore.Ceil, ceilImpl);\nvar ceilConfig = {\n    kernelName: tfjsCore.Ceil,\n    backendName: 'cpu',\n    kernelFunc: ceil,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction concatImpl(inputs, outShape, dtype, simplyConcat) {\n    var outVals = tfjsCore.util.getArrayFromDType(dtype, tfjsCore.util.sizeFromShape(outShape));\n    if (simplyConcat && dtype !== 'string') {\n        // Use built-in TypedArray.set() method for speed.\n        var offset_1 = 0;\n        inputs.forEach(function (input) {\n            var size = tfjsCore.util.sizeFromShape(input.shape);\n            outVals.set(input.vals, offset_1);\n            offset_1 += size;\n        });\n    }\n    else {\n        var colOffset_1 = 0;\n        inputs.forEach(function (input) {\n            var decodedData = dtype === 'string' ?\n                tfjsCore.backend_util.fromUint8ToStringArray(input.vals) :\n                input.vals;\n            var tIdx = 0;\n            for (var row = 0; row < input.shape[0]; ++row) {\n                var resIdx = row * outShape[1] + colOffset_1;\n                for (var col = 0; col < input.shape[1]; ++col) {\n                    outVals[resIdx + col] = decodedData[tIdx++];\n                }\n            }\n            colOffset_1 += input.shape[1];\n        });\n    }\n    return outVals;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar equalImpl = createSimpleBinaryKernelImpl(function (a, b) { return (a === b) ? 1 : 0; });\nvar equal = binaryKernelFunc(tfjsCore.Equal, equalImpl, null /* complexImpl */, 'bool');\nvar equalConfig = {\n    kernelName: tfjsCore.Equal,\n    backendName: 'cpu',\n    kernelFunc: equal\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar expImpl = createSimpleUnaryImpl(function (xi) { return Math.exp(xi); });\nvar exp = unaryKernelFuncFromImpl(tfjsCore.Exp, expImpl, 'float32');\nvar expConfig = {\n    kernelName: tfjsCore.Exp,\n    backendName: 'cpu',\n    kernelFunc: exp,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar expm1Impl = createSimpleUnaryImpl(function (xi) { return Math.expm1(xi); });\nvar expm1 = unaryKernelFuncFromImpl(tfjsCore.Expm1, expm1Impl);\nvar expm1Config = {\n    kernelName: tfjsCore.Expm1,\n    backendName: 'cpu',\n    kernelFunc: expm1,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar floorImpl = createSimpleUnaryImpl(function (xi) { return Math.floor(xi); });\nvar floor = unaryKernelFuncFromImpl(tfjsCore.Floor, floorImpl);\nvar floorConfig = {\n    kernelName: tfjsCore.Floor,\n    backendName: 'cpu',\n    kernelFunc: floor,\n};\n\nfunction gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {\n    var outBuf = tfjsCore.buffer([numSlices, sliceSize], dtype);\n    for (var i = 0; i < numSlices; i++) {\n        var index = [];\n        var flattenIndex = 0;\n        for (var j = 0; j < sliceRank; j++) {\n            var dim = indicesData[i * sliceRank + j];\n            flattenIndex += dim * strides[j];\n            index.push(dim);\n        }\n        if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n            throw new Error(\"Invalid indices: \" + index + \" does not index into \" + paramsShape);\n        }\n        for (var k = 0; k < sliceSize; k++) {\n            outBuf.values[i * sliceSize + k] = paramsBuf.get.apply(paramsBuf, __spread(paramsBuf.indexToLoc(flattenIndex * sliceSize + k)));\n        }\n    }\n    return outBuf;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {\n    var outBuf = tfjsCore.buffer(flattenOutputShape, xBuf.dtype);\n    for (var i = 0; i < outBuf.size; ++i) {\n        var newLoc = outBuf.indexToLoc(i);\n        var originalLoc = newLoc.slice();\n        var batchIdx = originalLoc[0];\n        var indicesIdx = originalLoc[2];\n        var indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n        originalLoc[2] = indicesBuf.values[indicesIndex];\n        var originalIndex = xBuf.locToIndex(originalLoc);\n        if (0 <= originalIndex && originalIndex < xBuf.values.length) {\n            outBuf.values[i] = xBuf.values[originalIndex];\n        } // Else, index is out of bounds, so leave the default zero val in outBuf.\n    }\n    return outBuf;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar greaterImpl = createSimpleBinaryKernelImpl(function (a, b) { return (a > b) ? 1 : 0; });\nvar greater = binaryKernelFunc(tfjsCore.Greater, greaterImpl, null /* complexImpl */, 'bool');\nvar greaterConfig = {\n    kernelName: tfjsCore.Greater,\n    backendName: 'cpu',\n    kernelFunc: greater\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar greaterEqualImpl = createSimpleBinaryKernelImpl(function (a, b) { return (a >= b) ? 1 : 0; });\nvar greaterEqual = binaryKernelFunc(tfjsCore.GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\nvar greaterEqualConfig = {\n    kernelName: tfjsCore.GreaterEqual,\n    backendName: 'cpu',\n    kernelFunc: greaterEqual\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar lessImpl = createSimpleBinaryKernelImpl(function (a, b) { return (a < b) ? 1 : 0; });\nvar less = binaryKernelFunc(tfjsCore.Less, lessImpl, null /* complexImpl */, 'bool');\nvar lessConfig = {\n    kernelName: tfjsCore.Less,\n    backendName: 'cpu',\n    kernelFunc: less\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar lessEqualImpl = createSimpleBinaryKernelImpl(function (a, b) { return (a <= b) ? 1 : 0; });\nvar lessEqual = binaryKernelFunc(tfjsCore.LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\nvar lessEqualConfig = {\n    kernelName: tfjsCore.LessEqual,\n    backendName: 'cpu',\n    kernelFunc: lessEqual\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction linSpaceImpl(start, stop, num) {\n    var step = (stop - start) / (num - 1);\n    var values = tfjsCore.util.makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return values;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar logImpl = createSimpleUnaryImpl(function (xi) { return Math.log(xi); });\nvar log = unaryKernelFuncFromImpl(tfjsCore.Log, logImpl);\nvar logConfig = {\n    kernelName: tfjsCore.Log,\n    backendName: 'cpu',\n    kernelFunc: log,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxImpl(aVals, reduceSize, outShape, dtype) {\n    var vals = tfjsCore.util.getTypedArrayFromDType(dtype, tfjsCore.util.sizeFromShape(outShape));\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var max = aVals[offset];\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            if (Number.isNaN(value) ||\n                value > max) { // comparison with NaN always return false\n                max = value;\n            }\n        }\n        vals[i] = max;\n    }\n    return vals;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar maximumImpl = createSimpleBinaryKernelImpl((function (aValue, bValue) { return Math.max(aValue, bValue); }));\nvar maximum = binaryKernelFunc(tfjsCore.Maximum, maximumImpl);\nvar maximumConfig = {\n    kernelName: tfjsCore.Maximum,\n    backendName: 'cpu',\n    kernelFunc: maximum\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar minimumImpl = createSimpleBinaryKernelImpl((function (aValue, bValue) { return Math.min(aValue, bValue); }));\nvar minimum = binaryKernelFunc(tfjsCore.Minimum, minimumImpl);\nvar minimumConfig = {\n    kernelName: tfjsCore.Minimum,\n    backendName: 'cpu',\n    kernelFunc: minimum\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar multiplyImpl = createSimpleBinaryKernelImpl((function (aValue, bValue) { return aValue * bValue; }));\nvar multiplyComplexImpl = createComplexBinaryKernelImpl((function (aReal, aImag, bReal, bImag) {\n    return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n    };\n}));\nvar multiply = binaryKernelFunc(tfjsCore.Multiply, multiplyImpl, multiplyComplexImpl);\nvar multiplyConfig = {\n    kernelName: tfjsCore.Multiply,\n    backendName: 'cpu',\n    kernelFunc: multiply\n};\n\nfunction negImpl(xVals, xShape, xDtype) {\n    var minusOne = tfjsCore.util.createScalarValue(-1, xDtype);\n    return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\nfunction neg(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x;\n    assertNotComplex(x, 'neg');\n    var xVals = backend.data.get(x.dataId).values;\n    var _a = __read(negImpl(xVals, x.shape, x.dtype), 2), res = _a[0], newShape = _a[1];\n    return backend.makeTensorInfo(newShape, x.dtype, res);\n}\nvar negConfig = {\n    kernelName: tfjsCore.Neg,\n    backendName: 'cpu',\n    kernelFunc: neg\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar notEqualImpl = createSimpleBinaryKernelImpl((function (a, b) { return (a !== b) ? 1 : 0; }));\nvar notEqual = binaryKernelFunc(tfjsCore.NotEqual, notEqualImpl, null /* complexOp */, 'bool');\nvar notEqualConfig = {\n    kernelName: tfjsCore.NotEqual,\n    backendName: 'cpu',\n    kernelFunc: notEqual\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction transposeImpl(xVals, xShape, dtype, perm, newShape) {\n    var xRank = xShape.length;\n    var xSize = tfjsCore.util.sizeFromShape(xShape);\n    var xStrides = tfjsCore.util.computeStrides(xShape);\n    var newStrides = tfjsCore.util.computeStrides(newShape);\n    var result = tfjsCore.util.getTypedArrayFromDType(dtype, tfjsCore.util.sizeFromShape(newShape));\n    for (var i = 0; i < xSize; ++i) {\n        var loc = tfjsCore.util.indexToLoc(i, xRank, xStrides);\n        // Permute location.\n        var newLoc = new Array(loc.length);\n        for (var i_1 = 0; i_1 < newLoc.length; i_1++) {\n            newLoc[i_1] = loc[perm[i_1]];\n        }\n        var newIndex = tfjsCore.util.locToIndex(newLoc, xRank, newStrides);\n        result[newIndex] = xVals[i];\n    }\n    return result;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction transpose(args) {\n    var inputs = args.inputs, attrs = args.attrs, backend = args.backend;\n    var x = inputs.x;\n    var perm = attrs.perm;\n    assertNotComplex(x, 'transpose');\n    var xRank = x.shape.length;\n    var newShape = new Array(xRank);\n    for (var i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[perm[i]];\n    }\n    var values = backend.data.get(x.dataId).values;\n    var result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n    var dataId = backend.write(result, newShape, x.dtype);\n    return { dataId: dataId, shape: newShape, dtype: x.dtype };\n}\nvar transposeConfig = {\n    kernelName: tfjsCore.Transpose,\n    backendName: 'cpu',\n    kernelFunc: transpose\n};\n\nfunction prodImpl(xShape, xDtype, xVals, reductionAxes) {\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes(xShape, reductionAxes), 2), outShape = _a[0], reduceShape = _a[1];\n    var outDtype = tfjsCore.upcastType(xDtype, 'int32');\n    var outVals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), outDtype);\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    for (var i = 0; i < outVals.length; ++i) {\n        var offset = i * reduceSize;\n        var prod_1 = 1;\n        for (var j = 0; j < reduceSize; ++j) {\n            prod_1 *= xVals[offset + j];\n        }\n        outVals[i] = prod_1;\n    }\n    return { outVals: outVals, outShape: outShape, outDtype: outDtype };\n}\nfunction prod(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    assertNotComplex(x, 'prod');\n    var xRank = x.shape.length;\n    var axes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var permutation = tfjsCore.backend_util.getAxesPermutation(axes, xRank);\n    var reductionAxes = axes;\n    var permutedX = x;\n    var intermediateTensorInfos = [];\n    if (permutation != null) {\n        permutedX = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutation } });\n        intermediateTensorInfos.push(permutedX);\n        reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n    }\n    var xVals = backend.data.get(permutedX.dataId).values;\n    var _a = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes), outVals = _a.outVals, outShape = _a.outShape, outDtype = _a.outDtype;\n    var resultShape = outShape;\n    if (keepDims) {\n        resultShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, axes);\n    }\n    intermediateTensorInfos.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\nvar prodConfig = {\n    kernelName: tfjsCore.Prod,\n    backendName: 'cpu',\n    kernelFunc: prod\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction rangeImpl(start, stop, step, dtype) {\n    var sameStartStop = start === stop;\n    var increasingRangeNegativeStep = start < stop && step < 0;\n    var decreasingRangePositiveStep = stop < start && step > 1;\n    if (sameStartStop || increasingRangeNegativeStep ||\n        decreasingRangePositiveStep) {\n        return tfjsCore.util.makeZerosTypedArray(0, dtype);\n    }\n    var numElements = Math.abs(Math.ceil((stop - start) / step));\n    var values = tfjsCore.util.makeZerosTypedArray(numElements, dtype);\n    if (stop < start && step === 1) {\n        // Auto adjust the step's sign if it hasn't been set\n        // (or was set to 1)\n        step = -1;\n    }\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return values;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar rsqrtImpl = createSimpleUnaryImpl(function (xi) { return 1 / Math.sqrt(xi); });\nvar rsqrt = unaryKernelFuncFromImpl(tfjsCore.Rsqrt, rsqrtImpl);\nvar rsqrtConfig = {\n    kernelName: tfjsCore.Rsqrt,\n    backendName: 'cpu',\n    kernelFunc: rsqrt,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar sigmoidImpl = createSimpleUnaryImpl(function (xi) { return 1 / (1 + Math.exp(-xi)); });\nvar sigmoid = unaryKernelFunc(tfjsCore.Sigmoid, function (xi) { return 1 / (1 + Math.exp(-xi)); });\nvar sigmoidConfig = {\n    kernelName: tfjsCore.Sigmoid,\n    backendName: 'cpu',\n    kernelFunc: sigmoid,\n};\n\nfunction sliceImpl(vals, begin, size, shape, dtype) {\n    var isContinous = tfjsCore.slice_util.isSliceContinous(shape, begin, size);\n    var length = tfjsCore.util.sizeFromShape(size);\n    var xStrides = tfjsCore.util.computeStrides(shape);\n    if (isContinous) {\n        var flatOffset = tfjsCore.slice_util.computeFlatOffset(begin, xStrides);\n        if (dtype === 'string') {\n            return vals.slice(flatOffset, flatOffset + length);\n        }\n        return vals.subarray(flatOffset, flatOffset + length);\n    }\n    var decodedData = dtype === 'string' ?\n        tfjsCore.backend_util.fromUint8ToStringArray(vals) :\n        vals;\n    var inBuf = tfjsCore.buffer(shape, dtype, decodedData);\n    var outBuf = tfjsCore.buffer(size, dtype);\n    for (var i = 0; i < outBuf.size; ++i) {\n        var outLoc = outBuf.indexToLoc(i);\n        var inLoc = outLoc.map(function (idx, j) { return idx + begin[j]; });\n        outBuf.set.apply(outBuf, __spread([inBuf.get.apply(inBuf, __spread(inLoc))], outLoc));\n    }\n    if (dtype === 'string') {\n        return tfjsCore.backend_util.fromStringArrayToUint8(outBuf.values);\n    }\n    return outBuf.values;\n}\nfunction slice(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var begin = attrs.begin, size = attrs.size;\n    assertNotComplex(x, 'slice');\n    var _a = __read(tfjsCore.slice_util.parseSliceParams(x, begin, size), 2), $begin = _a[0], $size = _a[1];\n    tfjsCore.slice_util.assertParamsValid(x, $begin, $size);\n    var vals = backend.data.get(x.dataId).values;\n    var outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outVals);\n}\nvar sliceConfig = {\n    kernelName: tfjsCore.Slice,\n    backendName: 'cpu',\n    kernelFunc: slice\n};\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {\n    var indicesCount = indicesShape[0];\n    var denseRows = denseShape[0];\n    var emptyRowIndicator = new Array(denseRows);\n    var reverseIndexMap = new Array(indicesCount);\n    var rank = indicesShape[1];\n    if (denseRows === 0) {\n        if (indicesCount !== 0) {\n            throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));\n        }\n        var outputIndices = tfjsCore.util.getArrayFromDType(indicesDType, 0);\n        var outputValues = tfjsCore.util.getArrayFromDType(valuesDType, 0);\n        return [\n            outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n        ];\n    }\n    var rowsAreOrdered = true;\n    var lastIndicesRow = 0;\n    var csrOffset = new Array(denseRows).fill(0);\n    for (var i = 0; i < indicesCount; ++i) {\n        // indices is a 2d tensor with shape of [N, rank]\n        var row = indices[i * rank];\n        if (row < 0) {\n            throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));\n        }\n        if (row >= denseRows) {\n            throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));\n        }\n        ++csrOffset[row];\n        rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n        lastIndicesRow = row;\n    }\n    var allRowsFull = true;\n    for (var row = 0; row < denseRows; ++row) {\n        // csrOffset here describes the number of elements in this dense row\n        var rowEmpty = (csrOffset[row] === 0);\n        emptyRowIndicator[row] = rowEmpty;\n        allRowsFull = allRowsFull && !rowEmpty;\n        // In filled version, each row has at least one element.\n        csrOffset[row] = Math.max(csrOffset[row], 1);\n        // Update csrOffset to represent the number of elements up to and\n        // including denseRows + 1:\n        //  csrOffset[0] == #{elements of row 0}\n        //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n        //  ..\n        //  csrOffset[i] == starting index for elements in row i + 1.\n        if (row > 0) {\n            csrOffset[row] += csrOffset[row - 1];\n        }\n    }\n    if (allRowsFull && rowsAreOrdered) {\n        var outputIndices = indices;\n        var outputValues = values;\n        for (var i = 0; i < indicesCount; ++i) {\n            reverseIndexMap[i] = i;\n        }\n        return [\n            outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n            reverseIndexMap\n        ];\n    }\n    else {\n        var fullIndicesCount = csrOffset[denseRows - 1];\n        var outputIndices = tfjsCore.util.getArrayFromDType(indicesDType, fullIndicesCount * rank);\n        var outputValues = tfjsCore.util.getArrayFromDType(valuesDType, fullIndicesCount);\n        var filledCount = new Array(denseRows).fill(0);\n        // Fill in values for rows that are not missing\n        for (var i = 0; i < indicesCount; ++i) {\n            // indices is a 2d tensor with shape of [N, rank]\n            var row = indices[i * rank];\n            var offset = filledCount[row];\n            var outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n            filledCount[row]++; // Increment the filled count for this row.\n            for (var j = 0; j < rank; ++j) {\n                // indices and outputIndices are 2d tensors with shape of [N, rank]\n                outputIndices[outputI * rank + j] = indices[i * rank + j];\n            }\n            outputValues[outputI] = values[i];\n            // We'll need this reverse index map to backprop correctly.\n            reverseIndexMap[i] = outputI;\n        }\n        // Fill in values for rows that are missing\n        for (var row = 0; row < denseRows; ++row) {\n            var rowCount = filledCount[row];\n            if (rowCount === 0) { // We haven't filled this row\n                var startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n                // Remaining index values were set to zero already.\n                // Just need to set the row index in the right location.\n                // outputIndices is a 2d tensor with shape of [N, rank]\n                outputIndices[startingIndex * rank + 0] = row;\n                for (var col = 1; col < rank; ++col) {\n                    outputIndices[startingIndex * rank + col] = 0;\n                }\n                outputValues[startingIndex] = defaultValue;\n            }\n        }\n        return [\n            outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,\n            reverseIndexMap\n        ];\n    }\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {\n    var denseSize = tfjsCore.util.sizeFromShape(inputShape);\n    var nnz = inputIndicesShape[0];\n    var outputRank = targetShape.length;\n    // Compute the output shape. Determine product of specified dimensions, and\n    // find the index of the unspecified one.\n    var outputShape = [];\n    var product = 1;\n    var unknownIndex = -1;\n    for (var d = 0; d < outputRank; ++d) {\n        var size = targetShape[d];\n        if (size === -1) {\n            if (unknownIndex !== -1) {\n                throw new Error(tfjsCore.backend_util\n                    .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));\n            }\n            unknownIndex = d;\n            outputShape.push(1);\n        }\n        else {\n            if (size < 0) {\n                throw new Error(tfjsCore.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(d, size));\n            }\n            product *= size;\n            outputShape.push(size);\n        }\n    }\n    if (unknownIndex !== -1) {\n        if (product <= 0) {\n            throw new Error(tfjsCore.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());\n        }\n        var missing = Math.trunc(denseSize / product);\n        if (product * missing !== denseSize) {\n            throw new Error(tfjsCore.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));\n        }\n        outputShape[unknownIndex] = missing;\n    }\n    var outputSize = tfjsCore.util.sizeFromShape(outputShape);\n    if (outputSize !== denseSize) {\n        throw new Error(tfjsCore.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));\n    }\n    var inputRank = inputShape.length;\n    var inputStrides = [];\n    if (inputRank > 0) {\n        inputStrides[inputRank - 1] = 1;\n        for (var d = inputRank - 2; d >= 0; --d) {\n            inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n        }\n    }\n    var outputStrides = [];\n    if (outputRank > 0) {\n        outputStrides[outputRank - 1] = 1;\n        for (var d = outputRank - 2; d >= 0; --d) {\n            outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n        }\n    }\n    var newIndices = tfjsCore.util.getArrayFromDType(inputDType, nnz * outputRank);\n    for (var i = 0; i < nnz; ++i) {\n        var id = 0;\n        for (var j = 0; j < inputRank; ++j) {\n            // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n            id += inputIndices[i * inputRank + j] * inputStrides[j];\n        }\n        for (var j = 0; j < outputRank; ++j) {\n            // newIndices is a 2d tensor with shape of [nnz, outputRank]\n            newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n            id %= outputStrides[j];\n        }\n    }\n    return [newIndices, [nnz, outputRank], outputShape];\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean, defaultValue) {\n    if (isMean === void 0) { isMean = false; }\n    if (defaultValue === void 0) { defaultValue = 0; }\n    var numIndices = indices.length;\n    // Flatten the array to two dimensions\n    var inputFlat = [inputShape[0], input.length / inputShape[0]];\n    var numCol = inputFlat[1];\n    // Note that the current implementation assumes that segmentIds values are\n    // sorted.\n    var lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;\n    var outputRows = lastSegmentIdPlusOne;\n    if (outputRows < 0) {\n        throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n    }\n    var outputShape = inputShape.slice();\n    outputShape[0] = outputRows;\n    var outputLength = outputShape.reduce(function (product, value) { return product * value; }, 1);\n    // Output array is initialized with the value 0 by default.\n    var output = tfjsCore.util.getArrayFromDType(inputDType, outputLength);\n    // Note that we do not initialize the output buffer with a default value, so\n    // we need to explicitly set missing indices to the default value.\n    if (numIndices === 0) {\n        if (outputRows > 0) {\n            output.fill(defaultValue);\n        }\n        return [output, outputShape];\n    }\n    if (outputRows <= 0) {\n        throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n    }\n    var start = 0, end = 1;\n    // Index from which the output is not initialized.\n    var uninitializedIndex = 0;\n    var outIndex = segmentIds[start];\n    while (true) {\n        // We initialize nextIndex to 0 to avoid may be uninitialized warning\n        var nextIndex = 0;\n        if (end < numIndices) {\n            nextIndex = segmentIds[end];\n            if (outIndex === nextIndex) {\n                ++end;\n                continue;\n            }\n            // We have a new segment here.  Verify that the segment ids are growing.\n            if (outIndex >= nextIndex) {\n                throw new Error(tfjsCore.backend_util\n                    .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());\n            }\n        }\n        if (outIndex < 0 || outIndex >= outputRows) {\n            throw new Error(tfjsCore.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));\n        }\n        // If there is a gap between two indices, we need to set that gap to the\n        // default value.\n        if (outIndex > uninitializedIndex) {\n            output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);\n        }\n        for (var i = start; i < end; ++i) {\n            var index = indices[i];\n            if (index < 0 || index >= inputFlat[0]) {\n                throw new Error(tfjsCore.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));\n            }\n            for (var j = 0; j < numCol; j++) {\n                output[outIndex * numCol + j] += input[index * numCol + j];\n            }\n        }\n        if (isMean) {\n            for (var j = 0; j < numCol; j++) {\n                output[outIndex * numCol + j] /= end - start;\n            }\n        }\n        start = end;\n        ++end;\n        uninitializedIndex = outIndex + 1;\n        outIndex = nextIndex;\n        if (end > numIndices) {\n            break;\n        }\n    }\n    // Fill the gap at the end with the default value.\n    if (uninitializedIndex < outputRows) {\n        output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);\n    }\n    return [output, outputShape];\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar sqrtImpl = createSimpleUnaryImpl(function (xi) { return Math.sqrt(xi); });\nvar sqrt = unaryKernelFunc(tfjsCore.Sqrt, function (xi) { return Math.sqrt(xi); });\nvar sqrtConfig = {\n    kernelName: tfjsCore.Sqrt,\n    backendName: 'cpu',\n    kernelFunc: sqrt,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar squaredDifferenceImpl = createSimpleBinaryKernelImpl((function (a, b) {\n    var diff = a - b;\n    return diff * diff;\n}));\nvar squaredDifference = binaryKernelFunc(tfjsCore.SquaredDifference, squaredDifferenceImpl);\nvar squaredDifferenceConfig = {\n    kernelName: tfjsCore.SquaredDifference,\n    backendName: 'cpu',\n    kernelFunc: squaredDifference\n};\n\nfunction stridedSliceImpl(outShape, xBuf, strides, begin) {\n    var outBuf = tfjsCore.buffer(outShape, xBuf.dtype);\n    for (var i = 0; i < outBuf.size; i++) {\n        var loc = outBuf.indexToLoc(i);\n        var newLoc = new Array(loc.length);\n        for (var j = 0; j < newLoc.length; j++) {\n            newLoc[j] = loc[j] * strides[j] + begin[j];\n        }\n        outBuf.set.apply(outBuf, __spread([xBuf.get.apply(xBuf, __spread(newLoc))], loc));\n    }\n    return outBuf;\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nvar StringNGramsOp = /** @class */ (function () {\n    function StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {\n        this.separator = tfjsCore.util.encodeString(separator);\n        this.nGramWidths = nGramWidths;\n        this.leftPad = tfjsCore.util.encodeString(leftPad);\n        this.rightPad = tfjsCore.util.encodeString(rightPad);\n        this.padWidth = padWidth;\n        this.preserveShort = preserveShortSequences;\n    }\n    StringNGramsOp.prototype.getPadWidth = function (nGramWidth) {\n        // Ngrams can be padded with either a fixed pad width or a dynamic pad\n        // width depending on the 'padWidth' arg, but in no case should the padding\n        // ever be wider than 'nGramWidth' - 1.\n        return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n    };\n    StringNGramsOp.prototype.getNumNGrams = function (length, nGramWidth) {\n        var padWidth = this.getPadWidth(nGramWidth);\n        return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n    };\n    StringNGramsOp.prototype.createNGrams = function (data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {\n        var _loop_1 = function (nGramIndex) {\n            var padWidth = this_1.getPadWidth(nGramWidth);\n            var leftPadding = Math.max(0, padWidth - nGramIndex);\n            var rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n            var numTokens = nGramWidth - (leftPadding + rightPadding);\n            var dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n            // Calculate the total expected size of the nGram so we can reserve the\n            // correct amount of space in the string.\n            var nGramSize = 0;\n            // Size of the left padding.\n            nGramSize += leftPadding * this_1.leftPad.length;\n            // Size of the tokens.\n            for (var n = 0; n < numTokens; ++n) {\n                nGramSize += data[dataStartIndex + n].length;\n            }\n            // Size of the right padding.\n            nGramSize += rightPadding * this_1.rightPad.length;\n            // Size of the separators.\n            var numSeparators = leftPadding + rightPadding + numTokens - 1;\n            nGramSize += numSeparators * this_1.separator.length;\n            // Build the nGram.\n            output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n            var nGram = output[outputStartIndex + nGramIndex];\n            var nextNGramIndex = 0;\n            var appendToNGram = function (str) { return str.forEach(function (value) { return nGram[nextNGramIndex++] = value; }); };\n            for (var n = 0; n < leftPadding; ++n) {\n                appendToNGram(this_1.leftPad);\n                appendToNGram(this_1.separator);\n            }\n            // Only output first numTokens - 1 pairs of data and separator\n            for (var n = 0; n < numTokens - 1; ++n) {\n                appendToNGram(data[dataStartIndex + n]);\n                appendToNGram(this_1.separator);\n            }\n            // Handle case when there are no tokens or no right padding as these\n            // can result in consecutive separators.\n            if (numTokens > 0) {\n                // If we have tokens, then output last and then pair each separator\n                // with the right padding that follows, to ensure nGram ends either with\n                // the token or with the right pad.\n                appendToNGram(data[dataStartIndex + numTokens - 1]);\n                for (var n = 0; n < rightPadding; ++n) {\n                    appendToNGram(this_1.separator);\n                    appendToNGram(this_1.rightPad);\n                }\n            }\n            else {\n                // If we don't have tokens, then the last item inserted into the nGram\n                // has been the separator from the left padding loop above. Hence,\n                // output right pad and separator and make sure to finish with a\n                // padding, not a separator.\n                for (var n = 0; n < rightPadding - 1; ++n) {\n                    appendToNGram(this_1.rightPad);\n                    appendToNGram(this_1.separator);\n                }\n                appendToNGram(this_1.rightPad);\n            }\n        };\n        var this_1 = this;\n        for (var nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n            _loop_1(nGramIndex);\n        }\n    };\n    // Data and splits together form the definition of the ragged tensor,\n    // where data is 1 dimensional and contains the values of the tensor\n    // and splits denotes the indices at which each row starts.\n    StringNGramsOp.prototype.compute = function (data, splits) {\n        var _this = this;\n        // Validate that the splits are valid indices into data, only if there are\n        // splits specified.\n        var inputDataSize = data.length;\n        var splitsSize = splits.length;\n        if (splitsSize > 0) {\n            var prevSplit = splits[0];\n            if (prevSplit !== 0) {\n                throw new Error(\"First split value must be 0, got \" + prevSplit);\n            }\n            for (var i = 1; i < splitsSize; ++i) {\n                var validSplits = splits[i] >= prevSplit;\n                validSplits = validSplits && (splits[i] <= inputDataSize);\n                if (!validSplits) {\n                    throw new Error(\"Invalid split value \" + splits[i] + \", must be in [\" + prevSplit + \", \" + inputDataSize + \"]\");\n                }\n                prevSplit = splits[i];\n            }\n            if (prevSplit !== inputDataSize) {\n                throw new Error(\"Last split value must be data size. Expected \" + inputDataSize + \", got \" + prevSplit);\n            }\n        }\n        var numBatchItems = splitsSize - 1;\n        var nGramsSplits = tfjsCore.util.getArrayFromDType('int32', splitsSize);\n        // If there is no data or size, return an empty ragged tensor.\n        if (inputDataSize === 0 || splitsSize === 0) {\n            var empty = new Array(inputDataSize);\n            for (var i = 0; i <= numBatchItems; ++i) {\n                nGramsSplits[i] = 0;\n            }\n            return [empty, nGramsSplits];\n        }\n        nGramsSplits[0] = 0;\n        var _loop_2 = function (i) {\n            var length = splits[i] - splits[i - 1];\n            var numNGrams = 0;\n            this_2.nGramWidths.forEach(function (nGramWidth) {\n                numNGrams += _this.getNumNGrams(length, nGramWidth);\n            });\n            if (this_2.preserveShort && length > 0 && numNGrams === 0) {\n                numNGrams = 1;\n            }\n            nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n        };\n        var this_2 = this;\n        for (var i = 1; i <= numBatchItems; ++i) {\n            _loop_2(i);\n        }\n        var nGrams = new Array(nGramsSplits[numBatchItems]);\n        var _loop_3 = function (i) {\n            var splitIndex = splits[i];\n            var outputStartIdx = nGramsSplits[i];\n            this_3.nGramWidths.forEach(function (nGramWidth) {\n                var length = splits[i + 1] - splits[i];\n                var numNGrams = _this.getNumNGrams(length, nGramWidth);\n                _this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n                outputStartIdx += numNGrams;\n            });\n            // If we're preserving short sequences, check to see if no sequence was\n            // generated by comparing the current output start idx to the original\n            // one (nGramSplitsdata). If no ngrams were generated, then they will\n            // be equal (since we increment outputStartIdx by numNGrams every\n            // time we create a set of ngrams.)\n            if (this_3.preserveShort && outputStartIdx === nGramsSplits[i]) {\n                var dataLength = splits[i + 1] - splits[i];\n                // One legitimate reason to not have any ngrams when this.preserveShort\n                // is true is if the sequence itself is empty. In that case, move on.\n                if (dataLength === 0) {\n                    return \"continue\";\n                }\n                // We don't have to worry about dynamic padding sizes here: if padding\n                // was dynamic, every sequence would have had sufficient padding to\n                // generate at least one nGram.\n                var nGramWidth = dataLength + 2 * this_3.padWidth;\n                var numNGrams = 1;\n                this_3.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n            }\n        };\n        var this_3 = this;\n        for (var i = 0; i < numBatchItems; ++i) {\n            _loop_3(i);\n        }\n        return [nGrams, nGramsSplits];\n    };\n    return StringNGramsOp;\n}());\nfunction stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {\n    return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences)\n        .compute(data, dataSplits);\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction split(str, delimiters, skipEmpty, result) {\n    if (!str.length) {\n        return;\n    }\n    // When the delimiter is empty, the input is split into individual characters.\n    if (delimiters.length === 0) {\n        for (var i = 0; i < str.length; ++i) {\n            result.push(str.subarray(i, i + 1));\n        }\n        return;\n    }\n    // When there is one delimiter, the input is split only at that delimiter.\n    if (delimiters.length === 1) {\n        var delimiter = delimiters[0];\n        var f = str.indexOf(delimiter);\n        while (f !== -1) {\n            var token = str.subarray(0, f);\n            if (!skipEmpty || token.length !== 0) {\n                result.push(token);\n            }\n            str = str.subarray(f + 1);\n            f = str.indexOf(delimiter);\n        }\n        if (!skipEmpty || str.length !== 0) {\n            result.push(str);\n        }\n        return;\n    }\n    // When there are multiple delimiters, the input is split at every instance\n    // one of the delimiters appears.\n    var tokenStart = 0;\n    for (var i = 0; i < str.length + 1; i++) {\n        if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n            var token = str.subarray(tokenStart, i);\n            if (!skipEmpty || token.length !== 0) {\n                result.push(token);\n            }\n            tokenStart = i + 1;\n        }\n    }\n}\nfunction stringSplitImpl(input, delimiter, skipEmpty) {\n    var batchSize = input.length;\n    // Empty delimiter means split the input character by character.\n    var tokens = [];\n    var outputSize = 0;\n    var maxNumEntries = 0;\n    var numIndices = new Array(batchSize);\n    for (var i = 0; i < batchSize; ++i) {\n        var prevTokensLength = tokens.length;\n        split(input[i], delimiter, skipEmpty, tokens);\n        var nEntries = tokens.length - prevTokensLength;\n        numIndices[i] = nEntries;\n        outputSize += nEntries;\n        maxNumEntries = Math.max(maxNumEntries, nEntries);\n    }\n    var indices = tfjsCore.util.getArrayFromDType('int32', outputSize * 2);\n    var values = new Array(outputSize);\n    var shape = [batchSize, maxNumEntries];\n    var c = 0;\n    for (var i = 0; i < batchSize; ++i) {\n        for (var j = 0; j < numIndices[i]; ++j) {\n            // indices is a 2d tensor with shape of [outputSize, 2]\n            indices[c * 2] = i;\n            indices[c * 2 + 1] = j;\n            values[c] = tokens[c];\n            ++c;\n        }\n    }\n    return [indices, values, shape];\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction stringToHashBucketFastImpl(input, numBuckets) {\n    var output = tfjsCore.util.getArrayFromDType('int32', input.length);\n    for (var i = 0; i < input.length; ++i) {\n        output[i] =\n            tfjsCore.util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n    }\n    return output;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar subImpl = createSimpleBinaryKernelImpl((function (aValue, bValue) { return aValue - bValue; }));\nvar subComplexImpl = createComplexBinaryKernelImpl((function (aReal, aImag, bReal, bImag) {\n    return { real: aReal - bReal, imag: aImag - bImag };\n}));\nvar sub = binaryKernelFunc(tfjsCore.Sub, subImpl, subComplexImpl);\nvar subConfig = {\n    kernelName: tfjsCore.Sub,\n    backendName: 'cpu',\n    kernelFunc: sub\n};\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\nfunction tileImpl(xBuf, reps) {\n    var newShape = new Array(xBuf.rank);\n    for (var i = 0; i < newShape.length; i++) {\n        newShape[i] = xBuf.shape[i] * reps[i];\n    }\n    var result = tfjsCore.buffer(newShape, xBuf.dtype);\n    for (var i = 0; i < result.values.length; ++i) {\n        var newLoc = result.indexToLoc(i);\n        var originalLoc = new Array(xBuf.rank);\n        for (var j = 0; j < originalLoc.length; j++) {\n            originalLoc[j] = newLoc[j] % xBuf.shape[j];\n        }\n        var originalIndex = xBuf.locToIndex(originalLoc);\n        result.values[i] = xBuf.values[originalIndex];\n    }\n    return result;\n}\n\nvar comparePair = function (a, b) {\n    var valueDiff = b.value - a.value;\n    return valueDiff === 0 ? a.index - b.index : valueDiff;\n};\n/**\n * Partitions array where all elements smaller than the (k+1) smallest element\n * are found to the left of it, and all larger to the right of it.\n * Based on the Floyd-Rivest Algorithm, ref:\n * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm\n * @param array: Array to partition\n * @param left: Left index for the interval\n * @param right: Right index for the interval\n * @param k: Desired index value, where array[k] is the (k+1)th smallest element\n *           when left = 0\n */\nfunction select$1(array, k, left, right) {\n    if (left === void 0) { left = 0; }\n    if (right === void 0) { right = array.length - 1; }\n    while (right > left) {\n        // Use select recursively to sample a smaller set of size s\n        // the arbitrary constants 600 and 0.5 are used in the original\n        // version to minimize execution time.\n        if (right - left > 600) {\n            var n = right - left + 1;\n            var i_1 = k - left + 1;\n            var z = Math.log(n);\n            var s = 0.5 * Math.exp(2 * z / 3);\n            var sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i_1 - n / 2);\n            var newLeft = Math.max(left, Math.floor(k - i_1 * s / n + sd));\n            var newRight = Math.min(right, Math.floor(k + (n - i_1) * s / n + sd));\n            select$1(array, k, newLeft, newRight);\n        }\n        // partition the elements between left and right around t\n        var t = array[k];\n        var i = left;\n        var j = right;\n        tfjsCore.util.swap(array, left, k);\n        if (comparePair(array[right], t) > 0) {\n            tfjsCore.util.swap(array, left, right);\n        }\n        while (i < j) {\n            tfjsCore.util.swap(array, i, j);\n            i++;\n            j--;\n            while (comparePair(array[i], t) < 0) {\n                i = i + 1;\n            }\n            while (comparePair(array[j], t) > 0) {\n                j = j - 1;\n            }\n        }\n        if (comparePair(array[left], t) === 0) {\n            tfjsCore.util.swap(array, left, j);\n        }\n        else {\n            j = j + 1;\n            tfjsCore.util.swap(array, j, right);\n        }\n        // Adjust left and right towards the boundaries of the subset\n        // containing the (k - left + 1)th smallest element.\n        if (j <= k) {\n            left = j + 1;\n        }\n        if (k <= j) {\n            right = j - 1;\n        }\n    }\n}\nfunction topKImpl(x, xShape, xDtype, k, sorted) {\n    // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n    var lastDim = xShape[xShape.length - 1];\n    var _a = __read([x.length / lastDim, lastDim], 2), batch = _a[0], size = _a[1];\n    var allTopKVals = tfjsCore.util.getTypedArrayFromDType(xDtype, batch * k);\n    var allTopKIndices = tfjsCore.util.getTypedArrayFromDType('int32', batch * k);\n    var _loop_1 = function (b) {\n        var offset = b * size;\n        var vals = x.subarray(offset, offset + size);\n        var valAndInd = new Array(vals.length);\n        vals.forEach(function (value, index) { return valAndInd[index] = { value: value, index: index }; });\n        if (k < valAndInd.length) {\n            select$1(valAndInd, k);\n            valAndInd = valAndInd.slice(0, k);\n        }\n        if (sorted) {\n            valAndInd.sort(comparePair);\n        }\n        var outOffset = b * k;\n        var topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n        var topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n        for (var i = 0; i < k; i++) {\n            topKVals[i] = valAndInd[i].value;\n            topKIndices[i] = valAndInd[i].index;\n        }\n    };\n    for (var b = 0; b < batch; b++) {\n        _loop_1(b);\n    }\n    // Reshape back to the original input shape, except that the last\n    // dimension is k.\n    var outputShape = xShape.slice();\n    outputShape[outputShape.length - 1] = k;\n    return [\n        tfjsCore.buffer(outputShape, xDtype, allTopKVals),\n        tfjsCore.buffer(outputShape, 'int32', allTopKIndices)\n    ];\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction uniqueImpl(values, axis, shape, dtype) {\n    // Normalize and validate axis.\n    var $axis = tfjsCore.util.parseAxisParam(axis, shape)[0];\n    // Calculate the new shape that is suitable for extracting data along the\n    // given axis.\n    //\n    // The rank is 3.\n    // The size of the 1st dimension is the size of all the axes < the given axis.\n    // The size of the 2nd dimension is the same as the size of the given axis.\n    // The size of the 3rd dimension is the size of all the axes > the given axis.\n    //\n    // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n    // newShape would be: [2*3, 5, 4].\n    //\n    // Note that this is not the final output shape. This will be the shape for an\n    // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n    // values along the given axis. To demonstrate how it works, consider the\n    // following example:\n    //\n    // Input: a 3D tensor, with shape [1, 2, 3]\n    // [\n    //   [\n    //      [1,2,3],\n    //      [4,5,6]\n    //   ]\n    // ]\n    // Axis: 2 (the last axis).\n    // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n    //\n    // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n    // 1*2. The re-shaped data would look like:\n    //\n    // [\n    //   [\n    //     [1], [2], [3]\n    //   ],\n    //   [\n    //     [4], [5], [6]\n    //   ]\n    // ]\n    //\n    // Then, we can construct a 3-level nested loop by the following dimension\n    // order to extract the values along the axis (dimension1):\n    // i: dimension1       // 0,1,2 (newShape[1])\n    //   m: dimension0     // 0,1   (newShape[0])\n    //     n: dimension2   // 0     (newShape[2])\n    //\n    //                       m, i, n\n    //                      ---------\n    // Iteration 0: data at [0, 0, 0] => \"1\"\n    // Iteration 1: data at [1, 0, 0] => \"4\"\n    // We got [1,4].\n    // Iteration 2: data at [0, 1, 0] => \"2\"\n    // Iteration 3: data at [1, 1, 0] => \"5\"\n    // We got [2,5].\n    // Iteration 4: data at [0, 2, 0] => \"3\"\n    // Iteration 5: data at [1, 2, 0] => \"6\"\n    // We got [3,6].\n    var newShape = [1, shape[0], 1];\n    for (var i = 0; i < $axis; i++) {\n        newShape[0] *= shape[i];\n    }\n    newShape[1] = shape[$axis];\n    for (var i = $axis + 1; i < shape.length; i++) {\n        newShape[2] *= shape[i];\n    }\n    // A map from unique elements (their string representations) to their values\n    // in \"indices\" (below).\n    var uniqueElements = {};\n    // The indices of each unique element in the original tensor along the given\n    // axis. It is 1D and has the same size as the given axis.\n    var indices = new Int32Array(shape[$axis]);\n    // Create a buffer so we can easily extract value at a given location.\n    var inputBuffer = new tfjsCore.TensorBuffer(newShape, dtype, values);\n    // The indices along the given axis that have unique elements. This is a\n    // de-duped version of \"indices\" above.\n    var uniqueIndices = [];\n    var is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n    for (var i = 0; i < shape[$axis]; i++) {\n        // Extract values along the axis.\n        var element = void 0;\n        if (is1DTensor) {\n            // Fast path for 1D tensor input.\n            element = values[i].toString();\n        }\n        else {\n            var axisValues = [];\n            for (var m = 0; m < newShape[0]; m++) {\n                for (var n = 0; n < newShape[2]; n++) {\n                    axisValues.push(inputBuffer.get(m, i, n));\n                }\n            }\n            element = axisValues.join(',');\n        }\n        // Dedup and update various indices.\n        if (uniqueElements[element] !== undefined) {\n            indices[i] = uniqueElements[element];\n        }\n        else {\n            var uniqueIndex = Object.keys(uniqueElements).length;\n            uniqueElements[element] = uniqueIndex;\n            indices[i] = uniqueIndex;\n            uniqueIndices.push(i);\n        }\n    }\n    // Now we know where each of the unique elements are located along the axis\n    // (uniqueIndices). Extract them from input buffer and store them in the\n    // output buffer.\n    var outputTmpShape = newShape.slice();\n    outputTmpShape[1] = Object.keys(uniqueElements).length;\n    var outputBuffer = new tfjsCore.TensorBuffer(outputTmpShape, dtype);\n    uniqueIndices.forEach(function (uniqueElementIndex, i) {\n        for (var m = 0; m < newShape[0]; m++) {\n            for (var n = 0; n < newShape[2]; n++) {\n                outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n            }\n        }\n    });\n    // The output shape can be calculated from the input shape with the size of\n    // the given axis replaced by the number of unique elements along that axis.\n    var outputShape = shape.slice();\n    outputShape[$axis] = outputTmpShape[1];\n    return {\n        outputValues: outputBuffer.values,\n        outputShape: outputShape,\n        indices: indices,\n    };\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar shared = {\n    __proto__: null,\n    simpleAbsImpl: simpleAbsImpl,\n    addImpl: addImpl,\n    bincountImpl: bincountImpl,\n    bincountReduceImpl: bincountReduceImpl,\n    ceilImpl: ceilImpl,\n    concatImpl: concatImpl,\n    equalImpl: equalImpl,\n    expImpl: expImpl,\n    expm1Impl: expm1Impl,\n    floorImpl: floorImpl,\n    gatherNdImpl: gatherNdImpl,\n    gatherV2Impl: gatherV2Impl,\n    greaterImpl: greaterImpl,\n    greaterEqualImpl: greaterEqualImpl,\n    lessImpl: lessImpl,\n    lessEqualImpl: lessEqualImpl,\n    linSpaceImpl: linSpaceImpl,\n    logImpl: logImpl,\n    maxImpl: maxImpl,\n    maximumImpl: maximumImpl,\n    minimumImpl: minimumImpl,\n    multiplyImpl: multiplyImpl,\n    negImpl: negImpl,\n    notEqualImpl: notEqualImpl,\n    prodImpl: prodImpl,\n    rangeImpl: rangeImpl,\n    rsqrtImpl: rsqrtImpl,\n    sigmoidImpl: sigmoidImpl,\n    sliceImpl: sliceImpl,\n    sparseFillEmptyRowsImpl: sparseFillEmptyRowsImpl,\n    sparseReshapeImpl: sparseReshapeImpl,\n    sparseSegmentReductionImpl: sparseSegmentReductionImpl,\n    sqrtImpl: sqrtImpl,\n    squaredDifferenceImpl: squaredDifferenceImpl,\n    stridedSliceImpl: stridedSliceImpl,\n    stringNGramsImpl: stringNGramsImpl,\n    stringSplitImpl: stringSplitImpl,\n    stringToHashBucketFastImpl: stringToHashBucketFastImpl,\n    subImpl: subImpl,\n    tileImpl: tileImpl,\n    topKImpl: topKImpl,\n    transposeImpl: transposeImpl,\n    uniqueImpl: uniqueImpl\n};\n\n/** @license See the LICENSE file. */\n// This code is auto-generated, do not modify this file!\nvar version = '3.15.0';\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Side effects for default initialization of MathBackendCPU\ntfjsCore.registerBackend('cpu', function () { return new MathBackendCPU(); }, 1 /* priority */);\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar elu = unaryKernelFunc(tfjsCore.Elu, function (xi) { return xi >= 0 ? xi : (Math.exp(xi) - 1); });\nvar eluConfig = {\n    kernelName: tfjsCore.Elu,\n    backendName: 'cpu',\n    kernelFunc: elu,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction leakyRelu(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var alpha = attrs.alpha;\n    assertNotComplex([x], 'leakyRelu');\n    var xSize = tfjsCore.util.sizeFromShape(x.shape);\n    var xVals = backend.data.get(x.dataId).values;\n    var outVals = tfjsCore.util.getTypedArrayFromDType('float32', xSize);\n    for (var i = 0; i < xVals.length; i++) {\n        outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];\n    }\n    return backend.makeTensorInfo(x.shape, 'float32', outVals);\n}\nvar leakyReluConfig = {\n    kernelName: tfjsCore.LeakyRelu,\n    backendName: 'cpu',\n    kernelFunc: leakyRelu\n};\n\nvar preluImpl = createSimpleBinaryKernelImpl(function (xValue, aValue) { return xValue < 0 ? aValue * xValue : xValue; });\nfunction prelu(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x, alpha = inputs.alpha;\n    assertNotComplex([x, alpha], 'prelu');\n    var aVals = backend.data.get(x.dataId).values;\n    var bVals = backend.data.get(alpha.dataId).values;\n    var _a = __read(preluImpl(x.shape, alpha.shape, aVals, bVals, 'float32'), 2), resultData = _a[0], resultShape = _a[1];\n    return backend.makeTensorInfo(resultShape, 'float32', resultData);\n}\nvar preluConfig = {\n    kernelName: tfjsCore.Prelu,\n    backendName: 'cpu',\n    kernelFunc: prelu,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar relu = unaryKernelFunc(tfjsCore.Relu, function (xi) { return Math.max(0, xi); });\nvar reluConfig = {\n    kernelName: tfjsCore.Relu,\n    backendName: 'cpu',\n    kernelFunc: relu,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar relu6 = unaryKernelFunc(tfjsCore.Relu6, function (xi) { return Math.min(Math.max(0, xi), 6); });\nvar relu6Config = {\n    kernelName: tfjsCore.Relu6,\n    backendName: 'cpu',\n    kernelFunc: relu6,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction applyActivation(backend, x, activation, preluActivationWeights, leakyreluAlpha) {\n    if (activation === 'linear') {\n        return identity({ inputs: { x: x }, backend: backend });\n    }\n    else if (activation === 'relu') {\n        return relu({ inputs: { x: x }, backend: backend });\n    }\n    else if (activation === 'elu') {\n        return elu({ inputs: { x: x }, backend: backend });\n    }\n    else if (activation === 'relu6') {\n        return relu6({ inputs: { x: x }, backend: backend });\n    }\n    else if (activation === 'prelu') {\n        return prelu({ inputs: { x: x, alpha: preluActivationWeights }, backend: backend });\n    }\n    else if (activation === 'leakyrelu') {\n        return leakyRelu({ inputs: { x: x }, backend: backend, attrs: { alpha: leakyreluAlpha } });\n    }\n    else if (activation === 'sigmoid') {\n        return sigmoid({ inputs: { x: x }, backend: backend });\n    }\n    throw new Error(\"Activation \" + activation + \" has not been implemented for the CPU backend.\");\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction reshape(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var shape = attrs.shape;\n    var xSize = tfjsCore.util.sizeFromShape(x.shape);\n    var $shape = tfjsCore.util.inferFromImplicitShape(shape, xSize);\n    var $xSize = tfjsCore.util.sizeFromShape($shape);\n    tfjsCore.util.assert(xSize === $xSize, function () { return \"The new shape (\" + $shape + \") has \" + $xSize + \" elements and the old \" +\n        (\"shape (\" + x.shape + \") has \" + xSize + \" elements. The new shape and old \") +\n        \"shape must have the same number of elements.\"; });\n    backend.incRef(x.dataId);\n    var xData = backend.data.get(x.dataId);\n    if (xData.complexTensorInfos != null) {\n        var real = xData.complexTensorInfos.real;\n        var imag = xData.complexTensorInfos.imag;\n        real.shape = $shape;\n        imag.shape = $shape;\n    }\n    return { dataId: x.dataId, shape: $shape, dtype: x.dtype };\n}\nvar reshapeConfig = {\n    kernelName: tfjsCore.Reshape,\n    backendName: 'cpu',\n    kernelFunc: reshape\n};\n\nfunction batchMatMul(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var a = inputs.a, b = inputs.b;\n    var transposeA = attrs.transposeA, transposeB = attrs.transposeB;\n    assertNotComplex([a, b], 'matMul');\n    var aRank = a.shape.length;\n    var bRank = b.shape.length;\n    var innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n    var innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n    var outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n    var outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n    var outerDimsA = a.shape.slice(0, -2);\n    var outerDimsB = b.shape.slice(0, -2);\n    var batchDimA = tfjsCore.util.sizeFromShape(outerDimsA);\n    var batchDimB = tfjsCore.util.sizeFromShape(outerDimsB);\n    var outShapeOuterDims = tfjsCore.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));\n    var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n    tfjsCore.util.assert(innerShapeA === innerShapeB, function () { return \"Error in matMul: inner shapes (\" + innerShapeA + \") and (\" +\n        (innerShapeB + \") of Tensors with shapes \" + a.shape + \" and \") +\n        (b.shape + \" and transposeA=\" + transposeA) +\n        (\" and transposeB=\" + transposeB + \" must match.\"); });\n    var a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n        [batchDimA, outerShapeA, innerShapeA];\n    var b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n        [batchDimB, innerShapeB, outerShapeB];\n    // The rest of the implementation is designed to operate on rank-3 tensors\n    var a3d = reshape({ inputs: { x: a }, backend: backend, attrs: { shape: a3dShape } });\n    var b3d = reshape({ inputs: { x: b }, backend: backend, attrs: { shape: b3dShape } });\n    var sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n    var leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n    var rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n    var batchDim = Math.max(batchDimA, batchDimB);\n    var a3dValues = backend.data.get(a3d.dataId).values;\n    var b3dValues = backend.data.get(b3d.dataId).values;\n    var a3dStrides = tfjsCore.util.computeStrides(a3d.shape);\n    var b3dStrides = tfjsCore.util.computeStrides(b3d.shape);\n    var _a = __read(transposeA ?\n        [a3dStrides[0], 1, a3dStrides[1]] :\n        [a3dStrides[0], a3dStrides[1], 1], 3), aBatch = _a[0], aOuterStep = _a[1], aInnerStep = _a[2];\n    var _b = __read(transposeB ?\n        [1, b3dStrides[1], b3dStrides[0]] :\n        [b3dStrides[1], 1, b3dStrides[0]], 3), bInnerStep = _b[0], bOuterStep = _b[1], bBatch = _b[2];\n    var size = leftDim * rightDim;\n    var result = tfjsCore.buffer([batchDim, leftDim, rightDim], a3d.dtype);\n    var resVals = result.values;\n    var blockSize = backend.blockSize;\n    for (var bi = 0; bi < batchDim; bi++) {\n        for (var i0 = 0; i0 < leftDim; i0 += blockSize) {\n            for (var j0 = 0; j0 < rightDim; j0 += blockSize) {\n                for (var k0 = 0; k0 < sharedDim; k0 += blockSize) {\n                    // for when blockSize doesn't evenly divide the input\n                    var iBlock = Math.min(i0 + blockSize, leftDim);\n                    var jBlock = Math.min(j0 + blockSize, rightDim);\n                    var kBlock = Math.min(k0 + blockSize, sharedDim);\n                    for (var i = i0; i < iBlock; i++) {\n                        for (var j = j0; j < jBlock; j++) {\n                            var sum = 0.0;\n                            for (var k = k0; k < kBlock; k++) {\n                                var batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                                var batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                                var aVal = a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                                var bVal = b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                                sum += aVal * bVal;\n                            }\n                            resVals[bi * size + (i * rightDim + j)] += sum;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    backend.disposeIntermediateTensorInfo(a3d);\n    backend.disposeIntermediateTensorInfo(b3d);\n    // set correct shape on output.\n    return backend.makeTensorInfo(outShape, result.dtype, result.values);\n}\nvar batchMatMulConfig = {\n    kernelName: tfjsCore.BatchMatMul,\n    backendName: 'cpu',\n    kernelFunc: batchMatMul,\n};\n\nfunction _fusedMatMul(args) {\n    var e_1, _a;\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var a = inputs.a, b = inputs.b, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;\n    var transposeA = attrs.transposeA, transposeB = attrs.transposeB, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;\n    var current;\n    var addRes;\n    var activationRes;\n    var intermediates = [];\n    var matMulRes = batchMatMul({ inputs: { a: a, b: b }, attrs: { transposeA: transposeA, transposeB: transposeB }, backend: backend });\n    current = matMulRes;\n    if (bias) {\n        addRes = add({ inputs: { a: current, b: bias }, backend: backend });\n        intermediates.push(current);\n        current = addRes;\n    }\n    if (activation) {\n        activationRes = applyActivation(backend, current, activation, preluActivationWeights, leakyreluAlpha);\n        intermediates.push(current);\n        current = activationRes;\n    }\n    try {\n        for (var intermediates_1 = __values(intermediates), intermediates_1_1 = intermediates_1.next(); !intermediates_1_1.done; intermediates_1_1 = intermediates_1.next()) {\n            var i = intermediates_1_1.value;\n            backend.disposeIntermediateTensorInfo(i);\n        }\n    }\n    catch (e_1_1) { e_1 = { error: e_1_1 }; }\n    finally {\n        try {\n            if (intermediates_1_1 && !intermediates_1_1.done && (_a = intermediates_1.return)) _a.call(intermediates_1);\n        }\n        finally { if (e_1) throw e_1.error; }\n    }\n    return current;\n}\nvar _fusedMatMulConfig = {\n    kernelName: tfjsCore._FusedMatMul,\n    backendName: 'cpu',\n    kernelFunc: _fusedMatMul,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar acos = unaryKernelFunc(tfjsCore.Acos, function (xi) { return Math.acos(xi); });\nvar acosConfig = {\n    kernelName: tfjsCore.Acos,\n    backendName: 'cpu',\n    kernelFunc: acos,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar acosh = unaryKernelFunc(tfjsCore.Acosh, function (xi) { return Math.acosh(xi); });\nvar acoshConfig = {\n    kernelName: tfjsCore.Acosh,\n    backendName: 'cpu',\n    kernelFunc: acosh,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction addN(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var tensors = inputs;\n    assertNotComplex(inputs, 'addN');\n    var vals = tensors.map(function (t) { return backend.data.get(t.dataId).values; });\n    var outBuf = tfjsCore.buffer(tensors[0].shape, tensors[0].dtype);\n    var outVals = outBuf.values;\n    for (var i = 0; i < tensors.length; i++) {\n        var currVals = vals[i];\n        for (var j = 0; j < outVals.length; j++) {\n            outVals[j] += currVals[j];\n        }\n    }\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\nvar addNConfig = {\n    kernelName: tfjsCore.AddN,\n    backendName: 'cpu',\n    kernelFunc: addN\n};\n\nfunction all(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    assertNotComplex(x, 'all');\n    var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var axes = origAxes;\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);\n    var $x = x;\n    if (permutedAxes != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutedAxes } });\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);\n    }\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('all', axes, $x.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a[0], reduceShape = _a[1];\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);\n    var aVals = backend.data.get($x.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var all_1 = aVals[offset];\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            all_1 = all_1 && value;\n        }\n        vals[i] = all_1;\n    }\n    if (permutedAxes != null) {\n        backend.disposeIntermediateTensorInfo($x);\n    }\n    var result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n    if (keepDims) {\n        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);\n        var reshapedResult = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: expandedShape } });\n        backend.disposeIntermediateTensorInfo(result);\n        return reshapedResult;\n    }\n    return result;\n}\nvar allConfig = {\n    kernelName: tfjsCore.All,\n    backendName: 'cpu',\n    kernelFunc: all\n};\n\nfunction any(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    assertNotComplex(x, 'any');\n    var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var axes = origAxes;\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);\n    var $x = x;\n    if (permutedAxes != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutedAxes } });\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);\n    }\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('any', axes, $x.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a[0], reduceShape = _a[1];\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);\n    var aVals = backend.data.get($x.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var anyVal = aVals[offset];\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            anyVal = anyVal || value;\n        }\n        vals[i] = anyVal;\n    }\n    if (permutedAxes != null) {\n        backend.disposeIntermediateTensorInfo($x);\n    }\n    var result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n    if (keepDims) {\n        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);\n        var reshapedResult = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: expandedShape } });\n        backend.disposeIntermediateTensorInfo(result);\n        return reshapedResult;\n    }\n    return result;\n}\nvar anyConfig = {\n    kernelName: tfjsCore.Any,\n    backendName: 'cpu',\n    kernelFunc: any\n};\n\nfunction argMax(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis;\n    assertNotComplex(x, 'argMax');\n    var axes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);\n    var $x = x;\n    var intermediateTensorInfos = [];\n    if (permutedAxes != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutedAxes } });\n        intermediateTensorInfos.push($x);\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n    }\n    axes = [axes[0]];\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a[0], reduceShape = _a[1];\n    var outSize = tfjsCore.util.sizeFromShape(outShape);\n    var vals = tfjsCore.util.makeZerosTypedArray(outSize, 'int32');\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var aVals = backend.data.get($x.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var max = aVals[offset];\n        var maxIndex = 0;\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            if (value > max) {\n                max = value;\n                maxIndex = j;\n            }\n        }\n        vals[i] = maxIndex;\n    }\n    intermediateTensorInfos.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return backend.makeTensorInfo(outShape, 'int32', vals);\n}\nvar argMaxConfig = {\n    kernelName: tfjsCore.ArgMax,\n    backendName: 'cpu',\n    kernelFunc: argMax\n};\n\nfunction argMin(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis;\n    assertNotComplex(x, 'argMin');\n    var axes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);\n    var $x = x;\n    var intermediateTensorInfos = [];\n    if (permutedAxes != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutedAxes } });\n        intermediateTensorInfos.push($x);\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n    }\n    axes = [axes[0]];\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('argMin', axes, $x.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a[0], reduceShape = _a[1];\n    var outSize = tfjsCore.util.sizeFromShape(outShape);\n    var vals = tfjsCore.util.makeZerosTypedArray(outSize, 'int32');\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var aVals = backend.data.get($x.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var min = aVals[offset];\n        var minIndex = 0;\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            if (value < min) {\n                min = value;\n                minIndex = j;\n            }\n        }\n        vals[i] = minIndex;\n    }\n    intermediateTensorInfos.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return backend.makeTensorInfo(outShape, 'int32', vals);\n}\nvar argMinConfig = {\n    kernelName: tfjsCore.ArgMin,\n    backendName: 'cpu',\n    kernelFunc: argMin\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar asin = unaryKernelFunc(tfjsCore.Asin, function (xi) { return Math.asin(xi); });\nvar asinConfig = {\n    kernelName: tfjsCore.Asin,\n    backendName: 'cpu',\n    kernelFunc: asin,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar asinh = unaryKernelFunc(tfjsCore.Asinh, function (xi) { return Math.asinh(xi); });\nvar asinhConfig = {\n    kernelName: tfjsCore.Asinh,\n    backendName: 'cpu',\n    kernelFunc: asinh,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar atan = unaryKernelFunc(tfjsCore.Atan, function (xi) { return Math.atan(xi); });\nvar atanConfig = {\n    kernelName: tfjsCore.Atan,\n    backendName: 'cpu',\n    kernelFunc: atan,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar atan2Impl = createSimpleBinaryKernelImpl(function (aValue, bValue) { return Math.atan2(aValue, bValue); });\nvar atan2 = binaryKernelFunc(tfjsCore.Atan2, atan2Impl);\nvar atan2Config = {\n    kernelName: tfjsCore.Atan2,\n    backendName: 'cpu',\n    kernelFunc: atan2,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar atanh = unaryKernelFunc(tfjsCore.Atanh, function (xi) { return Math.atanh(xi); });\nvar atanhConfig = {\n    kernelName: tfjsCore.Atanh,\n    backendName: 'cpu',\n    kernelFunc: atanh,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction pool(xValues, xShape, dtype, strides, convInfo, poolType) {\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n    var initialValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n        Number.POSITIVE_INFINITY);\n    var output = tfjsCore.buffer(convInfo.outShape, dtype);\n    var outputVals = output.values;\n    var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n    var outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n    var outputColStrides = convInfo.outShape[3];\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        var outputBatchOffset = b * outputBatchStrides;\n        var inputBatchOffset = b * strides[0];\n        for (var d = 0; d < convInfo.inChannels; ++d) {\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var xRCorner = yR * strideHeight - padTop;\n                var xRMin = Math.max(0, xRCorner);\n                var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                var outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n                for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                    var xCCorner = yC * strideWidth - padLeft;\n                    var xCMin = Math.max(0, xCCorner);\n                    var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                    var minMaxValue = initialValue;\n                    var avgValue = 0;\n                    var count = 0;\n                    for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                        var xROffset = inputBatchOffset + xR * strides[1];\n                        for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                            var xCOffset = xROffset + xC * strides[2];\n                            var pixel = xValues[xCOffset + d];\n                            if ((poolType === 'max' && pixel > minMaxValue)) {\n                                minMaxValue = pixel;\n                            }\n                            else if (poolType === 'avg') {\n                                avgValue += pixel;\n                                count++;\n                            }\n                        }\n                        if (isNaN(minMaxValue)) {\n                            break;\n                        }\n                    }\n                    var outputOffset = outputRowOffset + yC * outputColStrides + d;\n                    outputVals[outputOffset] =\n                        poolType === 'avg' ? avgValue / count : minMaxValue;\n                }\n            }\n        }\n    }\n    return output;\n}\nfunction maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions, includeBatchInIndex) {\n    if (flattenPositions === void 0) { flattenPositions = false; }\n    if (includeBatchInIndex === void 0) { includeBatchInIndex = false; }\n    var maxPositions = tfjsCore.buffer(convInfo.outShape, 'int32');\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n    var xBuf = tfjsCore.buffer(xShape, dtype, xValues);\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        for (var d = 0; d < convInfo.inChannels; ++d) {\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var xRCorner = yR * strideHeight - padTop;\n                var xRMin = xRCorner;\n                while (xRMin < 0) {\n                    xRMin += dilationHeight;\n                }\n                // const xRMin = Math.max(0, xRCorner);\n                var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                    var xCCorner = yC * strideWidth - padLeft;\n                    var xCMin = xCCorner;\n                    while (xCMin < 0) {\n                        xCMin += dilationWidth;\n                    }\n                    var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                    var maxValue = Number.NEGATIVE_INFINITY;\n                    var maxPosition = -1;\n                    for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                        var wR = xR - xRCorner;\n                        for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                            var wC = xC - xCCorner;\n                            var pixel = xBuf.get(b, xR, xC, d);\n                            if (pixel > maxValue) {\n                                maxValue = pixel;\n                                if (flattenPositions) {\n                                    maxPosition = includeBatchInIndex ?\n                                        ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                                            convInfo.inChannels +\n                                            d :\n                                        (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                                }\n                                else {\n                                    maxPosition = wR * effectiveFilterWidth + wC;\n                                }\n                            }\n                        }\n                    }\n                    maxPositions.set(maxPosition, b, yR, yC, d);\n                }\n            }\n        }\n    }\n    return maxPositions;\n}\nfunction pool3d(xValues, xShape, dtype, strides, convInfo, poolType) {\n    var strideDepth = convInfo.strideDepth;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationDepth = convInfo.dilationDepth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padFront = convInfo.padInfo.front;\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n    var initialValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n        Number.POSITIVE_INFINITY);\n    var output = tfjsCore.buffer(convInfo.outShape, dtype);\n    var outputVals = output.values;\n    var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    var outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    var outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    var outputColStrides = convInfo.outShape[4];\n    for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n        var outputBatchOffset = batch * outputBatchStrides;\n        var inputBatchOffset = batch * strides[0];\n        for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n            for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n                var xDepthCorner = yDepth * strideDepth - padFront;\n                var xDepthMin = xDepthCorner;\n                while (xDepthMin < 0) {\n                    xDepthMin += dilationDepth;\n                }\n                var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n                var outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;\n                for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n                    var xRowCorner = yRow * strideHeight - padTop;\n                    var xRowMin = xRowCorner;\n                    while (xRowMin < 0) {\n                        xRowMin += dilationHeight;\n                    }\n                    var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n                    var outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n                    for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n                        var xColCorner = yCol * strideWidth - padLeft;\n                        var xColMin = xColCorner;\n                        while (xColMin < 0) {\n                            xColMin += dilationWidth;\n                        }\n                        var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n                        // Shader code begins\n                        var outputColOffset = outputRowOffset + yCol * outputColStrides;\n                        var minMaxValue = initialValue;\n                        var avgValue = 0;\n                        var count = 0;\n                        for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {\n                            var xDepthOffset = inputBatchOffset + xDepth * strides[1];\n                            for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                                var xRowOffset = xDepthOffset + xRow * strides[2];\n                                for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {\n                                    var xColOffset = xRowOffset + xCol * strides[3];\n                                    var pixel = xValues[xColOffset + channel];\n                                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                                        minMaxValue = pixel;\n                                    }\n                                    else if (poolType === 'avg') {\n                                        avgValue += pixel;\n                                        count++;\n                                    }\n                                    if (isNaN(minMaxValue)) {\n                                        break;\n                                    }\n                                }\n                                if (isNaN(minMaxValue)) {\n                                    break;\n                                }\n                            }\n                            if (isNaN(minMaxValue)) {\n                                break;\n                            }\n                        }\n                        var outputOffset = outputColOffset + channel;\n                        outputVals[outputOffset] =\n                            poolType === 'avg' ? avgValue / count : minMaxValue;\n                    }\n                }\n            }\n        }\n    }\n    return output;\n}\nfunction maxPool3dPositions(xBuf, convInfo) {\n    var maxPositions = tfjsCore.buffer(convInfo.outShape, 'int32');\n    var strideDepth = convInfo.strideDepth;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationDepth = convInfo.dilationDepth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padFront = convInfo.padInfo.front;\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n    for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n        for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n            for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n                var xDepthCorner = yDepth * strideDepth - padFront;\n                var xDepthMin = xDepthCorner;\n                while (xDepthMin < 0) {\n                    xDepthMin += dilationDepth;\n                }\n                var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n                for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n                    var xRowCorner = yRow * strideHeight - padTop;\n                    var xRowMin = xRowCorner;\n                    while (xRowMin < 0) {\n                        xRowMin += dilationHeight;\n                    }\n                    var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n                    for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n                        var xColCorner = yCol * strideWidth - padLeft;\n                        var xColMin = xColCorner;\n                        while (xColMin < 0) {\n                            xColMin += dilationWidth;\n                        }\n                        var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n                        // Shader code begins\n                        var maxValue = Number.NEGATIVE_INFINITY;\n                        var maxPosition = -1;\n                        for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {\n                            var wDepth = xDepth - xDepthCorner;\n                            for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                                var wRow = xRow - xRowCorner;\n                                for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {\n                                    var wCol = xCol - xColCorner;\n                                    var pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                                    if (pixel >= maxValue) {\n                                        maxValue = pixel;\n                                        maxPosition =\n                                            wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                                                wRow * effectiveFilterHeight + wCol;\n                                    }\n                                }\n                            }\n                        }\n                        maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n                    }\n                }\n            }\n        }\n    }\n    return maxPositions;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction avgPool(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    assertNotComplex(x, 'avgPool');\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;\n    var dilations = 1;\n    tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in avgPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res;\n    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n        tfjsCore.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n        res = identity({ inputs: { x: x }, backend: backend });\n    }\n    else {\n        var xValues = backend.data.get(x.dataId).values;\n        var strides_1 = tfjsCore.util.computeStrides(x.shape);\n        var buffer = pool(xValues, x.shape, x.dtype, strides_1, convInfo, 'avg');\n        res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer.values);\n    }\n    return res;\n}\nvar avgPoolConfig = {\n    kernelName: tfjsCore.AvgPool,\n    backendName: 'cpu',\n    kernelFunc: avgPool\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction avgPool3D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;\n    assertNotComplex(x, 'avgPool3d');\n    var convInfo = tfjsCore.backend_util.computePool3DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode, dataFormat);\n    var xValues = backend.data.get(x.dataId).values;\n    var outBuf = pool3d(xValues, x.shape, x.dtype, tfjsCore.util.computeStrides(x.shape), convInfo, 'avg');\n    return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\nvar avgPool3DConfig = {\n    kernelName: tfjsCore.AvgPool3D,\n    backendName: 'cpu',\n    kernelFunc: avgPool3D\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction avgPool3DGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, input = inputs.input;\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;\n    assertNotComplex([dy, input], 'avgPool3DGrad');\n    var convInfo = tfjsCore.backend_util.computePool3DInfo(input.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n    var strideDepth = convInfo.strideDepth;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterDepth = convInfo.filterDepth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dilationDepth = convInfo.dilationDepth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    var dx = tfjsCore.buffer(input.shape, 'float32');\n    var avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n    var dyBuf = backend.bufferSync(dy);\n    for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n        for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n            for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n                for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n                    for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n                        // Shader code begins.\n                        var dyDepthCorner = dxDepth - padFront;\n                        var dyRowCorner = dxRow - padTop;\n                        var dyColCorner = dxCol - padLeft;\n                        var dotProd = 0;\n                        for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {\n                            var dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                            if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                                Math.floor(dyDepth) !== dyDepth) {\n                                continue;\n                            }\n                            for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {\n                                var dyRow = (dyRowCorner + wRow) / strideHeight;\n                                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                                    Math.floor(dyRow) !== dyRow) {\n                                    continue;\n                                }\n                                for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {\n                                    var dyCol = (dyColCorner + wCol) / strideWidth;\n                                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                                        Math.floor(dyCol) !== dyCol) {\n                                        continue;\n                                    }\n                                    var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                    dotProd += pixel;\n                                }\n                            }\n                        }\n                        dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar avgPool3DGradConfig = {\n    kernelName: tfjsCore.AvgPool3DGrad,\n    backendName: 'cpu',\n    kernelFunc: avgPool3DGrad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction avgPoolGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, input = inputs.input;\n    var x = input;\n    assertNotComplex([dy, input], 'avgPoolGrad');\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad;\n    var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad);\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    var dx = tfjsCore.buffer(x.shape, 'float32');\n    var avgMultiplier = 1 / (filterHeight * filterWidth);\n    var dyData = backend.data.get(dy.dataId).values;\n    var dyBuf = tfjsCore.buffer(dy.shape, 'float32', dyData);\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        for (var d = 0; d < convInfo.inChannels; ++d) {\n            for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                    // Shader code begins.\n                    var dyRCorner = dxR - padTop;\n                    var dyCCorner = dxC - padLeft;\n                    var dotProd = 0;\n                    for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                        var dyR = (dyRCorner + wR) / strideHeight;\n                        if (dyR < 0 || dyR >= convInfo.outHeight ||\n                            Math.floor(dyR) !== dyR) {\n                            continue;\n                        }\n                        for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                            var dyC = (dyCCorner + wC) / strideWidth;\n                            if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                Math.floor(dyC) !== dyC) {\n                                continue;\n                            }\n                            var pixel = dyBuf.get(b, dyR, dyC, d);\n                            dotProd += pixel;\n                        }\n                    }\n                    dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar avgPoolGradConfig = {\n    kernelName: tfjsCore.AvgPoolGrad,\n    backendName: 'cpu',\n    kernelFunc: avgPoolGrad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction batchNorm(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, scale = inputs.scale, offset = inputs.offset, mean = inputs.mean, variance = inputs.variance;\n    tfjsCore.util.assert(mean.shape.length === variance.shape.length, function () { return 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.'; });\n    tfjsCore.util.assert(offset == null || mean.shape.length === offset.shape.length, function () { return 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.'; });\n    tfjsCore.util.assert(scale == null || mean.shape.length === scale.shape.length, function () { return 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.'; });\n    assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n    var varianceEpsilon = attrs.varianceEpsilon;\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    var xVals = backend.data.get(x.dataId).values;\n    var mVals = backend.data.get(mean.dataId).values;\n    var varVals = backend.data.get(variance.dataId).values;\n    var sVals = scale ? backend.data.get(scale.dataId).values :\n        new Float32Array([1]);\n    var offVals = offset ?\n        backend.data.get(offset.dataId).values :\n        new Float32Array([0]);\n    var outVals = new Float32Array(xVals.length);\n    var offValsLength = offVals.length;\n    var sValsLength = sVals.length;\n    var varValsLength = varVals.length;\n    var mValsLength = mVals.length;\n    var offi = 0;\n    var mi = 0;\n    var si = 0;\n    var vi = 0;\n    for (var i = 0; i < xVals.length; ++i) {\n        outVals[i] = offVals[offi++] +\n            (xVals[i] - mVals[mi++]) * sVals[si++] /\n                Math.sqrt(varVals[vi++] + varianceEpsilon);\n        if (offi >= offValsLength) {\n            offi = 0;\n        }\n        if (mi >= mValsLength) {\n            mi = 0;\n        }\n        if (si >= sValsLength) {\n            si = 0;\n        }\n        if (vi >= varValsLength) {\n            vi = 0;\n        }\n    }\n    return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\nvar batchNormConfig = {\n    kernelName: tfjsCore.FusedBatchNorm,\n    backendName: 'cpu',\n    kernelFunc: batchNorm,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction batchToSpaceND(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var blockShape = attrs.blockShape, crops = attrs.crops;\n    assertNotComplex([x], 'batchToSpaceND');\n    var prod = blockShape.reduce(function (a, b) { return a * b; });\n    var reshaped = tfjsCore.backend_util.getReshaped(x.shape, blockShape, prod);\n    var permuted = tfjsCore.backend_util.getPermuted(reshaped.length, blockShape.length);\n    var reshapedPermuted = tfjsCore.backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    var sliceBeginCoords = tfjsCore.backend_util.getSliceBeginCoords(crops, blockShape.length);\n    var sliceSize = tfjsCore.backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n    var xReshaped = reshape({ inputs: { x: x }, backend: backend, attrs: { shape: reshaped } });\n    var xTransposed = transpose({ inputs: { x: xReshaped }, backend: backend, attrs: { perm: permuted } });\n    var xTransposedReshaped = reshape({ inputs: { x: xTransposed }, backend: backend, attrs: { shape: reshapedPermuted } });\n    var result = slice({\n        inputs: { x: xTransposedReshaped },\n        backend: backend,\n        attrs: { begin: sliceBeginCoords, size: sliceSize }\n    });\n    backend.disposeIntermediateTensorInfo(xReshaped);\n    backend.disposeIntermediateTensorInfo(xTransposed);\n    backend.disposeIntermediateTensorInfo(xTransposedReshaped);\n    return result;\n}\nvar batchToSpaceNDConfig = {\n    kernelName: tfjsCore.BatchToSpaceND,\n    backendName: 'cpu',\n    kernelFunc: batchToSpaceND\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction bincount(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, weights = inputs.weights;\n    var size = attrs.size;\n    var xVals = backend.data.get(x.dataId).values;\n    var weightsVals = backend.data.get(weights.dataId).values;\n    var outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n    return backend.makeTensorInfo([size], weights.dtype, outVals);\n}\nvar bincountConfig = {\n    kernelName: tfjsCore.Bincount,\n    backendName: 'cpu',\n    kernelFunc: bincount\n};\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction broadcastArgs(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var s0 = inputs.s0, s1 = inputs.s1;\n    var s0Vals = backend.data.get(s0.dataId).values;\n    var s1Vals = backend.data.get(s1.dataId).values;\n    var broadcastShape = tfjsCore.backend_util.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));\n    return backend.makeTensorInfo([broadcastShape.length], 'int32', Int32Array.from(broadcastShape));\n}\nvar broadcastArgsConfig = {\n    kernelName: tfjsCore.BroadcastArgs,\n    backendName: 'cpu',\n    kernelFunc: broadcastArgs\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar clipByValue = unaryKernelFunc(tfjsCore.ClipByValue, function (xi, attrs) {\n    var clipAttrs = attrs;\n    if (xi > clipAttrs.clipValueMax) {\n        return clipAttrs.clipValueMax;\n    }\n    return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\nvar clipByValueConfig = {\n    kernelName: tfjsCore.ClipByValue,\n    backendName: 'cpu',\n    kernelFunc: clipByValue,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar complexAbs = function (args) {\n    var x = args.inputs.x;\n    var cpuBackend = args.backend;\n    var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(x.shape));\n    var complexVals = cpuBackend.data.get(x.dataId);\n    var real = complexVals.complexTensorInfos.real;\n    var imag = complexVals.complexTensorInfos.imag;\n    var realVals = cpuBackend.data.get(real.dataId).values;\n    var imagVals = cpuBackend.data.get(imag.dataId).values;\n    for (var i = 0; i < realVals.length; i++) {\n        var real_1 = realVals[i];\n        var imag_1 = imagVals[i];\n        resultValues[i] = Math.hypot(real_1, imag_1);\n    }\n    return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n};\nvar complexAbsConfig = {\n    kernelName: tfjsCore.ComplexAbs,\n    backendName: 'cpu',\n    kernelFunc: complexAbs,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction imag(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var input = inputs.input;\n    var imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n    var imagVal = backend.data.get(imag.dataId).values;\n    // When complex tensor is disposed, its underlying parts will be disposed too.\n    // Make new tensor out of the imag value of the complex. This makes sure the\n    // value is still accessible even if complex tensor is disposed.\n    return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\nvar imagConfig = {\n    kernelName: tfjsCore.Imag,\n    backendName: 'cpu',\n    kernelFunc: imag\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction concat(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var axis = attrs.axis;\n    var $axis = tfjsCore.util.parseAxisParam(axis, inputs[0].shape)[0];\n    var outShape = tfjsCore.backend_util.computeOutShape(inputs.map(function (t) { return t.shape; }), $axis);\n    if (tfjsCore.util.sizeFromShape(outShape) === 0) {\n        return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    var $inputs = inputs.filter(function (t) { return tfjsCore.util.sizeFromShape(t.shape) > 0; });\n    if ($inputs.length === 1) {\n        return identity({ inputs: { x: $inputs[0] }, backend: backend });\n    }\n    var shapes = $inputs.map(function (t) { return t.shape; });\n    tfjsCore.backend_util.assertParamsConsistent(shapes, $axis);\n    if ($inputs[0].dtype === 'complex64') {\n        var reals = $inputs.map(function (t) { return real({ inputs: { input: t }, backend: backend }); });\n        var imags = $inputs.map(function (t) { return imag({ inputs: { input: t }, backend: backend }); });\n        var realConcated = concat({ inputs: reals, backend: backend, attrs: { axis: $axis } });\n        var imagConcated = concat({ inputs: imags, backend: backend, attrs: { axis: $axis } });\n        var result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend: backend });\n        reals.forEach(function (r) { return backend.disposeIntermediateTensorInfo(r); });\n        imags.forEach(function (i) { return backend.disposeIntermediateTensorInfo(i); });\n        backend.disposeIntermediateTensorInfo(realConcated);\n        backend.disposeIntermediateTensorInfo(imagConcated);\n        return result;\n    }\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    var inputs2D = $inputs.map(function (t) {\n        var innerSize = tfjsCore.util.sizeFromShape(t.shape.slice($axis));\n        var shape = [-1, innerSize];\n        return reshape({ inputs: { x: t }, backend: backend, attrs: { shape: shape } });\n    });\n    var inputsValShapes = inputs2D.map(function (t) {\n        return { vals: backend.data.get(t.dataId).values, shape: t.shape };\n    });\n    // Concats 2d tensors along axis=1.\n    outShape =\n        tfjsCore.backend_util.computeOutShape(inputs2D.map(function (t) { return t.shape; }), 1 /* axis */);\n    var simplyConcat = inputs2D[0].shape[0] === 1;\n    var outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n    var finalOutShape = tfjsCore.backend_util.computeOutShape($inputs.map(function (t) { return t.shape; }), $axis);\n    var outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n    inputs2D.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return outInfo;\n}\nvar concatConfig = {\n    kernelName: tfjsCore.Concat,\n    backendName: 'cpu',\n    kernelFunc: concat\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction conv2D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, filter = inputs.filter;\n    var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;\n    assertNotComplex([x, filter], 'conv2d');\n    var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var padLeft = convInfo.padInfo.left;\n    var padTop = convInfo.padInfo.top;\n    var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    var xBatchStride = xStrides[0];\n    var xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];\n    var xColStride = isChannelsLast ? xStrides[2] : 1;\n    var xChannelStride = isChannelsLast ? 1 : xStrides[1];\n    var yBatchStride = y.strides[0];\n    var yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n    var yColStride = isChannelsLast ? y.strides[2] : 1;\n    var yChannelStride = isChannelsLast ? 1 : y.strides[1];\n    var xVals = backend.data.get(x.dataId).values;\n    var wVals = backend.data.get(filter.dataId).values;\n    var yVals = y.values;\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        var xOffset1 = b * xBatchStride;\n        var yOffset1 = b * yBatchStride;\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n            var yOffset2 = yOffset1 + yR * yRowStride;\n            var xRCorner = yR * convInfo.strideHeight - padTop;\n            for (var wR = 0; wR < filterHeight; ++wR) {\n                var xR = xRCorner + wR * dilationHeight;\n                if (xR < 0 || xR >= convInfo.inHeight) {\n                    continue;\n                }\n                var wOffset1 = wR * filterStrides[0];\n                var xOffset2 = xOffset1 + xR * xRowStride;\n                for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                    var yOffset3 = yOffset2 + yC * yColStride;\n                    var xCCorner = yC * convInfo.strideWidth - padLeft;\n                    for (var wC = 0; wC < filterWidth; ++wC) {\n                        var xC = xCCorner + wC * dilationWidth;\n                        if (xC < 0 || xC >= convInfo.inWidth) {\n                            continue;\n                        }\n                        var wOffset2 = wOffset1 + wC * filterStrides[1];\n                        var xOffset3 = xOffset2 + xC * xColStride;\n                        var wOffset3 = wOffset2;\n                        for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                            var xVal = xVals[xOffset3 + d1 * xChannelStride];\n                            for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                yVals[yOffset3 + d2 * yChannelStride] +=\n                                    xVal * wVals[wOffset3 + d2];\n                            }\n                            wOffset3 += convInfo.outChannels;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(y.shape, y.dtype, yVals);\n}\nvar conv2DConfig = {\n    kernelName: tfjsCore.Conv2D,\n    backendName: 'cpu',\n    kernelFunc: conv2D\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction conv2DBackpropFilter(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, dy = inputs.dy;\n    var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;\n    assertNotComplex([x, dy], 'conv2dBackpropFilter');\n    var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filterShape, strides, 1 /* dilations */, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n    var strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth;\n    var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    var dW = new tfjsCore.TensorBuffer(convInfo.filterShape, 'float32');\n    var leftPad = convInfo.padInfo.left;\n    var topPad = convInfo.padInfo.top;\n    var xVals = backend.data.get(x.dataId).values;\n    var dyVals = backend.data.get(dy.dataId).values;\n    var xBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype, xVals);\n    var dyBuf = new tfjsCore.TensorBuffer(dy.shape, dy.dtype, dyVals);\n    for (var wR = 0; wR < filterHeight; ++wR) {\n        var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n        for (var wC = 0; wC < filterWidth; ++wC) {\n            var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n            var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    var dotProd = 0;\n                    for (var b = 0; b < convInfo.batchSize; ++b) {\n                        for (var yR = yRMin; yR < yRMax; ++yR) {\n                            var xR = wR + yR * strideHeight - topPad;\n                            for (var yC = yCMin; yC < yCMax; ++yC) {\n                                var xC = wC + yC * strideWidth - leftPad;\n                                if (isChannelsLast) {\n                                    dotProd += xBuf.get(b, xR, xC, d1) *\n                                        dyBuf.get(b, yR, yC, d2);\n                                }\n                                else {\n                                    dotProd += xBuf.get(b, d1, xR, xC) *\n                                        dyBuf.get(b, d2, yR, yC);\n                                }\n                            }\n                        }\n                    }\n                    dW.set(dotProd, wR, wC, d1, d2);\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\nvar conv2DBackpropFilterConfig = {\n    kernelName: tfjsCore.Conv2DBackpropFilter,\n    backendName: 'cpu',\n    kernelFunc: conv2DBackpropFilter\n};\n\nfunction conv2DBackpropInput(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, filter = inputs.filter;\n    var inputShape = attrs.inputShape, strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode;\n    assertNotComplex([dy, filter], 'conv2dBackpropInput');\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    var dyStrides = tfjsCore.util.computeStrides(dy.shape);\n    var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, 1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n    var dx = new tfjsCore.TensorBuffer(convInfo.inShape, 'float32');\n    var dxValues = dx.values;\n    var dyValues = backend.data.get(dy.dataId).values;\n    var fltValues = backend.data.get(filter.dataId).values;\n    var _a = __read(filterStrides, 3), fltS0 = _a[0], fltS1 = _a[1], fltS2 = _a[2];\n    var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n    $dataFormat = convInfo.dataFormat;\n    var topPad = filterHeight - 1 - convInfo.padInfo.top;\n    var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    var isChannelsLast = $dataFormat === 'channelsLast';\n    var xBatchStride = dx.strides[0];\n    var xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n    var xColStride = isChannelsLast ? dx.strides[2] : 1;\n    var xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n    var yBatchStride = dyStrides[0];\n    var yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n    var yColStride = isChannelsLast ? dyStrides[2] : 1;\n    var yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n    for (var b = 0; b < batchSize; ++b) {\n        for (var d1 = 0; d1 < inChannels; ++d1) {\n            for (var xR = 0; xR < inHeight; ++xR) {\n                var xRCorner = xR - topPad;\n                var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                for (var xC = 0; xC < inWidth; ++xC) {\n                    var xCCorner = xC - leftPad;\n                    var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                    var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                    var dotProd = 0;\n                    for (var yR = xRMin; yR < yRMax; ++yR) {\n                        var wR = yR * strideHeight - xRCorner;\n                        for (var yC = xCMin; yC < yCMax; ++yC) {\n                            var wC = yC * strideWidth - xCCorner;\n                            var dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;\n                            var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                            for (var d2 = 0; d2 < outChannels; ++d2) {\n                                var pixel = dyValues[dyOffset + yChannelStride * d2];\n                                var weight = fltValues[fltOffset + d2];\n                                dotProd += pixel * weight;\n                            }\n                        }\n                    }\n                    var dxOffset = xBatchStride * b + xRowStride * xR +\n                        xColStride * xC + xChannelStride * d1;\n                    dxValues[dxOffset] = dotProd;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar conv2DBackpropInputConfig = {\n    kernelName: tfjsCore.Conv2DBackpropInput,\n    backendName: 'cpu',\n    kernelFunc: conv2DBackpropInput\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction conv3D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, filter = inputs.filter;\n    var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;\n    assertNotComplex([x, filter], 'conv3d');\n    var convInfo = tfjsCore.backend_util.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad);\n    var filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, dilationDepth = convInfo.dilationDepth, dilationHeight = convInfo.dilationHeight, dilationWidth = convInfo.dilationWidth, padInfo = convInfo.padInfo;\n    var padFront = padInfo.front;\n    var padLeft = padInfo.left;\n    var padTop = padInfo.top;\n    var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);\n    var xVals = backend.data.get(x.dataId).values;\n    var wVals = backend.data.get(filter.dataId).values;\n    var yVals = y.values;\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        var xOffset1 = b * xStrides[0];\n        var yOffset1 = b * y.strides[0];\n        for (var yF = 0; yF < convInfo.outDepth; ++yF) {\n            var yOffset2 = yOffset1 + yF * y.strides[1];\n            var xFCorner = yF * convInfo.strideDepth - padFront;\n            for (var wF = 0; wF < filterDepth; ++wF) {\n                var xF = xFCorner + wF * dilationDepth;\n                if (xF < 0 || xF >= convInfo.inDepth) {\n                    continue;\n                }\n                var wOffset1 = wF * filterStrides[0];\n                var xOffset2 = xOffset1 + xF * xStrides[1];\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var yOffset3 = yOffset2 + yR * y.strides[2];\n                    var xRCorner = yR * convInfo.strideHeight - padTop;\n                    for (var wR = 0; wR < filterHeight; ++wR) {\n                        var xR = xRCorner + wR * dilationHeight;\n                        if (xR < 0 || xR >= convInfo.inHeight) {\n                            continue;\n                        }\n                        var wOffset2 = wOffset1 + wR * filterStrides[1];\n                        var xOffset3 = xOffset2 + xR * xStrides[2];\n                        for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                            var yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                            var xCCorner = yC * convInfo.strideWidth - padLeft;\n                            for (var wC = 0; wC < filterWidth; ++wC) {\n                                var xC = xCCorner + wC * dilationWidth;\n                                if (xC < 0 || xC >= convInfo.inWidth) {\n                                    continue;\n                                }\n                                var wOffset3 = wOffset2 + wC * filterStrides[2];\n                                var xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                                var wOffset4 = wOffset3;\n                                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                    var xVal = xVals[xOffset4 + d1];\n                                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                        yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                                    }\n                                    wOffset4 += convInfo.outChannels;\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\nvar conv3DConfig = {\n    kernelName: tfjsCore.Conv3D,\n    backendName: 'cpu',\n    kernelFunc: conv3D\n};\n\nfunction conv3DBackpropFilterV2(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, dy = inputs.dy;\n    var strides = attrs.strides, pad = attrs.pad, filterShape = attrs.filterShape;\n    assertNotComplex([x, dy], 'conv3dBackpropFilterV2');\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var dyStrides = tfjsCore.util.computeStrides(dy.shape);\n    var convInfo = tfjsCore.backend_util.computeConv3DInfo(x.shape, filterShape, strides, 1 /* dilations */, pad);\n    var strideDepth = convInfo.strideDepth;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterDepth = convInfo.filterDepth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dw = new tfjsCore.TensorBuffer(convInfo.filterShape, 'float32');\n    var dwValues = dw.values;\n    var _a = __read(dw.strides, 4), dwS0 = _a[0], dwS1 = _a[1], dwS2 = _a[2], dwS3 = _a[3];\n    var dyValues = backend.data.get(dy.dataId).values;\n    var _b = __read(dyStrides, 4), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n    var xValues = backend.data.get(x.dataId).values;\n    var _c = __read(xStrides, 4), xS0 = _c[0], xS1 = _c[1], xS2 = _c[2], xS3 = _c[3];\n    var frontPad = convInfo.padInfo.front;\n    var leftPad = convInfo.padInfo.left;\n    var topPad = convInfo.padInfo.top;\n    for (var wF = 0; wF < filterDepth; ++wF) {\n        var yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n        var yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n        var wOffset1 = wF * dwS0;\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            var wOffset2 = wR * dwS1 + wOffset1;\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                var wOffset3 = wC * dwS2 + wOffset2;\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    var wOffset4 = d1 * dwS3 + wOffset3;\n                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                        var dotProd = 0;\n                        for (var b = 0; b < convInfo.batchSize; ++b) {\n                            var xOffset1 = b * xS0;\n                            var yOffset1 = b * dyS0;\n                            for (var yF = yFMin; yF < yFMax; ++yF) {\n                                var xF = wF + yF * strideDepth - frontPad;\n                                var xOffset2 = xF * xS1 + xOffset1;\n                                var yOffset2 = yF * dyS1 + yOffset1;\n                                for (var yR = yRMin; yR < yRMax; ++yR) {\n                                    var xR = wR + yR * strideHeight - topPad;\n                                    var xOffset3 = xR * xS2 + xOffset2;\n                                    var yOffset3 = yR * dyS2 + yOffset2;\n                                    for (var yC = yCMin; yC < yCMax; ++yC) {\n                                        var xC = wC + yC * strideWidth - leftPad;\n                                        var xOffset4 = xC * xS3 + xOffset3;\n                                        var yOffset4 = yC * dyS3 + yOffset3;\n                                        dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                                    }\n                                }\n                            }\n                        }\n                        dwValues[wOffset4 + d2] = dotProd;\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);\n}\nvar conv3DBackpropFilterV2Config = {\n    kernelName: tfjsCore.Conv3DBackpropFilterV2,\n    backendName: 'cpu',\n    kernelFunc: conv3DBackpropFilterV2\n};\n\nfunction conv3DBackpropInputV2(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, filter = inputs.filter;\n    var pad = attrs.pad, strides = attrs.strides, inputShape = attrs.inputShape;\n    assertNotComplex([dy], 'conv3dBackpropInputV2');\n    var dyStrides = tfjsCore.util.computeStrides(dy.shape);\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    var convInfo = tfjsCore.backend_util.computeConv3DInfo(inputShape, filter.shape, strides, 1 /* dilations */, pad);\n    var dx = new tfjsCore.TensorBuffer(convInfo.inShape, 'float32');\n    var dxValues = dx.values;\n    var _a = __read(dx.strides, 4), dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2], dxS3 = _a[3];\n    var dyValues = backend.data.get(dy.dataId).values;\n    var _b = __read(dyStrides, 4), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n    var fltValues = backend.data.get(filter.dataId).values;\n    var _c = __read(filterStrides, 4), fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2], fltS3 = _c[3];\n    var batchSize = convInfo.batchSize, filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inDepth = convInfo.inDepth, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outDepth = convInfo.outDepth, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideDepth = convInfo.strideDepth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n    var frontPad = filterDepth - 1 - convInfo.padInfo.front;\n    var topPad = filterHeight - 1 - convInfo.padInfo.top;\n    var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    for (var b = 0; b < batchSize; ++b) {\n        for (var d1 = 0; d1 < inChannels; ++d1) {\n            // Frames of depth\n            for (var xF = 0; xF < inDepth; ++xF) {\n                var xFCorner = xF - frontPad;\n                var xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n                var yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n                // Rows as per standard 2d matrix notation\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - topPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    // Columns as per standard 2d matrix notation\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - leftPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yF = xFMin; yF < yFMax; ++yF) {\n                            var wF = yF * strideDepth - xFCorner;\n                            for (var yR = xRMin; yR < yRMax; ++yR) {\n                                var wR = yR * strideHeight - xRCorner;\n                                for (var yC = xCMin; yC < yCMax; ++yC) {\n                                    var wC = yC * strideWidth - xCCorner;\n                                    var dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                                    var fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                                        fltS1 * (filterHeight - 1 - wR) +\n                                        fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n                                    for (var d2 = 0; d2 < outChannels; ++d2) {\n                                        var pixel = dyValues[dyOffset + d2];\n                                        var weight = fltValues[fltOffset + d2];\n                                        dotProd += pixel * weight;\n                                    }\n                                }\n                            }\n                        }\n                        dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                            dotProd;\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar conv3DBackpropInputV2Config = {\n    kernelName: tfjsCore.Conv3DBackpropInputV2,\n    backendName: 'cpu',\n    kernelFunc: conv3DBackpropInputV2\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar cos = unaryKernelFunc(tfjsCore.Cos, function (xi) { return Math.cos(xi); });\nvar cosConfig = {\n    kernelName: tfjsCore.Cos,\n    backendName: 'cpu',\n    kernelFunc: cos,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar cosh = unaryKernelFunc(tfjsCore.Cosh, function (xi) { return Math.cosh(xi); });\nvar coshConfig = {\n    kernelName: tfjsCore.Cosh,\n    backendName: 'cpu',\n    kernelFunc: cosh,\n};\n\nfunction cropAndResize(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var image = inputs.image, boxes = inputs.boxes, boxInd = inputs.boxInd;\n    var cropSize = attrs.cropSize, method = attrs.method, extrapolationValue = attrs.extrapolationValue;\n    var _a = __read(image.shape, 4), batch = _a[0], imageHeight = _a[1], imageWidth = _a[2], numChannels = _a[3];\n    var numBoxes = boxes.shape[0];\n    var _b = __read(cropSize, 2), cropHeight = _b[0], cropWidth = _b[1];\n    var output = tfjsCore.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n    var boxVals = backend.data.get(boxes.dataId).values;\n    var boxIndVals = backend.data.get(boxInd.dataId).values;\n    var imageVals = backend.data.get(image.dataId).values;\n    var inStride = tfjsCore.util.computeStrides(image.shape); // to calculate flat indexes into image\n    var outStride = tfjsCore.util.computeStrides(output.shape); // to calculate flat indexes into output\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (var b = 0; b < numBoxes; b++) {\n        var startInd = b * 4;\n        var y1 = boxVals[startInd];\n        var x1 = boxVals[startInd + 1];\n        var y2 = boxVals[startInd + 2];\n        var x2 = boxVals[startInd + 3];\n        var bInd = boxIndVals[b];\n        if (bInd >= batch) {\n            continue;\n        }\n        var heightScale = (cropHeight > 1) ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;\n        var widthScale = (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n        for (var y = 0; y < cropHeight; y++) {\n            var yInd = (cropHeight > 1) ?\n                y1 * (imageHeight - 1) + y * (heightScale) :\n                0.5 * (y1 + y2) * (imageHeight - 1);\n            if (yInd < 0 || yInd > imageHeight - 1) {\n                for (var x = 0; x < cropWidth; x++) {\n                    for (var c = 0; c < numChannels; c++) {\n                        var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                        output.values[ind] = extrapolationValue;\n                    }\n                }\n                continue;\n            }\n            if (method === 'bilinear') {\n                var topInd = Math.floor(yInd);\n                var bottomInd = Math.ceil(yInd);\n                var yLerp = yInd - topInd;\n                for (var x = 0; x < cropWidth; x++) {\n                    var xInd = (cropWidth > 1) ?\n                        x1 * (imageWidth - 1) + x * widthScale :\n                        0.5 * (x1 + x2) * (imageWidth - 1);\n                    if (xInd < 0 || xInd > imageWidth - 1) {\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = extrapolationValue;\n                        }\n                        continue;\n                    }\n                    var leftInd = Math.floor(xInd);\n                    var rightInd = Math.ceil(xInd);\n                    var xLerp = xInd - leftInd;\n                    for (var c = 0; c < numChannels; c++) {\n                        var ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                            bInd * inStride[0];\n                        var topLeft = imageVals[ind];\n                        ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                            bInd * inStride[0];\n                        var topRight = imageVals[ind];\n                        ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                            bInd * inStride[0];\n                        var bottomLeft = imageVals[ind];\n                        ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                            bInd * inStride[0];\n                        var bottomRight = imageVals[ind];\n                        var top = topLeft + (topRight - topLeft) * xLerp;\n                        var bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n                        ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                        output.values[ind] = top + ((bottom - top) * yLerp);\n                    }\n                }\n            }\n            else { // method == \"nearest\"\n                for (var x = 0; x < cropWidth; ++x) {\n                    var xInd = (cropWidth > 1) ?\n                        x1 * (imageWidth - 1) + x * widthScale :\n                        0.5 * (x1 + x2) * (imageWidth - 1);\n                    if (xInd < 0 || xInd > imageWidth - 1) {\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = extrapolationValue;\n                        }\n                        continue;\n                    }\n                    var closestX = Math.round(xInd);\n                    var closestY = Math.round(yInd);\n                    for (var c = 0; c < numChannels; c++) {\n                        var inInd = c + closestX * inStride[2] + closestY * inStride[1] +\n                            bInd * inStride[0];\n                        var outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                        output.values[outInd] = imageVals[inInd];\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(output.shape, output.dtype, output.values);\n}\nvar cropAndResizeConfig = {\n    kernelName: tfjsCore.CropAndResize,\n    backendName: 'cpu',\n    kernelFunc: cropAndResize\n};\n\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction cumprod(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, exclusive = attrs.exclusive, reverse = attrs.reverse;\n    assertNotComplex(x, 'cumprod');\n    var permutation = tfjsCore.backend_util.getAxesPermutation([axis], x.shape.length);\n    var $x = x;\n    if (permutation != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutation } });\n    }\n    var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, x.shape.length)[0];\n    if (permutedAxis !== $x.shape.length - 1) {\n        throw new Error(\"backend.cumprod in CPU expects an inner-most \" +\n            (\"axis=\" + ($x.shape.length - 1) + \" but got axis=\" + permutedAxis));\n    }\n    var resultDtype = tfjsCore.upcastType($x.dtype, 'int32');\n    var vals = tfjsCore.util.makeOnesTypedArray(tfjsCore.util.sizeFromShape($x.shape), resultDtype);\n    var aVals = backend.data.get($x.dataId).values;\n    var finalDim = $x.shape[$x.shape.length - 1];\n    var indexAdjuster = reverse ?\n        function (i, j) { return i + finalDim - j - 1; } :\n        function (i, j) { return i + j; };\n    for (var i = 0; i < aVals.length; i += finalDim) {\n        for (var j = 0; j < finalDim; j++) {\n            var idx = indexAdjuster(i, j);\n            if (j === 0) {\n                vals[idx] = exclusive ? 1 : aVals[idx];\n            }\n            else {\n                var prevIdx = indexAdjuster(i, j - 1);\n                vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] :\n                    aVals[idx] * vals[prevIdx];\n            }\n        }\n    }\n    var result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n    if (permutation != null) {\n        var reversePermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);\n        var reverseTransposedResult = transpose({ inputs: { x: result }, backend: backend, attrs: { perm: reversePermutation } });\n        backend.disposeIntermediateTensorInfo(result);\n        backend.disposeIntermediateTensorInfo($x);\n        return reverseTransposedResult;\n    }\n    return result;\n}\nvar cumprodConfig = {\n    kernelName: tfjsCore.Cumprod,\n    backendName: 'cpu',\n    kernelFunc: cumprod\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction cumsum(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, exclusive = attrs.exclusive, reverse = attrs.reverse;\n    assertNotComplex(x, 'cumsum');\n    var permutation = tfjsCore.backend_util.getAxesPermutation([axis], x.shape.length);\n    var $x = x;\n    if (permutation != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutation } });\n    }\n    var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, x.shape.length)[0];\n    if (permutedAxis !== $x.shape.length - 1) {\n        throw new Error(\"backend.cumsum in CPU expects an inner-most \" +\n            (\"axis=\" + ($x.shape.length - 1) + \" but got axis=\" + permutedAxis));\n    }\n    var resultDtype = tfjsCore.upcastType($x.dtype, 'int32');\n    var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape($x.shape), resultDtype);\n    var aVals = backend.data.get($x.dataId).values;\n    var finalDim = $x.shape[$x.shape.length - 1];\n    var indexAdjuster = reverse ?\n        function (i, j) { return i + finalDim - j - 1; } :\n        function (i, j) { return i + j; };\n    for (var i = 0; i < aVals.length; i += finalDim) {\n        for (var j = 0; j < finalDim; j++) {\n            var idx = indexAdjuster(i, j);\n            if (j === 0) {\n                vals[idx] = exclusive ? 0 : aVals[idx];\n            }\n            else {\n                var prevIdx = indexAdjuster(i, j - 1);\n                vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                    aVals[idx] + vals[prevIdx];\n            }\n        }\n    }\n    var result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n    if (permutation != null) {\n        var reversePermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);\n        var reverseTransposedResult = transpose({ inputs: { x: result }, backend: backend, attrs: { perm: reversePermutation } });\n        backend.disposeIntermediateTensorInfo(result);\n        backend.disposeIntermediateTensorInfo($x);\n        return reverseTransposedResult;\n    }\n    return result;\n}\nvar cumsumConfig = {\n    kernelName: tfjsCore.Cumsum,\n    backendName: 'cpu',\n    kernelFunc: cumsum\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction denseBincount(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, weights = inputs.weights;\n    var size = attrs.size, binaryOutput = attrs.binaryOutput;\n    if (x.shape.length === 1) {\n        var xVals = backend.data.get(x.dataId).values;\n        var weightsVals = backend.data.get(weights.dataId).values;\n        var outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n        return backend.makeTensorInfo([size], weights.dtype, outVals);\n    }\n    else if (x.shape.length === 2) {\n        var xBuf = backend.bufferSync(x);\n        var weightsBuf = backend.bufferSync(weights);\n        var outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);\n        return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);\n    }\n    throw new Error(\"Error in denseBincount: input must be at most rank 2, but got rank\" +\n        (x.shape.length + \".\"));\n}\nvar denseBincountConfig = {\n    kernelName: tfjsCore.DenseBincount,\n    backendName: 'cpu',\n    kernelFunc: denseBincount\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction depthToSpace(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var blockSize = attrs.blockSize, dataFormat = attrs.dataFormat;\n    tfjsCore.util.assert(dataFormat === 'NHWC', function () { return \"Only NHWC dataFormat supported on CPU for depthToSpace. Got \" + dataFormat; });\n    var batchSize = x.shape[0];\n    var inputHeight = x.shape[1];\n    var inputWidth = x.shape[2];\n    var inputDepth = x.shape[3];\n    var outputHeight = inputHeight * blockSize;\n    var outputWidth = inputWidth * blockSize;\n    var outputDepth = inputDepth / (blockSize * blockSize);\n    var xValues = backend.data.get(x.dataId).values;\n    var result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n    var outputIdx = 0;\n    for (var b = 0; b < batchSize; ++b) {\n        for (var h = 0; h < outputHeight; ++h) {\n            var inH = Math.floor(h / blockSize);\n            var offsetH = (h % blockSize);\n            for (var w = 0; w < outputWidth; ++w) {\n                var inW = Math.floor(w / blockSize);\n                var offsetW = (w % blockSize);\n                var offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n                for (var d = 0; d < outputDepth; ++d) {\n                    var inD = d + offsetD;\n                    var inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n                    result[outputIdx++] = xValues[inputIdx];\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);\n}\nvar depthToSpaceConfig = {\n    kernelName: tfjsCore.DepthToSpace,\n    backendName: 'cpu',\n    kernelFunc: depthToSpace\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction depthwiseConv2dNative(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, filter = inputs.filter;\n    var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;\n    assertNotComplex([x, filter], 'depthwiseConv2DNative');\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    var $dilations = dilations;\n    if ($dilations == null) {\n        $dilations = [1, 1];\n    }\n    tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), function () { return 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n        (\"1. Got strides \" + strides + \" and dilations '\" + $dilations + \"'\"); });\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */);\n    var filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, dilationHeight = convInfo.dilationHeight, dilationWidth = convInfo.dilationWidth, padInfo = convInfo.padInfo;\n    var padLeft = padInfo.left;\n    var padTop = padInfo.top;\n    var chMul = convInfo.outChannels / convInfo.inChannels;\n    var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);\n    var xVals = backend.data.get(x.dataId).values;\n    var wVals = backend.data.get(filter.dataId).values;\n    var yVals = y.values;\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        var xOffset1 = b * xStrides[0];\n        var yOffset1 = b * y.strides[0];\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n            var yOffset2 = yOffset1 + yR * y.strides[1];\n            var xRCorner = yR * convInfo.strideHeight - padTop;\n            for (var wR = 0; wR < filterHeight; ++wR) {\n                var xR = xRCorner + wR * dilationHeight;\n                if (xR < 0 || xR >= convInfo.inHeight) {\n                    continue;\n                }\n                var wOffset1 = wR * filterStrides[0];\n                var xOffset2 = xOffset1 + xR * xStrides[1];\n                for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                    var yOffset3 = yOffset2 + yC * y.strides[2];\n                    var xCCorner = yC * convInfo.strideWidth - padLeft;\n                    for (var wC = 0; wC < filterWidth; ++wC) {\n                        var xC = xCCorner + wC * dilationWidth;\n                        if (xC < 0 || xC >= convInfo.inWidth) {\n                            continue;\n                        }\n                        var wOffset2 = wOffset1 + wC * filterStrides[1];\n                        var xOffset3 = xOffset2 + xC * convInfo.inChannels;\n                        var yOffset4 = yOffset3;\n                        var wOffset3 = wOffset2;\n                        for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                            var xVal = xVals[xOffset3 + d1];\n                            for (var q = 0; q < chMul; ++q) {\n                                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                            }\n                            yOffset4 += chMul;\n                            wOffset3 += chMul;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\nvar depthwiseConv2dNativeConfig = {\n    kernelName: tfjsCore.DepthwiseConv2dNative,\n    backendName: 'cpu',\n    kernelFunc: depthwiseConv2dNative\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction depthwiseConv2dNativeBackpropFilter(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, dy = inputs.dy;\n    var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;\n    assertNotComplex([x, dy], 'depthwiseConv2dNativeBackpropFilter');\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    var strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth;\n    var dW = new tfjsCore.TensorBuffer(convInfo.filterShape, 'float32');\n    var leftPad = convInfo.padInfo.left;\n    var topPad = convInfo.padInfo.top;\n    var chMul = convInfo.outChannels / convInfo.inChannels;\n    var xVals = backend.data.get(x.dataId).values;\n    var xBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype, xVals);\n    var dyVals = backend.data.get(dy.dataId).values;\n    var dyBuf = new tfjsCore.TensorBuffer(dy.shape, dy.dtype, dyVals);\n    for (var wR = 0; wR < filterHeight; ++wR) {\n        var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n        for (var wC = 0; wC < filterWidth; ++wC) {\n            var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n            var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n            for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                var d1 = Math.trunc(d2 / chMul);\n                var dm = d2 % chMul;\n                var dotProd = 0;\n                for (var b = 0; b < convInfo.batchSize; ++b) {\n                    for (var yR = yRMin; yR < yRMax; ++yR) {\n                        var xR = wR + yR * strideHeight - topPad;\n                        for (var yC = yCMin; yC < yCMax; ++yC) {\n                            var xC = wC + yC * strideWidth - leftPad;\n                            dotProd += xBuf.get(b, xR, xC, d1) *\n                                dyBuf.get(b, yR, yC, d2);\n                        }\n                    }\n                }\n                dW.set(dotProd, wR, wC, d1, dm);\n            }\n        }\n    }\n    return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\nvar depthwiseConv2dNativeBackpropFilterConfig = {\n    kernelName: tfjsCore.DepthwiseConv2dNativeBackpropFilter,\n    backendName: 'cpu',\n    kernelFunc: depthwiseConv2dNativeBackpropFilter\n};\n\nfunction depthwiseConv2dNativeBackpropInput(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, filter = inputs.filter;\n    var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, inputShape = attrs.inputShape;\n    assertNotComplex([dy, filter], 'depthwiseConv2DNativeBackpropInput');\n    var dyStrides = tfjsCore.util.computeStrides(dy.shape);\n    var filterStrides = tfjsCore.util.computeStrides(filter.shape);\n    var convInfo = tfjsCore.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    var dx = new tfjsCore.TensorBuffer(convInfo.inShape, 'float32');\n    var dxValues = dx.values;\n    var _a = __read(dx.strides, 3), dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2];\n    var dyValues = backend.data.get(dy.dataId).values;\n    var _b = __read(dyStrides, 3), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];\n    var fltValues = backend.data.get(filter.dataId).values;\n    var _c = __read(filterStrides, 3), fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];\n    var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n    var topPad = filterHeight - 1 - convInfo.padInfo.top;\n    var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    var chMul = outChannels / inChannels;\n    for (var b = 0; b < batchSize; ++b) {\n        for (var d1 = 0; d1 < inChannels; ++d1) {\n            for (var xR = 0; xR < inHeight; ++xR) {\n                var xRCorner = xR - topPad;\n                var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                for (var xC = 0; xC < inWidth; ++xC) {\n                    var xCCorner = xC - leftPad;\n                    var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                    var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                    var dotProd = 0;\n                    for (var yR = xRMin; yR < yRMax; ++yR) {\n                        var wR = yR * strideHeight - xRCorner;\n                        for (var yC = xCMin; yC < yCMax; ++yC) {\n                            var wC = yC * strideWidth - xCCorner;\n                            var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                            var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                            for (var dm = 0; dm < chMul; ++dm) {\n                                var d2 = d1 * chMul + dm;\n                                var pixel = dyValues[dyOffset + d2];\n                                var weight = fltValues[fltOffset + dm];\n                                dotProd += pixel * weight;\n                            }\n                        }\n                    }\n                    dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar depthwiseConv2dNativeBackpropInputConfig = {\n    kernelName: tfjsCore.DepthwiseConv2dNativeBackpropInput,\n    backendName: 'cpu',\n    kernelFunc: depthwiseConv2dNativeBackpropInput\n};\n\nfunction diag(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x;\n    var xSize = tfjsCore.util.sizeFromShape(x.shape);\n    var xVals = backend.data.get(x.dataId).values;\n    var outBuf = tfjsCore.buffer([xSize, xSize], x.dtype);\n    var vals = outBuf.values;\n    for (var i = 0; i < xVals.length; i++) {\n        vals[i * xSize + i] = xVals[i];\n    }\n    var outShape = __spread(x.shape, x.shape);\n    return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);\n}\nvar diagConfig = {\n    kernelName: tfjsCore.Diag,\n    backendName: 'cpu',\n    kernelFunc: diag\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar dilation2DConfig = {\n    kernelName: tfjsCore.Dilation2D,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend, attrs = _a.attrs;\n        var x = inputs.x, filter = inputs.filter;\n        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;\n        var cpuBackend = backend;\n        var xVals = cpuBackend.data.get(x.dataId).values;\n        var xRank = x.shape.length;\n        var filterVals = cpuBackend.data.get(filter.dataId).values;\n        var filterRank = filter.shape.length;\n        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;\n        var outSize = tfjsCore.util.sizeFromShape(outShape);\n        var outRank = outShape.length;\n        var outputVals = tfjsCore.util.getArrayFromDType(x.dtype, outSize);\n        // Upsampling the input by fill in `dilation size - 1` values between each\n        // input value.\n        // This implementation follows the TF c++ implementation:\n        // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n        for (var b = 0; b < batchSize; ++b) {\n            for (var hOut = 0; hOut < outHeight; ++hOut) {\n                var hBeg = hOut * strideHeight - padInfo.top;\n                for (var wOut = 0; wOut < outWidth; ++wOut) {\n                    var wBeg = wOut * strideWidth - padInfo.left;\n                    for (var d = 0; d < inChannels; ++d) {\n                        var curVal = Number.MIN_SAFE_INTEGER;\n                        for (var h = 0; h < filterHeight; ++h) {\n                            var hIn = hBeg + h * dilationHeight;\n                            if (hIn >= 0 && hIn < inHeight) {\n                                for (var w = 0; w < filterWidth; ++w) {\n                                    var wIn = wBeg + w * dilationWidth;\n                                    if (wIn >= 0 && wIn < inWidth) {\n                                        var xIndex = tfjsCore.util.locToIndex([b, hIn, wIn, d], xRank, tfjsCore.util.computeStrides(x.shape));\n                                        var filterIndex = tfjsCore.util.locToIndex([h, w, d], filterRank, tfjsCore.util.computeStrides(filter.shape));\n                                        var val = xVals[xIndex] + filterVals[filterIndex];\n                                        if (val > curVal) {\n                                            curVal = val;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                        var outputIndex = tfjsCore.util.locToIndex([b, hOut, wOut, d], outRank, tfjsCore.util.computeStrides(outShape));\n                        outputVals[outputIndex] = curVal;\n                    }\n                }\n            }\n        }\n        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n        return { dataId: dataId, shape: outShape, dtype: x.dtype };\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar dilation2DBackpropFilterConfig = {\n    kernelName: tfjsCore.Dilation2DBackpropFilter,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend, attrs = _a.attrs;\n        var x = inputs.x, filter = inputs.filter, dy = inputs.dy;\n        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;\n        var cpuBackend = backend;\n        var $x = tfjsCore.util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n        var $filter = tfjsCore.util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;\n        tfjsCore.util.assert(dy.rank === outShape.length, function () { return \"Error in \" + tfjsCore.Dilation2DBackpropFilter + \", dy \" +\n            (\"must have the same rank as output \" + outShape.length + \", but got \") +\n            (\"\" + dy.rank); });\n        var $dy = tfjsCore.util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);\n        // The computed filter gradients has the same dimensions as the filter:\n        // [filterHeight, filterWidth, depth]\n        var gradients = tfjsCore.util.makeZerosNestedTypedArray(filter.shape, filter.dtype);\n        // In the case of multiple argmax branches, we only back-propagate along the\n        // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n        // similarly to the max-pooling backward routines.\n        // This implementation follows the TF c++ implementation:\n        // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n        for (var b = 0; b < batchSize; ++b) {\n            for (var hOut = 0; hOut < outHeight; ++hOut) {\n                var hBeg = hOut * strideHeight - padInfo.top;\n                for (var wOut = 0; wOut < outWidth; ++wOut) {\n                    var wBeg = wOut * strideWidth - padInfo.left;\n                    for (var d = 0; d < inChannels; ++d) {\n                        var curVal = Number.MIN_SAFE_INTEGER;\n                        var hMax = 0;\n                        var wMax = 0;\n                        for (var h = 0; h < filterHeight; ++h) {\n                            var hIn = hBeg + h * dilationHeight;\n                            if (hIn >= 0 && hIn < inHeight) {\n                                for (var w = 0; w < filterWidth; ++w) {\n                                    var wIn = wBeg + w * dilationWidth;\n                                    if (wIn >= 0 && wIn < inWidth) {\n                                        var val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                                        if (val > curVal) {\n                                            curVal = val;\n                                            hMax = h;\n                                            wMax = w;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                        gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n                    }\n                }\n            }\n        }\n        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n        return { dataId: dataId, shape: filter.shape, dtype: filter.dtype };\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar dilation2DBackpropInputConfig = {\n    kernelName: tfjsCore.Dilation2DBackpropInput,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend, attrs = _a.attrs;\n        var x = inputs.x, filter = inputs.filter, dy = inputs.dy;\n        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;\n        var cpuBackend = backend;\n        var $x = tfjsCore.util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n        var $filter = tfjsCore.util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;\n        tfjsCore.util.assert(dy.rank === outShape.length, function () { return \"Error in \" + tfjsCore.Dilation2DBackpropInput + \", dy \" +\n            (\"must have the same rank as output \" + outShape.length + \", but got \") +\n            (\"\" + dy.rank); });\n        var $dy = tfjsCore.util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);\n        // The computed gradients has the same dimensions as the input:\n        // [batch, inputHeight, inputCols, inChannel]\n        var gradients = tfjsCore.util.makeZerosNestedTypedArray(x.shape, x.dtype);\n        // In the case of multiple argmax branches, we only back-propagate along the\n        // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n        // similarly to the max-pooling backward routines.\n        // This implementation follows the TF c++ implementation:\n        // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n        for (var b = 0; b < batchSize; ++b) {\n            for (var hOut = 0; hOut < outHeight; ++hOut) {\n                var hBeg = hOut * strideHeight - padInfo.top;\n                for (var wOut = 0; wOut < outWidth; ++wOut) {\n                    var wBeg = wOut * strideWidth - padInfo.left;\n                    for (var d = 0; d < inChannels; ++d) {\n                        var curVal = Number.MIN_SAFE_INTEGER;\n                        var hInMax = (hBeg < 0) ? 0 : hBeg;\n                        var wInMax = (wBeg < 0) ? 0 : wBeg;\n                        for (var h = 0; h < filterHeight; ++h) {\n                            var hIn = hBeg + h * dilationHeight;\n                            if (hIn >= 0 && hIn < inHeight) {\n                                for (var w = 0; w < filterWidth; ++w) {\n                                    var wIn = wBeg + w * dilationWidth;\n                                    if (wIn >= 0 && wIn < inWidth) {\n                                        var val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                                        if (val > curVal) {\n                                            curVal = val;\n                                            hInMax = hIn;\n                                            wInMax = wIn;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                        gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n                    }\n                }\n            }\n        }\n        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n        return { dataId: dataId, shape: x.shape, dtype: x.dtype };\n    }\n};\n\nfunction sum(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    assertNotComplex(x, 'sum');\n    var $x;\n    if (x.dtype === 'bool') {\n        $x = cast({ inputs: { x: x }, backend: backend, attrs: { dtype: 'int32' } });\n    }\n    else {\n        $x = identity({ inputs: { x: x }, backend: backend });\n    }\n    var xRank = $x.shape.length;\n    var axes = tfjsCore.util.parseAxisParam(axis, $x.shape);\n    var permutation = tfjsCore.backend_util.getAxesPermutation(axes, xRank);\n    var reductionAxes = axes;\n    var permutedX = $x;\n    if (permutation != null) {\n        permutedX =\n            transpose({ inputs: { x: $x }, backend: backend, attrs: { perm: permutation } });\n        reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n    }\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('sum', reductionAxes, permutedX.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes(permutedX.shape, reductionAxes), 2), outShape = _a[0], reduceShape = _a[1];\n    var resultDtype = tfjsCore.backend_util.upcastType(permutedX.dtype, 'int32');\n    var result = zeros(backend, outShape, resultDtype);\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var vals = backend.data.get(result.dataId).values;\n    var aVals = backend.data.get(permutedX.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var sum_1 = 0;\n        for (var j = 0; j < reduceSize; ++j) {\n            sum_1 += aVals[offset + j];\n        }\n        vals[i] = sum_1;\n    }\n    if (keepDims) {\n        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(result.shape, axes);\n        var oldResult = result;\n        result = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: newShape } });\n        backend.disposeIntermediateTensorInfo(oldResult);\n    }\n    backend.disposeIntermediateTensorInfo($x);\n    if (permutation != null) {\n        backend.disposeIntermediateTensorInfo(permutedX);\n    }\n    return result;\n}\nvar sumConfig = {\n    kernelName: tfjsCore.Sum,\n    backendName: 'cpu',\n    kernelFunc: sum\n};\n\nfunction einsum(args) {\n    var e_1, _a, e_2, _b;\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var equation = attrs.equation;\n    var tensors = inputs;\n    var _c = tfjsCore.backend_util.decodeEinsumEquation(equation, tensors.length), allDims = _c.allDims, summedDims = _c.summedDims, idDims = _c.idDims;\n    tfjsCore.backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n    var _d = tfjsCore.backend_util.getEinsumComputePath(summedDims, idDims), path = _d.path, steps = _d.steps;\n    var nSteps = steps.length;\n    var out = null;\n    var numDimsRemaining = allDims.length;\n    var tensorsToDispose = [];\n    for (var i = 0; i < nSteps; ++i) {\n        try {\n            for (var _e = (e_1 = void 0, __values(steps[i])), _f = _e.next(); !_f.done; _f = _e.next()) {\n                var idTerm = _f.value;\n                var _g = tfjsCore.backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]), perm = _g.permutationIndices, dimsToExpand = _g.expandDims;\n                var x = void 0;\n                if (tfjsCore.backend_util.isIdentityPermutation(perm)) {\n                    x = tensors[idTerm];\n                }\n                else {\n                    x = transpose({ inputs: { x: tensors[idTerm] }, backend: backend, attrs: { perm: perm } });\n                    tensorsToDispose.push(x);\n                }\n                var targetShape = x.shape.slice();\n                for (var k = 0; k < dimsToExpand.length; ++k) {\n                    targetShape.splice(dimsToExpand[k], 0, 1);\n                }\n                if (!tfjsCore.util.arraysEqual(x.shape, targetShape)) {\n                    x = reshape({ inputs: { x: x }, backend: backend, attrs: { shape: targetShape } });\n                    tensorsToDispose.push(x);\n                }\n                if (out === null) {\n                    out = x;\n                }\n                else {\n                    // tslint:disable-next-line: no-unnecessary-type-assertion\n                    out = multiply({ inputs: { a: x, b: out }, backend: backend });\n                    tensorsToDispose.push(out);\n                }\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (_f && !_f.done && (_a = _e.return)) _a.call(_e);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        if (i < nSteps - 1) {\n            if (path[i] >= 0) {\n                out = sum({\n                    inputs: { x: out },\n                    backend: backend,\n                    attrs: {\n                        axis: path[i] - (allDims.length - numDimsRemaining),\n                        keepDims: false\n                    }\n                });\n                tensorsToDispose.push(out);\n            }\n            numDimsRemaining--;\n        }\n    }\n    try {\n        // Clean up intermediate tensors.\n        for (var tensorsToDispose_1 = __values(tensorsToDispose), tensorsToDispose_1_1 = tensorsToDispose_1.next(); !tensorsToDispose_1_1.done; tensorsToDispose_1_1 = tensorsToDispose_1.next()) {\n            var tensorInfo = tensorsToDispose_1_1.value;\n            if (tensorInfo === out) {\n                continue;\n            }\n            backend.disposeIntermediateTensorInfo(tensorInfo);\n        }\n    }\n    catch (e_2_1) { e_2 = { error: e_2_1 }; }\n    finally {\n        try {\n            if (tensorsToDispose_1_1 && !tensorsToDispose_1_1.done && (_b = tensorsToDispose_1.return)) _b.call(tensorsToDispose_1);\n        }\n        finally { if (e_2) throw e_2.error; }\n    }\n    return out;\n}\nvar einsumConfig = {\n    kernelName: tfjsCore.Einsum,\n    backendName: 'cpu',\n    kernelFunc: einsum\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction eluGrad(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var dy = inputs.dy, y = inputs.y;\n    assertNotComplex([dy, y], 'eluGrad');\n    var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(y.shape));\n    var values = backend.data.get(y.dataId).values;\n    var dyValues = backend.data.get(dy.dataId).values;\n    for (var i = 0; i < values.length; ++i) {\n        var v = values[i];\n        if (v >= 1) {\n            resultValues[i] = dyValues[i];\n        }\n        else {\n            resultValues[i] = dyValues[i] * (v + 1);\n        }\n    }\n    return backend.makeTensorInfo(y.shape, 'float32', resultValues);\n}\nvar eluGradConfig = {\n    kernelName: tfjsCore.EluGrad,\n    backendName: 'cpu',\n    kernelFunc: eluGrad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar p = tfjsCore.backend_util.ERF_P;\nvar a1 = tfjsCore.backend_util.ERF_A1;\nvar a2 = tfjsCore.backend_util.ERF_A2;\nvar a3 = tfjsCore.backend_util.ERF_A3;\nvar a4 = tfjsCore.backend_util.ERF_A4;\nvar a5 = tfjsCore.backend_util.ERF_A5;\nvar erf = unaryKernelFunc(tfjsCore.Erf, function (xi) {\n    var sign = Math.sign(xi);\n    var v = Math.abs(xi);\n    var t = 1.0 / (1.0 + p * v);\n    return sign *\n        (1.0 -\n            (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n                Math.exp(-v * v));\n});\nvar erfConfig = {\n    kernelName: tfjsCore.Erf,\n    backendName: 'cpu',\n    kernelFunc: erf,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction expandDims(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var input = inputs.input;\n    var dim = attrs.dim;\n    var inputRank = input.shape.length;\n    var newShape = input.shape.slice();\n    var $dim = dim;\n    if (dim < 0) {\n        // Negative value is counted from the tail of rank.\n        tfjsCore.util.assert(-(inputRank + 1) <= dim, function () { return \"Axis must be in the interval [\" + -(inputRank + 1) + \", \" + inputRank + \"]\"; });\n        $dim = inputRank + dim + 1;\n    }\n    newShape.splice($dim, 0, 1);\n    return reshape({ inputs: { x: input }, backend: backend, attrs: { shape: newShape } });\n}\nvar expandDimsConfig = {\n    kernelName: tfjsCore.ExpandDims,\n    backendName: 'cpu',\n    kernelFunc: expandDims\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar realDivImpl = createSimpleBinaryKernelImpl(function (a, b) { return a / b; });\nvar div = binaryKernelFunc(tfjsCore.RealDiv, realDivImpl);\nvar realDivConfig = {\n    kernelName: tfjsCore.RealDiv,\n    backendName: 'cpu',\n    kernelFunc: div\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nfunction fftBatch(input, inverse, cpuBackend) {\n    var inputShape = input.shape;\n    var batch = inputShape[0];\n    var innerDim = inputShape[1];\n    var inputVals = cpuBackend.data.get(input.dataId);\n    var real2D = inputVals.complexTensorInfos.real;\n    var imag2D = inputVals.complexTensorInfos.imag;\n    // Collects real and imaginary values separately.\n    var resultShape = [batch, innerDim];\n    var resultSize = tfjsCore.util.sizeFromShape(resultShape);\n    var resultReal = tfjsCore.util.getTypedArrayFromDType('float32', resultSize);\n    var resultImag = tfjsCore.util.getTypedArrayFromDType('float32', resultSize);\n    for (var b = 0; b < batch; b++) {\n        // TODO: Support slice ops for complex type.\n        var r = slice({\n            inputs: { x: real2D },\n            backend: cpuBackend,\n            attrs: { begin: [b, 0], size: [1, innerDim] }\n        });\n        var i = slice({\n            inputs: { x: imag2D },\n            backend: cpuBackend,\n            attrs: { begin: [b, 0], size: [1, innerDim] }\n        });\n        var input_1 = complex({ inputs: { real: r, imag: i }, backend: cpuBackend });\n        // Run FFT by batch element.\n        var _a = fftImpl(input_1, inverse, cpuBackend), real_1 = _a.real, imag_1 = _a.imag;\n        var res = tfjsCore.backend_util.mergeRealAndImagArrays(real_1, imag_1);\n        for (var d = 0; d < innerDim; d++) {\n            var c = tfjsCore.backend_util.getComplexWithIndex(res, d);\n            resultReal[b * innerDim + d] = c.real;\n            resultImag[b * innerDim + d] = c.imag;\n        }\n        cpuBackend.disposeIntermediateTensorInfo(r);\n        cpuBackend.disposeIntermediateTensorInfo(i);\n        cpuBackend.disposeIntermediateTensorInfo(input_1);\n    }\n    var $realInfo = cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n    var $imagInfo = cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n    var result = complex({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });\n    cpuBackend.disposeIntermediateTensorInfo($realInfo);\n    cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n    return result;\n}\nfunction fftImpl(input, inverse, cpuBackend) {\n    var inputSize = tfjsCore.util.sizeFromShape(input.shape);\n    var inputVals = cpuBackend.data.get(input.dataId);\n    var realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;\n    var imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;\n    if (isExponentOf2(inputSize)) {\n        var result = fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n        var resultShape = [input.shape[0], input.shape[1]];\n        if (inverse) {\n            var realInfo = cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n            var imagInfo = cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n            var sizeInfo = cpuBackend.makeTensorInfo([], 'float32', tfjsCore.util.createScalarValue(inputSize, 'float32'));\n            var sizeInfoCopy = identity({ inputs: { x: sizeInfo }, backend: cpuBackend });\n            var divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });\n            var divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });\n            var divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;\n            var divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;\n            cpuBackend.disposeIntermediateTensorInfo(realInfo);\n            cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n            cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n            cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n            cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n            cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n            return { real: divRealVals, imag: divImagVals };\n        }\n        return result;\n    }\n    else {\n        var data = tfjsCore.backend_util.mergeRealAndImagArrays(realVals, imagVals);\n        var rawOutput = fourierTransformByMatmul(data, inputSize, inverse);\n        return tfjsCore.backend_util.splitRealAndImagArrays(rawOutput);\n    }\n}\nfunction isExponentOf2(size) {\n    return (size & size - 1) === 0;\n}\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(realVals, imagVals, size, inverse, cpuBackend) {\n    if (size === 1) {\n        return { real: realVals, imag: imagVals };\n    }\n    var data = tfjsCore.backend_util.mergeRealAndImagArrays(realVals, imagVals);\n    var half = size / 2;\n    var evenComplex = tfjsCore.backend_util.complexWithEvenIndex(data);\n    var evenRealVals = evenComplex.real;\n    var evenImagVals = evenComplex.imag;\n    var evenShape = [evenRealVals.length];\n    var evenRealInfo = cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n    var evenImagInfo = cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n    var evenTensorInfo = complex({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });\n    var oddComplex = tfjsCore.backend_util.complexWithOddIndex(data);\n    var oddRealVals = oddComplex.real;\n    var oddImagVals = oddComplex.imag;\n    var oddShape = [oddRealVals.length];\n    var oddRealInfo = cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n    var oddImagInfo = cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n    var oddTensorInfo = complex({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });\n    // Recursive call for half part of original input.\n    var $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n    var $evenRealVals = $evenComplex.real;\n    var $evenImagVals = $evenComplex.imag;\n    var $evenShape = [$evenRealVals.length];\n    var $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n    var $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n    var $evenTensorInfo = complex({\n        inputs: { real: $evenRealInfo, imag: $evenImagInfo },\n        backend: cpuBackend\n    });\n    var $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n    var $oddRealVals = $oddComplex.real;\n    var $oddImagVals = $oddComplex.imag;\n    var $oddShape = [$oddRealVals.length];\n    var $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n    var $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n    var $oddTensorInfo = complex({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });\n    var e = tfjsCore.backend_util.exponents(size, inverse);\n    var eShape = [e.real.length];\n    var eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n    var eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n    var complexInfo = complex({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });\n    var exponentInfo = multiply({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });\n    var addPart = add({\n        inputs: { a: $evenTensorInfo, b: exponentInfo },\n        backend: cpuBackend\n    });\n    var subPart = sub({\n        inputs: { a: $evenTensorInfo, b: exponentInfo },\n        backend: cpuBackend\n    });\n    var addPartReal = real({ inputs: { input: addPart }, backend: cpuBackend });\n    var subPartReal = real({ inputs: { input: subPart }, backend: cpuBackend });\n    var addPartImag = imag({ inputs: { input: addPart }, backend: cpuBackend });\n    var subPartImag = imag({ inputs: { input: subPart }, backend: cpuBackend });\n    var $real = concat({\n        inputs: [addPartReal, subPartReal],\n        backend: cpuBackend,\n        attrs: { axis: 0 }\n    });\n    var $imag = concat({\n        inputs: [addPartImag, subPartImag],\n        backend: cpuBackend,\n        attrs: { axis: 0 }\n    });\n    var $realVals = cpuBackend.data.get($real.dataId).values;\n    var $imagVals = cpuBackend.data.get($imag.dataId).values;\n    cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n    cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n    cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n    cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n    cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n    cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n    cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n    cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n    cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n    cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n    cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n    cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n    cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n    cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n    cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n    cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n    cpuBackend.disposeIntermediateTensorInfo(addPart);\n    cpuBackend.disposeIntermediateTensorInfo(subPart);\n    cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n    cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n    cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n    cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n    cpuBackend.disposeIntermediateTensorInfo($real);\n    cpuBackend.disposeIntermediateTensorInfo($imag);\n    return { real: $realVals, imag: $imagVals };\n}\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(data, size, inverse) {\n    var ret = new Float32Array(size * 2);\n    // TODO: Use matmul instead once it supports complex64 type.\n    for (var r = 0; r < size; r++) {\n        var real_2 = 0.0;\n        var imag_2 = 0.0;\n        for (var c = 0; c < size; c++) {\n            var e = tfjsCore.backend_util.exponent(r * c, size, inverse);\n            var term = tfjsCore.backend_util.getComplexWithIndex(data, c);\n            real_2 += term.real * e.real - term.imag * e.imag;\n            imag_2 += term.real * e.imag + term.imag * e.real;\n        }\n        if (inverse) {\n            real_2 /= size;\n            imag_2 /= size;\n        }\n        tfjsCore.backend_util.assignToTypedArray(ret, real_2, imag_2, r);\n    }\n    return ret;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction fft(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var input = inputs.input;\n    var inputSize = tfjsCore.util.sizeFromShape(input.shape);\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = inputSize / innerDimensionSize;\n    var input2D = reshape({\n        inputs: { x: input },\n        backend: backend,\n        attrs: { shape: [batch, innerDimensionSize] }\n    });\n    var result = fftBatch(input2D, false, backend);\n    var resultReshaped = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: input.shape } });\n    backend.disposeIntermediateTensorInfo(input2D);\n    backend.disposeIntermediateTensorInfo(result);\n    return resultReshaped;\n}\nvar fftConfig = {\n    kernelName: tfjsCore.FFT,\n    backendName: 'cpu',\n    kernelFunc: fft\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction fill(args) {\n    var backend = args.backend, attrs = args.attrs;\n    var shape = attrs.shape, value = attrs.value, dtype = attrs.dtype;\n    var $dtype = dtype || tfjsCore.util.inferDtype(value);\n    var values = tfjsCore.util.getArrayFromDType($dtype, tfjsCore.util.sizeFromShape(shape));\n    fillValues(values, value, $dtype);\n    return backend.makeTensorInfo(shape, $dtype, values);\n}\nvar fillConfig = {\n    kernelName: tfjsCore.Fill,\n    backendName: 'cpu',\n    kernelFunc: fill\n};\nfunction fillValues(values, value, dtype) {\n    if (dtype === 'string') {\n        values.fill(value);\n    }\n    else {\n        values.fill(value);\n    }\n}\n\nvar flipLeftRightConfig = {\n    kernelName: tfjsCore.FlipLeftRight,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs; _a.attrs; var backend = _a.backend;\n        var image = inputs.image;\n        var cpuBackend = backend;\n        var output = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(image.shape));\n        var _b = __read(image.shape, 4), batch = _b[0], imageHeight = _b[1], imageWidth = _b[2], numChannels = _b[3];\n        var imageVals = cpuBackend.data.get(image.dataId).values;\n        for (var batchIdx = 0; batchIdx < batch; batchIdx++) {\n            var batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n            for (var row = 0; row < imageHeight; row++) {\n                var rowOffset = row * (imageWidth * numChannels);\n                for (var col = 0; col < imageWidth; col++) {\n                    var colOffset = col * numChannels;\n                    for (var channel = 0; channel < numChannels; channel++) {\n                        var coordX = Math.round(imageWidth - col - 1);\n                        var outIdx = batchOffset + rowOffset + colOffset + channel;\n                        var outputValue = imageVals[outIdx];\n                        // If the coordinate position falls within the image boundaries...\n                        if (coordX >= 0 && coordX < imageWidth) {\n                            // set the output to the image value at the coordinate position.\n                            var rotatedColOffset = coordX * numChannels;\n                            var imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;\n                            outputValue = imageVals[imageIdx];\n                        }\n                        output[outIdx] = outputValue;\n                    }\n                }\n            }\n        }\n        var dataId = cpuBackend.write(output, image.shape, image.dtype);\n        return { dataId: dataId, shape: image.shape, dtype: image.dtype };\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar floorDivImpl = createSimpleBinaryKernelImpl(function (a, b) { return Math.floor(a / b); });\nvar floorDiv = binaryKernelFunc(tfjsCore.FloorDiv, floorDivImpl, null /* complexImpl */, 'int32');\nvar floorDivConfig = {\n    kernelName: tfjsCore.FloorDiv,\n    backendName: 'cpu',\n    kernelFunc: floorDiv\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction fusedConv2D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;\n    var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;\n    var result = conv2D({\n        inputs: { x: x, filter: filter },\n        backend: backend,\n        attrs: { strides: strides, pad: pad, dataFormat: dataFormat, dilations: dilations, dimRoundingMode: dimRoundingMode }\n    });\n    if (bias) {\n        var resultOld = result;\n        result = add({ inputs: { a: result, b: bias }, backend: backend });\n        backend.disposeIntermediateTensorInfo(resultOld);\n    }\n    if (activation) {\n        var resultOld = result;\n        result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);\n        backend.disposeIntermediateTensorInfo(resultOld);\n    }\n    return result;\n}\nvar fusedConv2DConfig = {\n    kernelName: tfjsCore.FusedConv2D,\n    backendName: 'cpu',\n    kernelFunc: fusedConv2D\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction fusedDepthwiseConv2D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;\n    var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;\n    var result = depthwiseConv2dNative({\n        inputs: { x: x, filter: filter },\n        backend: backend,\n        attrs: { strides: strides, pad: pad, dataFormat: dataFormat, dilations: dilations, dimRoundingMode: dimRoundingMode }\n    });\n    if (bias) {\n        var oldResult = result;\n        result = add({ inputs: { a: result, b: bias }, backend: backend });\n        backend.disposeIntermediateTensorInfo(oldResult);\n    }\n    if (activation) {\n        var oldResult = result;\n        result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);\n        backend.disposeIntermediateTensorInfo(oldResult);\n    }\n    return result;\n}\nvar fusedDepthwiseConv2DConfig = {\n    kernelName: tfjsCore.FusedDepthwiseConv2D,\n    backendName: 'cpu',\n    kernelFunc: fusedDepthwiseConv2D\n};\n\nfunction gatherNd(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var params = inputs.params, indices = inputs.indices;\n    var paramsSize = tfjsCore.util.sizeFromShape(params.shape);\n    var indicesShape = indices.shape;\n    var sliceRank = indicesShape[indicesShape.length - 1];\n    var _a = __read(tfjsCore.backend_util.prepareAndValidate(params, indices), 4), resultShape = _a[0], numSlices = _a[1], sliceSize = _a[2], strides = _a[3];\n    if (numSlices === 0) {\n        return backend.makeTensorInfo(resultShape, params.dtype, []);\n    }\n    var indicesData = backend.data.get(indices.dataId).values;\n    var paramsBuf = backend.bufferSync(params);\n    var outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);\n    return backend.makeTensorInfo(resultShape, params.dtype, outBuf.values);\n}\nvar gatherNdConfig = {\n    kernelName: tfjsCore.GatherNd,\n    backendName: 'cpu',\n    kernelFunc: gatherNd\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction gatherV2(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, indices = inputs.indices;\n    var axis = attrs.axis, batchDims = attrs.batchDims;\n    assertNotComplex([x, indices], 'gatherV2');\n    // Throw error when any index is out of bound.\n    var parsedAxis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];\n    var indicesVals = backend.data.get(indices.dataId).values;\n    var axisDim = x.shape[parsedAxis];\n    var _loop_1 = function (i) {\n        var index = indicesVals[i];\n        tfjsCore.util.assert(index <= axisDim - 1 && index >= 0, function () { return \"GatherV2: the index value \" + index + \" is not in [0, \" + (axisDim - 1) + \"]\"; });\n    };\n    for (var i = 0; i < indicesVals.length; ++i) {\n        _loop_1(i);\n    }\n    var $batchDims = batchDims;\n    if (batchDims == null) {\n        $batchDims = 0;\n    }\n    var indicesSize = tfjsCore.util.sizeFromShape(indices.shape);\n    var shapeInfo = tfjsCore.backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);\n    var flattenX = reshape({\n        inputs: { x: x },\n        backend: backend,\n        attrs: {\n            shape: [\n                shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n                shapeInfo.sliceSize\n            ]\n        }\n    });\n    var flattenIndex = reshape({\n        inputs: { x: indices },\n        backend: backend,\n        attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }\n    });\n    var flattenOutputShape = [\n        shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n        shapeInfo.sliceSize\n    ];\n    var indicesBuf = backend.bufferSync(flattenIndex);\n    var xBuf = backend.bufferSync(flattenX);\n    var outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);\n    backend.disposeIntermediateTensorInfo(flattenX);\n    backend.disposeIntermediateTensorInfo(flattenIndex);\n    return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);\n}\nvar gatherV2Config = {\n    kernelName: tfjsCore.GatherV2,\n    backendName: 'cpu',\n    kernelFunc: gatherV2\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction ifft(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var input = inputs.input;\n    var inputSize = tfjsCore.util.sizeFromShape(input.shape);\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = inputSize / innerDimensionSize;\n    var input2D = reshape({\n        inputs: { x: input },\n        backend: backend,\n        attrs: { shape: [batch, innerDimensionSize] }\n    });\n    var result = fftBatch(input2D, true, backend);\n    var resultReshaped = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: input.shape } });\n    backend.disposeIntermediateTensorInfo(input2D);\n    backend.disposeIntermediateTensorInfo(result);\n    return resultReshaped;\n}\nvar ifftConfig = {\n    kernelName: tfjsCore.IFFT,\n    backendName: 'cpu',\n    kernelFunc: ifft\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar isFinite = unaryKernelFunc(tfjsCore.IsFinite, function (xi) { return Number.isFinite(xi) ? 1 : 0; }, 'bool');\nvar isFiniteConfig = {\n    kernelName: tfjsCore.IsFinite,\n    backendName: 'cpu',\n    kernelFunc: isFinite,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar isInf = unaryKernelFunc(tfjsCore.IsInf, function (xi) { return Math.abs(xi) === Infinity ? 1 : 0; }, 'bool');\nvar isInfConfig = {\n    kernelName: tfjsCore.IsInf,\n    backendName: 'cpu',\n    kernelFunc: isInf,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar isNaN$1 = unaryKernelFunc(tfjsCore.IsNan, function (xi) { return Number.isNaN(xi) ? 1 : 0; }, 'bool');\nvar isNaNConfig = {\n    kernelName: tfjsCore.IsNan,\n    backendName: 'cpu',\n    kernelFunc: isNaN$1,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction linSpace(args) {\n    var backend = args.backend, attrs = args.attrs;\n    var start = attrs.start, stop = attrs.stop, num = attrs.num;\n    var outVals = linSpaceImpl(start, stop, num);\n    return backend.makeTensorInfo([outVals.length], 'float32', outVals);\n}\nvar linSpaceConfig = {\n    kernelName: tfjsCore.LinSpace,\n    backendName: 'cpu',\n    kernelFunc: linSpace\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar log1p = unaryKernelFunc(tfjsCore.Log1p, function (xi) { return Math.log1p(xi); });\nvar log1pConfig = {\n    kernelName: tfjsCore.Log1p,\n    backendName: 'cpu',\n    kernelFunc: log1p,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar logicalAndImpl = createSimpleBinaryKernelImpl(function (a, b) { return a && b; });\nvar logicalAnd = binaryKernelFunc(tfjsCore.LogicalAnd, logicalAndImpl, null /* complexImpl */, 'bool');\nvar logicalAndConfig = {\n    kernelName: tfjsCore.LogicalAnd,\n    backendName: 'cpu',\n    kernelFunc: logicalAnd\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar logicalNot = unaryKernelFunc(tfjsCore.LogicalNot, function (xi) { return xi ? 0 : 1; }, 'bool');\nvar logicalNotConfig = {\n    kernelName: tfjsCore.LogicalNot,\n    backendName: 'cpu',\n    kernelFunc: logicalNot,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar logicalOrImpl = createSimpleBinaryKernelImpl(function (a, b) { return a || b; });\nvar logicalOr = binaryKernelFunc(tfjsCore.LogicalOr, logicalOrImpl, null /* complexImpl */, 'bool');\nvar logicalOrConfig = {\n    kernelName: tfjsCore.LogicalOr,\n    backendName: 'cpu',\n    kernelFunc: logicalOr\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction lRN(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;\n    assertNotComplex(x, 'LRN');\n    var channels = x.shape[3];\n    var maxD = channels - 1;\n    var xValues = backend.data.get(x.dataId).values;\n    var size = tfjsCore.util.sizeFromShape(x.shape);\n    var result = new Float32Array(size);\n    function sumAcrossChannels(offset) {\n        var currentChannel = offset % channels;\n        var beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n        var endSumOffset = offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);\n        var sum = 0.0;\n        for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n            var z = xValues[beginSumOffset];\n            sum += z * z;\n        }\n        return sum;\n    }\n    for (var offset = 0; offset < size; offset++) {\n        var sum = sumAcrossChannels(offset);\n        var val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n        result[offset] = val;\n    }\n    return backend.makeTensorInfo(x.shape, x.dtype, result);\n}\n// tslint:disable-next-line: variable-name\nvar LRNConfig = {\n    kernelName: tfjsCore.LRN,\n    backendName: 'cpu',\n    kernelFunc: lRN\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction lRNGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, y = inputs.y, dy = inputs.dy;\n    var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;\n    assertNotComplex(dy, 'LRNGrad');\n    var dySize = tfjsCore.util.sizeFromShape(dy.shape);\n    var channels = dy.shape[3];\n    var dyValues = backend.data.get(dy.dataId).values;\n    var xValues = backend.data.get(x.dataId).values;\n    var yValues = backend.data.get(y.dataId).values;\n    var result = new Float32Array(dySize);\n    var size = dySize;\n    for (var offset = 0; offset < size; offset++) {\n        var currentChannel = offset % channels;\n        var depthBegin = (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n        var depthEnd = (offset - currentChannel) +\n            Math.min(channels, currentChannel + depthRadius + 1);\n        var norm = 0;\n        for (var k = depthBegin; k < depthEnd; k++) {\n            norm += Math.pow(xValues[k], 2);\n        }\n        norm = alpha * norm + bias;\n        for (var k = depthBegin; k < depthEnd; k++) {\n            var dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm;\n            if (offset === k) {\n                dyi += Math.pow(norm, -beta);\n            }\n            dyi *= dyValues[offset];\n            result[k] += dyi;\n        }\n    }\n    return backend.makeTensorInfo(dy.shape, x.dtype, result);\n}\n// tslint:disable-next-line: variable-name\nvar LRNGradConfig = {\n    kernelName: tfjsCore.LRNGrad,\n    backendName: 'cpu',\n    kernelFunc: lRNGrad\n};\n\nfunction max(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var reductionIndices = attrs.reductionIndices, keepDims = attrs.keepDims;\n    var cpuBackend = backend;\n    var xShape = x.shape;\n    var xRank = xShape.length;\n    var origAxes = tfjsCore.util.parseAxisParam(reductionIndices, xShape);\n    var axes = origAxes;\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, xRank);\n    var xVals = cpuBackend.data.get(x.dataId).values;\n    if (permutedAxes != null) {\n        var newShape = new Array(xRank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = xShape[permutedAxes[i]];\n        }\n        xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, xRank);\n        xShape = newShape;\n    }\n    assertNotComplex(x, 'max');\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes(xShape, axes), 2), maxOutShape = _a[0], reduceShape = _a[1];\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    var dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n    var outShape = maxOutShape;\n    if (keepDims) {\n        // reshape\n        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n        outShape = newShape;\n    }\n    return { dataId: dataId, shape: outShape, dtype: x.dtype };\n}\nvar maxConfig = {\n    kernelName: tfjsCore.Max,\n    backendName: 'cpu',\n    kernelFunc: max\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxPool(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    assertNotComplex(x, 'maxPool');\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;\n    var dilations = 1;\n    tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in maxPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res;\n    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n        tfjsCore.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n        res = identity({ inputs: { x: x }, backend: backend });\n    }\n    else {\n        var xValues = backend.data.get(x.dataId).values;\n        var strides_1 = tfjsCore.util.computeStrides(x.shape);\n        var buffer = pool(xValues, x.shape, x.dtype, strides_1, convInfo, 'max');\n        res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer.values);\n    }\n    return res;\n}\nvar maxPoolConfig = {\n    kernelName: tfjsCore.MaxPool,\n    backendName: 'cpu',\n    kernelFunc: maxPool\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxPool3D(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;\n    assertNotComplex(x, 'maxPool3d');\n    var convInfo = tfjsCore.backend_util.computePool3DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode, dataFormat);\n    var xValues = backend.data.get(x.dataId).values;\n    var outBuf = pool3d(xValues, x.shape, x.dtype, tfjsCore.util.computeStrides(x.shape), convInfo, 'max');\n    return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\nvar maxPool3DConfig = {\n    kernelName: tfjsCore.MaxPool3D,\n    backendName: 'cpu',\n    kernelFunc: maxPool3D\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxPool3DGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, input = inputs.input;\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;\n    assertNotComplex([dy, input], 'maxPool3DGrad');\n    var convInfo = tfjsCore.backend_util.computePool3DInfo(input.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n    var inputBuf = backend.bufferSync(input);\n    var maxPosBuf = maxPool3dPositions(inputBuf, convInfo);\n    var strideDepth = convInfo.strideDepth;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationDepth = convInfo.dilationDepth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    var dx = tfjsCore.buffer(input.shape, 'float32');\n    var dyBuf = backend.bufferSync(dy);\n    for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n        for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n            for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n                for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n                    for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n                        // Shader code begins\n                        var dyDepthCorner = dxDepth - padFront;\n                        var dyRowCorner = dxRow - padTop;\n                        var dyColCorner = dxCol - padLeft;\n                        var dotProd = 0;\n                        for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {\n                            var dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                            if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                                Math.floor(dyDepth) !== dyDepth) {\n                                continue;\n                            }\n                            for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {\n                                var dyRow = (dyRowCorner + wRow) / strideHeight;\n                                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                                    Math.floor(dyRow) !== dyRow) {\n                                    continue;\n                                }\n                                for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {\n                                    var dyCol = (dyColCorner + wCol) / strideWidth;\n                                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                                        Math.floor(dyCol) !== dyCol) {\n                                        continue;\n                                    }\n                                    var maxPos = effectiveFilterDepth * effectiveFilterHeight *\n                                        effectiveFilterWidth -\n                                        1 -\n                                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                    var curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                                        wRow * effectiveFilterWidth + wCol;\n                                    var mask = maxPos === curPos ? 1 : 0;\n                                    if (mask === 0) {\n                                        continue;\n                                    }\n                                    var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                    dotProd += pixel * mask;\n                                }\n                            }\n                        }\n                        dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n                    }\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar maxPool3DGradConfig = {\n    kernelName: tfjsCore.MaxPool3DGrad,\n    backendName: 'cpu',\n    kernelFunc: maxPool3DGrad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxPoolGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var dy = inputs.dy, input = inputs.input, output = inputs.output;\n    var x = input;\n    assertNotComplex([input, output], 'maxPoolGrad');\n    var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;\n    var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n    var xValues = backend.data.get(x.dataId).values;\n    var maxPosBuf = tfjsCore.buffer(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    var dx = tfjsCore.buffer(x.shape, 'float32');\n    var dyData = backend.data.get(dy.dataId).values;\n    var dyBuf = tfjsCore.buffer(dy.shape, 'float32', dyData);\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n        for (var d = 0; d < convInfo.inChannels; ++d) {\n            for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                    // Shader code begins.\n                    var dyRCorner = dxR - padTop;\n                    var dyCCorner = dxC - padLeft;\n                    var dotProd = 0;\n                    for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                        var dyR = (dyRCorner + wR) / strideHeight;\n                        if (dyR < 0 || dyR >= convInfo.outHeight ||\n                            Math.floor(dyR) !== dyR) {\n                            continue;\n                        }\n                        for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                            var dyC = (dyCCorner + wC) / strideWidth;\n                            if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                Math.floor(dyC) !== dyC) {\n                                continue;\n                            }\n                            var maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                                maxPosBuf.get(b, dyR, dyC, d);\n                            var curPos = wR * effectiveFilterWidth + wC;\n                            var mask = maxPos === curPos ? 1 : 0;\n                            if (mask === 0) {\n                                continue;\n                            }\n                            var pixel = dyBuf.get(b, dyR, dyC, d);\n                            dotProd += pixel * mask;\n                        }\n                    }\n                    dx.set(dotProd, b, dxR, dxC, d);\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\nvar maxPoolGradConfig = {\n    kernelName: tfjsCore.MaxPoolGrad,\n    backendName: 'cpu',\n    kernelFunc: maxPoolGrad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {\n    var strides = tfjsCore.util.computeStrides(xShape);\n    var maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n    var maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n    return [maxPools.values, maxPositions.values];\n}\n\nvar maxPoolWithArgmaxConfig = {\n    kernelName: tfjsCore.MaxPoolWithArgmax,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, attrs = _a.attrs, backend = _a.backend;\n        var x = inputs.x;\n        var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, includeBatchInIndex = attrs.includeBatchInIndex;\n        var cpuBackend = backend;\n        assertNotComplex(x, 'MaxPoolWithArgmax');\n        var values = cpuBackend.data.get(x.dataId).values;\n        var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad);\n        var _b = __read(maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo), 2), pooled = _b[0], indexes = _b[1];\n        var pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);\n        var indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);\n        return [\n            { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },\n            { dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32' }\n        ];\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction mean(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    var axes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var shapes = tfjsCore.backend_util.computeOutAndReduceShapes(x.shape, axes);\n    var reduceShape = shapes[1];\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var toDispose = [];\n    var reduceSizeScalar = backend.makeTensorInfo([], 'float32', new Float32Array([reduceSize]));\n    toDispose.push(reduceSizeScalar);\n    var $x = cast({ inputs: { x: x }, backend: backend, attrs: { dtype: 'float32' } });\n    toDispose.push($x);\n    var res = div({ inputs: { a: $x, b: reduceSizeScalar }, backend: backend });\n    toDispose.push(res);\n    var result = sum({ inputs: { x: res }, backend: backend, attrs: { axis: axis, keepDims: keepDims } });\n    toDispose.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return result;\n}\nvar meanConfig = {\n    kernelName: tfjsCore.Mean,\n    backendName: 'cpu',\n    kernelFunc: mean\n};\n\nfunction min(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var axis = attrs.axis, keepDims = attrs.keepDims;\n    assertNotComplex(x, 'min');\n    var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);\n    var axes = origAxes;\n    var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);\n    var $x = x;\n    if (permutedAxes != null) {\n        $x = transpose({ inputs: { x: x }, backend: backend, attrs: { perm: permutedAxes } });\n        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);\n    }\n    tfjsCore.backend_util.assertAxesAreInnerMostDims('min', axes, $x.shape.length);\n    var _a = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a[0], reduceShape = _a[1];\n    var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);\n    var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);\n    var aVals = backend.data.get($x.dataId).values;\n    for (var i = 0; i < vals.length; ++i) {\n        var offset = i * reduceSize;\n        var min_1 = aVals[offset];\n        for (var j = 0; j < reduceSize; ++j) {\n            var value = aVals[offset + j];\n            if (Number.isNaN(value) ||\n                value < min_1) { // comparison with NaN always return false\n                min_1 = value;\n            }\n        }\n        vals[i] = min_1;\n    }\n    if (permutedAxes != null) {\n        backend.disposeIntermediateTensorInfo($x);\n    }\n    var result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n    if (keepDims) {\n        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);\n        var reshapedResult = reshape({ inputs: { x: result }, backend: backend, attrs: { shape: expandedShape } });\n        backend.disposeIntermediateTensorInfo(result);\n        return reshapedResult;\n    }\n    return result;\n}\nvar minConfig = {\n    kernelName: tfjsCore.Min,\n    backendName: 'cpu',\n    kernelFunc: min\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction mirrorPad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var paddings = attrs.paddings, mode = attrs.mode;\n    assertNotComplex(x, 'mirrorPad');\n    var outShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + x.shape[i] + p[1]; } /* afterPad */);\n    var start = paddings.map(function (p) { return p[0]; });\n    var end = paddings.map(function (p, i) { return p[0] + x.shape[i]; });\n    var offset = mode === 'reflect' ? 0 : 1;\n    var xVals = backend.data.get(x.dataId).values;\n    var xRank = x.shape.length;\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var resultSize = tfjsCore.util.sizeFromShape(outShape);\n    var resultRank = outShape.length;\n    var resultStrides = tfjsCore.util.computeStrides(outShape);\n    var resVals = tfjsCore.util.getTypedArrayFromDType(x.dtype, resultSize);\n    for (var i = 0; i < resultSize; i++) {\n        var coords = tfjsCore.util.indexToLoc(i, resultRank, resultStrides);\n        for (var i_1 = 0; i_1 < resultRank; i_1++) {\n            if (coords[i_1] < start[i_1]) {\n                coords[i_1] = start[i_1] * 2 - coords[i_1] - offset;\n            }\n            else if (coords[i_1] >= end[i_1]) {\n                coords[i_1] = (end[i_1] - 1) * 2 - coords[i_1] + offset;\n            }\n        }\n        coords = coords.map(function (c, i) { return c - start[i]; });\n        var inIndex = tfjsCore.util.locToIndex(coords, xRank, xStrides);\n        resVals[i] = xVals[inIndex];\n    }\n    var outId = backend.write(resVals, outShape, x.dtype);\n    return { dataId: outId, shape: outShape, dtype: x.dtype };\n}\nvar mirrorPadConfig = {\n    kernelName: tfjsCore.MirrorPad,\n    backendName: 'cpu',\n    kernelFunc: mirrorPad\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar modImpl = createSimpleBinaryKernelImpl((function (aValue, bValue) {\n    var rem = aValue % bValue;\n    if ((aValue < 0 && bValue < 0) || (aValue >= 0 && bValue >= 0)) {\n        return rem;\n    }\n    else {\n        return (rem + bValue) % bValue;\n    }\n}));\nvar mod = binaryKernelFunc(tfjsCore.Mod, modImpl);\nvar modConfig = {\n    kernelName: tfjsCore.Mod,\n    backendName: 'cpu',\n    kernelFunc: mod\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction softmax(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var logits = inputs.logits;\n    var dim = attrs.dim;\n    var logitsRank = logits.shape.length;\n    var $dim = dim;\n    if ($dim === -1) {\n        $dim = logitsRank - 1;\n    }\n    if ($dim !== logitsRank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            (\"Logits was rank \" + logitsRank + \" and dim was \" + $dim));\n    }\n    var axes = tfjsCore.util.parseAxisParam([$dim], logits.shape);\n    var maxLogit = max({\n        inputs: { x: logits },\n        backend: backend,\n        attrs: { reductionIndices: axes, keepDims: false }\n    });\n    var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n    var maxLogitReshaped = reshape({ inputs: { x: maxLogit }, backend: backend, attrs: { shape: expandedShape } });\n    var a = sub({ inputs: { a: logits, b: maxLogitReshaped }, backend: backend });\n    var b = exp({ inputs: { x: a }, backend: backend });\n    var sumExp = sum({ inputs: { x: b }, backend: backend, attrs: { axis: axes, keepDims: false } });\n    var sumReshaped = reshape({ inputs: { x: sumExp }, backend: backend, attrs: { shape: expandedShape } });\n    var result = div({ inputs: { a: b, b: sumReshaped }, backend: backend });\n    backend.disposeIntermediateTensorInfo(maxLogit);\n    backend.disposeIntermediateTensorInfo(maxLogitReshaped);\n    backend.disposeIntermediateTensorInfo(a);\n    backend.disposeIntermediateTensorInfo(b);\n    backend.disposeIntermediateTensorInfo(sumExp);\n    backend.disposeIntermediateTensorInfo(sumReshaped);\n    return result;\n}\nvar softmaxConfig = {\n    kernelName: tfjsCore.Softmax,\n    backendName: 'cpu',\n    kernelFunc: softmax\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction multinomial(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var logits = inputs.logits;\n    var numSamples = attrs.numSamples, seed = attrs.seed, normalized = attrs.normalized;\n    assertNotComplex(logits, 'multinomial');\n    var probabilities = normalized ?\n        logits :\n        softmax({ inputs: { logits: logits }, backend: backend, attrs: { dim: -1 } });\n    var batchSize = probabilities.shape[0];\n    var numEvents = probabilities.shape[1];\n    var probVals = backend.data.get(probabilities.dataId).values;\n    var resShape = [batchSize, numSamples];\n    var resVals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(resShape), 'int32');\n    for (var b = 0; b < batchSize; ++b) {\n        var offset = b * numEvents;\n        // The cdf won't include the last event. It will be implicit if no other\n        // event happened.\n        var cdf = new Float32Array(numEvents - 1);\n        cdf[0] = probVals[offset];\n        for (var event = 1; event < cdf.length; ++event) {\n            cdf[event] = cdf[event - 1] + probVals[offset + event];\n        }\n        var random = seedrandom__namespace.alea(seed.toString());\n        var outOffset = b * numSamples;\n        for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n            var r = random();\n            // Assume last event happened by default.\n            resVals[outOffset + sampleId] = cdf.length;\n            for (var event = 0; event < cdf.length; event++) {\n                if (r < cdf[event]) {\n                    resVals[outOffset + sampleId] = event;\n                    break;\n                }\n            }\n        }\n    }\n    if (!normalized) {\n        backend.disposeIntermediateTensorInfo(probabilities);\n    }\n    return backend.makeTensorInfo(resShape, 'int32', resVals);\n}\nvar multinomialConfig = {\n    kernelName: tfjsCore.Multinomial,\n    backendName: 'cpu',\n    kernelFunc: multinomial\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar nonMaxSuppressionV3Impl = tfjsCore.kernel_impls.nonMaxSuppressionV3Impl;\nfunction nonMaxSuppressionV3(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var boxes = inputs.boxes, scores = inputs.scores;\n    var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold;\n    assertNotComplex(boxes, 'NonMaxSuppression');\n    var boxesVals = backend.data.get(boxes.dataId).values;\n    var scoresVals = backend.data.get(scores.dataId).values;\n    var selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;\n    return backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\nvar nonMaxSuppressionV3Config = {\n    kernelName: tfjsCore.NonMaxSuppressionV3,\n    backendName: 'cpu',\n    kernelFunc: nonMaxSuppressionV3\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar nonMaxSuppressionV4Impl = tfjsCore.kernel_impls.nonMaxSuppressionV4Impl;\nfunction nonMaxSuppressionV4(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var boxes = inputs.boxes, scores = inputs.scores;\n    var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, padToMaxOutputSize = attrs.padToMaxOutputSize;\n    assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n    var boxesVals = backend.data.get(boxes.dataId).values;\n    var scoresVals = backend.data.get(scores.dataId).values;\n    var _a = nonMaxSuppressionV4Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize), selectedIndices = _a.selectedIndices, validOutputs = _a.validOutputs;\n    return [\n        backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n        backend.makeTensorInfo([], 'int32', new Int32Array([validOutputs]))\n    ];\n}\nvar nonMaxSuppressionV4Config = {\n    kernelName: tfjsCore.NonMaxSuppressionV4,\n    backendName: 'cpu',\n    kernelFunc: nonMaxSuppressionV4\n};\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar nonMaxSuppressionV5Impl = tfjsCore.kernel_impls.nonMaxSuppressionV5Impl;\nfunction nonMaxSuppressionV5(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var boxes = inputs.boxes, scores = inputs.scores;\n    var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, softNmsSigma = attrs.softNmsSigma;\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n    var boxesVals = backend.data.get(boxes.dataId).values;\n    var scoresVals = backend.data.get(scores.dataId).values;\n    var maxOutputSizeVal = maxOutputSize;\n    var iouThresholdVal = iouThreshold;\n    var scoreThresholdVal = scoreThreshold;\n    var softNmsSigmaVal = softNmsSigma;\n    var _a = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal), selectedIndices = _a.selectedIndices, selectedScores = _a.selectedScores;\n    return [\n        backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n        backend.makeTensorInfo([selectedScores.length], 'float32', new Float32Array(selectedScores))\n    ];\n}\nvar nonMaxSuppressionV5Config = {\n    kernelName: tfjsCore.NonMaxSuppressionV5,\n    backendName: 'cpu',\n    kernelFunc: nonMaxSuppressionV5\n};\n\nfunction oneHot(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var indices = inputs.indices;\n    var depth = attrs.depth, onValue = attrs.onValue, offValue = attrs.offValue;\n    assertNotComplex(indices, 'oneHot');\n    var indicesSize = tfjsCore.util.sizeFromShape(indices.shape);\n    var res = new Float32Array(indicesSize * depth);\n    res.fill(offValue);\n    var indicesVal = backend.data.get(indices.dataId).values;\n    for (var event = 0; event < indicesSize; ++event) {\n        if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n            res[event * depth + indicesVal[event]] = onValue;\n        }\n    }\n    return backend.makeTensorInfo(__spread(indices.shape, [depth]), 'int32', res);\n}\nvar oneHotConfig = {\n    kernelName: tfjsCore.OneHot,\n    backendName: 'cpu',\n    kernelFunc: oneHot\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction zerosLike(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x;\n    if (x.dtype === 'string') {\n        throw new Error('zerosLike is not supported for string tensors');\n    }\n    else if (x.dtype === 'complex64') {\n        var realPart = real({ inputs: { input: x }, backend: backend });\n        var r = zerosLike({ inputs: { x: realPart }, backend: backend });\n        var imagPart = imag({ inputs: { input: x }, backend: backend });\n        var i = zerosLike({ inputs: { x: imagPart }, backend: backend });\n        var result = complex({ inputs: { real: r, imag: i }, backend: backend });\n        backend.disposeIntermediateTensorInfo(realPart);\n        backend.disposeIntermediateTensorInfo(r);\n        backend.disposeIntermediateTensorInfo(imagPart);\n        backend.disposeIntermediateTensorInfo(i);\n        return result;\n    }\n    else {\n        return fill({ backend: backend, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });\n    }\n}\nvar zerosLikeConfig = {\n    kernelName: tfjsCore.ZerosLike,\n    backendName: 'cpu',\n    kernelFunc: zerosLike\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction onesLike(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var x = inputs.x;\n    if (x.dtype === 'string') {\n        throw new Error('onesLike is not supported for string tensors');\n    }\n    else if (x.dtype === 'complex64') {\n        var realPart = real({ inputs: { input: x }, backend: backend });\n        var r = onesLike({ inputs: { x: realPart }, backend: backend });\n        var imagPart = imag({ inputs: { input: x }, backend: backend });\n        var i = zerosLike({ inputs: { x: imagPart }, backend: backend });\n        var result = complex({ inputs: { real: r, imag: i }, backend: backend });\n        backend.disposeIntermediateTensorInfo(realPart);\n        backend.disposeIntermediateTensorInfo(r);\n        backend.disposeIntermediateTensorInfo(imagPart);\n        backend.disposeIntermediateTensorInfo(i);\n        return result;\n    }\n    else {\n        return fill({ backend: backend, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });\n    }\n}\nvar onesLikeConfig = {\n    kernelName: tfjsCore.OnesLike,\n    backendName: 'cpu',\n    kernelFunc: onesLike\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction pack(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var axis = attrs.axis;\n    if (inputs.length === 1) {\n        return expandDims({ inputs: { input: inputs[0] }, backend: backend, attrs: { dim: axis } });\n    }\n    var shape = inputs[0].shape;\n    var dtype = inputs[0].dtype;\n    inputs.forEach(function (t) {\n        tfjsCore.util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n        tfjsCore.util.assert(dtype === t.dtype, function () { return 'All tensors passed to stack must have matching dtypes'; });\n    });\n    var intermediateTensorInfos = [];\n    var expandedTensors = inputs.map(function (t) {\n        var expandedT = expandDims({ inputs: { input: t }, backend: backend, attrs: { dim: axis } });\n        intermediateTensorInfos.push(expandedT);\n        return expandedT;\n    });\n    var result = concat({ inputs: expandedTensors, backend: backend, attrs: { axis: axis } });\n    intermediateTensorInfos.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return result;\n}\nvar packConfig = {\n    kernelName: tfjsCore.Pack,\n    backendName: 'cpu',\n    kernelFunc: pack\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction padV2(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var paddings = attrs.paddings, constantValue = attrs.constantValue;\n    assertNotComplex(x, 'pad');\n    var outShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + x.shape[i] + p[1]; } /* afterPad */);\n    var start = paddings.map(function (p) { return p[0]; });\n    var xVals = backend.data.get(x.dataId).values;\n    var xSize = tfjsCore.util.sizeFromShape(x.shape);\n    var xRank = x.shape.length;\n    var xStrides = tfjsCore.util.computeStrides(x.shape);\n    var resultSize = tfjsCore.util.sizeFromShape(outShape);\n    var resultRank = outShape.length;\n    var resultStrides = tfjsCore.util.computeStrides(outShape);\n    var resVals = tfjsCore.util.getTypedArrayFromDType(x.dtype, resultSize);\n    if (constantValue !== 0) {\n        resVals.fill(constantValue);\n    }\n    for (var i = 0; i < xSize; i++) {\n        var coords = tfjsCore.util.indexToLoc(i, xRank, xStrides);\n        var outCoords = coords.map(function (c, i) { return c + start[i]; });\n        var outIndex = tfjsCore.util.locToIndex(outCoords, resultRank, resultStrides);\n        resVals[outIndex] = xVals[i];\n    }\n    var outId = backend.write(resVals, outShape, x.dtype);\n    return { dataId: outId, shape: outShape, dtype: x.dtype };\n}\nvar padV2Config = {\n    kernelName: tfjsCore.PadV2,\n    backendName: 'cpu',\n    kernelFunc: padV2\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar powImpl = createSimpleBinaryKernelImpl(function (a, b) { return Math.pow(a, b); });\nvar pow = binaryKernelFunc(tfjsCore.Pow, powImpl);\nvar powConfig = {\n    kernelName: tfjsCore.Pow,\n    backendName: 'cpu',\n    kernelFunc: pow\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction range(args) {\n    var backend = args.backend, attrs = args.attrs;\n    var start = attrs.start, stop = attrs.stop, dtype = attrs.dtype, step = attrs.step;\n    var values = rangeImpl(start, stop, step, dtype);\n    return backend.makeTensorInfo([values.length], dtype, values);\n}\nvar rangeConfig = {\n    kernelName: tfjsCore.Range,\n    backendName: 'cpu',\n    kernelFunc: range\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar reciprocal = unaryKernelFunc(tfjsCore.Reciprocal, function (xi) { return 1 / xi; });\nvar reciprocalConfig = {\n    kernelName: tfjsCore.Reciprocal,\n    backendName: 'cpu',\n    kernelFunc: reciprocal,\n};\n\nfunction resizeBilinear(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var images = inputs.images;\n    var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;\n    assertNotComplex(images, 'resizeBilinear');\n    var imagesStrides = tfjsCore.util.computeStrides(images.shape);\n    var _a = __read(size, 2), newHeight = _a[0], newWidth = _a[1];\n    var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];\n    var xValues = backend.data.get(images.dataId).values;\n    var result = new Float32Array(tfjsCore.util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n    var effectiveInputSize = [\n        (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n        (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n    var effectiveOutputSize = [\n        (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n        (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    var outputIdx = 0;\n    var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n    var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n    for (var b = 0; b < batch; b++) {\n        for (var r = 0; r < newHeight; r++) {\n            var sourceFracRow = void 0;\n            if (halfPixelCenters) {\n                sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;\n            }\n            else {\n                sourceFracRow = effectiveRowSizeRatio * r;\n            }\n            var sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));\n            var rowFrac = sourceFracRow - sourceRowFloor;\n            var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n            var topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];\n            var botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];\n            for (var c = 0; c < newWidth; c++) {\n                var sourceFracCol = void 0;\n                if (halfPixelCenters) {\n                    sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;\n                }\n                else {\n                    sourceFracCol = effectiveColSizeRatio * c;\n                }\n                var sourceColFloor = Math.max(0, Math.floor(sourceFracCol));\n                var colFrac = sourceFracCol - sourceColFloor;\n                var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n                var topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];\n                var botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];\n                var topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];\n                var botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];\n                for (var d = 0; d < numChannels; d++) {\n                    // Begin shader.\n                    // Compute the fractional index of the source.\n                    var topLeft = xValues[topLeftOffest + d];\n                    var bottomLeft = xValues[botLeftOffset + d];\n                    var topRight = xValues[topRightOffset + d];\n                    var bottomRight = xValues[botRightOffest + d];\n                    var top = topLeft + (topRight - topLeft) * colFrac;\n                    var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n                    var newValue = top + (bottom - top) * rowFrac;\n                    result[outputIdx++] = newValue;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], 'float32', result);\n}\nvar resizeBilinearConfig = {\n    kernelName: tfjsCore.ResizeBilinear,\n    backendName: 'cpu',\n    kernelFunc: resizeBilinear\n};\n\nfunction resizeBilinearGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var images = inputs.images, dy = inputs.dy;\n    var alignCorners = attrs.alignCorners;\n    assertNotComplex([dy, images], 'resizeBilinearGrad');\n    var imagesStrides = tfjsCore.util.computeStrides(images.shape);\n    var _a = __read(images.shape, 4), batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n    var _b = __read(dy.shape, 3), yHeight = _b[1], yWidth = _b[2];\n    var output = new Float32Array(batch * xHeight * xWidth * depth);\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n    var effectiveXSize = [\n        (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n        (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n    var effectiveYSize = [\n        (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n        (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n    var heightScale = effectiveXSize[0] / effectiveYSize[0];\n    var widthScale = effectiveXSize[1] / effectiveYSize[1];\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n    var dyValues = backend.data.get(dy.dataId).values;\n    var offset = 0;\n    for (var b = 0; b < batch; b++) {\n        var bOffset = b * imagesStrides[0];\n        for (var r = 0; r < yHeight; r++) {\n            var dxR = r * heightScale;\n            var topDxRIndex = Math.floor(dxR);\n            var bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n            var topDxROffset = bOffset + topDxRIndex * imagesStrides[1];\n            var bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];\n            var dxRLerp = dxR - topDxRIndex;\n            var inverseDxRLerp = 1.0 - dxRLerp;\n            for (var c = 0; c < yWidth; c++) {\n                var dxC = c * widthScale;\n                var leftDxCIndex = Math.floor(dxC);\n                var rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n                var dxCLerp = dxC - leftDxCIndex;\n                var inverseDxCLerp = 1.0 - dxCLerp;\n                var topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];\n                var topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];\n                var bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];\n                var bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];\n                var inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;\n                var inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n                var dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n                var dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n                for (var d = 0; d < depth; d++) {\n                    var dyVal = dyValues[offset++];\n                    output[topLeftRCOffset + d] +=\n                        dyVal * inverseDxRLerpTimesInverseDxCLerp;\n                    output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n                    output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;\n                    output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo([batch, xWidth, xHeight, depth], 'float32', output);\n}\nvar resizeBilinearGradConfig = {\n    kernelName: tfjsCore.ResizeBilinearGrad,\n    backendName: 'cpu',\n    kernelFunc: resizeBilinearGrad\n};\n\nfunction resizeNearestNeighbor(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var images = inputs.images;\n    var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;\n    assertNotComplex(images, 'resizeNearestNeighbor');\n    var imagesStrides = tfjsCore.util.computeStrides(images.shape);\n    var _a = __read(size, 2), newHeight = _a[0], newWidth = _a[1];\n    var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];\n    var xValues = backend.data.get(images.dataId).values;\n    var output = new Float32Array(batch * newHeight * newWidth * numChannels);\n    var effectiveInputSize = [\n        (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n        (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n    var effectiveOutputSize = [\n        (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n        (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n    var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n    var outputOffset = 0;\n    for (var b = 0; b < batch; b++) {\n        var batchOffset = b * imagesStrides[0];\n        for (var r = 0; r < newHeight; r++) {\n            var sourceFracRow = halfPixelCenters ?\n                effectiveRowSizeRatio * (r + 0.5) :\n                effectiveRowSizeRatio * r;\n            var sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n            if (halfPixelCenters) {\n                sourceNearestRow = Math.max(0, sourceNearestRow);\n            }\n            var rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];\n            for (var c = 0; c < newWidth; c++) {\n                var sourceFracCol = halfPixelCenters ?\n                    effectiveColSizeRatio * (c + 0.5) :\n                    effectiveColSizeRatio * c;\n                var sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                    Math.floor(sourceFracCol));\n                if (halfPixelCenters) {\n                    sourceNearestCol = Math.max(0, sourceNearestCol);\n                }\n                var colOffset = rowOffset + sourceNearestCol * imagesStrides[2];\n                for (var d = 0; d < numChannels; d++) {\n                    // Begin shader.\n                    // Compute the fractional index of the source.\n                    var newVal = xValues[colOffset + d];\n                    output[outputOffset++] = newVal;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);\n}\nvar resizeNearestNeighborConfig = {\n    kernelName: tfjsCore.ResizeNearestNeighbor,\n    backendName: 'cpu',\n    kernelFunc: resizeNearestNeighbor\n};\n\nfunction resizeNearestNeighborGrad(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var images = inputs.images, dy = inputs.dy;\n    var alignCorners = attrs.alignCorners;\n    assertNotComplex([dy, images], 'resizeNearestNeighborGrad');\n    var imagesStrides = tfjsCore.util.computeStrides(images.shape);\n    var dyStrides = tfjsCore.util.computeStrides(dy.shape);\n    var _a = __read(images.shape, 4), batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n    var _b = __read(dy.shape, 3), yHeight = _b[1], yWidth = _b[2];\n    var output = new Float32Array(batch * xHeight * xWidth * depth);\n    var dyValues = backend.data.get(dy.dataId).values;\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n    var effectiveXSize = [\n        (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n        (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n    var effectiveYSize = [\n        (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n        (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n    var heightScale = effectiveXSize[0] / effectiveYSize[0];\n    var widthScale = effectiveXSize[1] / effectiveYSize[1];\n    var invHeightScale = 1 / heightScale;\n    var invWidthScale = 1 / widthScale;\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n    // Loop over the output space.\n    for (var b = 0; b < batch; b++) {\n        var batchOffset = b * imagesStrides[0];\n        for (var r = 0; r < xHeight; r++) {\n            var rowOffset = batchOffset + r * imagesStrides[1];\n            // Compute bounds for where in dy we will look\n            var startRLerp = Math.floor(r * invHeightScale);\n            var startDyR = Math.floor(startRLerp - (winHeight / 2));\n            for (var c = 0; c < xWidth; c++) {\n                var colOffset = rowOffset + c * imagesStrides[2];\n                // Compute bounds for where in dy we will look\n                var startCLerp = Math.floor(c * invWidthScale);\n                var startDyC = Math.floor(startCLerp - (winWidth / 2));\n                for (var d = 0; d < depth; d++) {\n                    var accum = 0;\n                    // loop over dy\n                    for (var dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n                        var dyR = dyRIndex + startDyR;\n                        // Guard against the window exceeding the bounds of dy\n                        if (dyR < 0 || dyR >= yHeight) {\n                            continue;\n                        }\n                        var dyROffset = batchOffset + dyR * dyStrides[1];\n                        var sourceFracRow = dyR * heightScale;\n                        var sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) :\n                            Math.floor(sourceFracRow));\n                        if (r !== sourceNearestRow) {\n                            continue;\n                        }\n                        for (var dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                            var dyC = dyCIndex + startDyC;\n                            // Guard against the window exceeding the bounds of dy\n                            if (dyC < 0 || dyC >= yWidth) {\n                                continue;\n                            }\n                            var dyCOffset = dyROffset + dyC * dyStrides[2];\n                            var sourceFracCol = dyC * widthScale;\n                            var sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                                Math.floor(sourceFracCol));\n                            if (c === sourceNearestCol) {\n                                accum += dyValues[dyCOffset + d];\n                            }\n                        }\n                    }\n                    output[colOffset + d] = accum;\n                }\n            }\n        }\n    }\n    return backend.makeTensorInfo(images.shape, images.dtype, output);\n}\nvar resizeNearestNeighborGradConfig = {\n    kernelName: tfjsCore.ResizeNearestNeighborGrad,\n    backendName: 'cpu',\n    kernelFunc: resizeNearestNeighborGrad\n};\n\nfunction reverse(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var dims = attrs.dims;\n    assertNotComplex(x, 'reverse');\n    var xRank = x.shape.length;\n    var $dims = tfjsCore.util.parseAxisParam(dims, x.shape);\n    if (xRank === 0) {\n        return identity({ inputs: { x: x }, backend: backend });\n    }\n    var outBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype);\n    var xBuf = backend.bufferSync(x);\n    var _loop_1 = function (i) {\n        var outLoc = outBuf.indexToLoc(i);\n        var inLoc = outLoc.slice();\n        $dims.forEach(function (d) { return inLoc[d] = x.shape[d] - 1 - inLoc[d]; });\n        outBuf.set.apply(outBuf, __spread([xBuf.get.apply(xBuf, __spread(inLoc))], outLoc));\n    };\n    for (var i = 0; i < outBuf.size; i++) {\n        _loop_1(i);\n    }\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\nvar reverseConfig = {\n    kernelName: tfjsCore.Reverse,\n    backendName: 'cpu',\n    kernelFunc: reverse\n};\n\nvar rotateWithOffsetConfig = {\n    kernelName: tfjsCore.RotateWithOffset,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, attrs = _a.attrs, backend = _a.backend;\n        var image = inputs.image;\n        var radians = attrs.radians, fillValue = attrs.fillValue, center = attrs.center;\n        var cpuBackend = backend;\n        var output = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(image.shape));\n        var _b = __read(image.shape, 4), batch = _b[0], imageHeight = _b[1], imageWidth = _b[2], numChannels = _b[3];\n        var _c = __read(tfjsCore.backend_util.getImageCenter(center, imageHeight, imageWidth), 2), centerX = _c[0], centerY = _c[1];\n        var fullOpacityValue = 255;\n        var sinFactor = Math.sin(radians);\n        var cosFactor = Math.cos(radians);\n        var imageVals = cpuBackend.data.get(image.dataId).values;\n        for (var batchIdx = 0; batchIdx < batch; batchIdx++) {\n            var batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n            for (var row = 0; row < imageHeight; row++) {\n                var rowOffset = row * (imageWidth * numChannels);\n                for (var col = 0; col < imageWidth; col++) {\n                    var colOffset = col * numChannels;\n                    for (var channel = 0; channel < numChannels; channel++) {\n                        var coords = [batch, row, col, channel];\n                        var x = coords[2];\n                        var y = coords[1];\n                        // coordX/coordY are the result of rotating and translating x/y.\n                        var coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n                        var coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n                        coordX = Math.round(coordX + centerX);\n                        coordY = Math.round(coordY + centerY);\n                        var outputValue = fillValue;\n                        if (typeof fillValue !== 'number') {\n                            if (channel === 3) {\n                                outputValue = fullOpacityValue;\n                            }\n                            else {\n                                outputValue = fillValue[channel];\n                            }\n                        }\n                        // If the coordinate position falls within the image boundaries...\n                        if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                            coordY < imageHeight) {\n                            // set the output to the image value at the coordinate position.\n                            var rotatedRowOffset = coordY * (imageWidth * numChannels);\n                            var rotatedColOffset = coordX * numChannels;\n                            var imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n                            outputValue = imageVals[imageIdx];\n                        }\n                        var outIdx = batchOffset + rowOffset + colOffset + channel;\n                        output[outIdx] = outputValue;\n                    }\n                }\n            }\n        }\n        var dataId = cpuBackend.write(output, image.shape, image.dtype);\n        return { dataId: dataId, shape: image.shape, dtype: image.dtype };\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar round = unaryKernelFunc(tfjsCore.Round, function (xi) {\n    // The algorithm is based on banker's rounding.\n    var base = Math.floor(xi);\n    if (xi - base < 0.5) {\n        return Math.floor(xi);\n    }\n    else if (xi - base > 0.5) {\n        return Math.ceil(xi);\n    }\n    else {\n        if (base % 2.0 === 0.0) {\n            return base;\n        }\n        else {\n            return base + 1.0;\n        }\n    }\n});\nvar roundConfig = {\n    kernelName: tfjsCore.Round,\n    backendName: 'cpu',\n    kernelFunc: round,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {\n    var flattenShape = [outputSize / sliceSize, sliceSize];\n    var indicesData = indices.values;\n    var updatesData = updates.values;\n    if (outputSize === 0) {\n        return tfjsCore.buffer(shape, updates.dtype);\n    }\n    var outBuf = tfjsCore.buffer(flattenShape, updates.dtype);\n    outBuf.values.fill(defaultValue);\n    for (var i = 0; i < numUpdates; i++) {\n        var index = [];\n        var flattenIndex = 0;\n        for (var j = 0; j < sliceRank; j++) {\n            var dim = indicesData[i * sliceRank + j];\n            index.push(dim);\n            flattenIndex += dim * strides[j];\n        }\n        if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n            throw new Error(\"Invalid indices: \" + index + \" does not index into \" + shape);\n        }\n        for (var k = 0; k < sliceSize; k++) {\n            if (sumDupeIndices) {\n                outBuf.values[flattenIndex * sliceSize + k] +=\n                    updatesData[i * sliceSize + k];\n            }\n            else {\n                outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n                    updatesData[0] :\n                    updatesData[i * sliceSize + k];\n            }\n        }\n    }\n    return outBuf;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction scatterNd(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var indices = inputs.indices, updates = inputs.updates;\n    var shape = attrs.shape;\n    var _a = tfjsCore.backend_util.calculateShapes(updates, indices, shape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n    var sumDupeIndices = true;\n    var indicesBuf = backend.bufferSync(indices);\n    var updatesBuf = backend.bufferSync(updates);\n    var outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0 /* defaultValue */, sumDupeIndices);\n    return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);\n}\nvar scatterNdConfig = {\n    kernelName: tfjsCore.ScatterNd,\n    backendName: 'cpu',\n    kernelFunc: scatterNd\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction select(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var condition = inputs.condition, t = inputs.t, e = inputs.e;\n    assertNotComplex([condition, t, e], 'select');\n    var conditionRank = condition.shape.length;\n    var values = backend.data.get(condition.dataId).values;\n    var tValues = backend.data.get(t.dataId).values;\n    var eValues = backend.data.get(e.dataId).values;\n    var resultDtype = tfjsCore.upcastType(t.dtype, e.dtype);\n    var newValues = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(t.shape), resultDtype);\n    var index = 0;\n    var offset = conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ?\n        1 :\n        tfjsCore.util.sizeFromShape(t.shape.slice(1));\n    for (var i = 0; i < values.length; i++) {\n        for (var j = 0; j < offset; j++) {\n            if (values[i] === 1) {\n                newValues[index++] = tValues[i];\n            }\n            else {\n                newValues[index++] = eValues[i];\n            }\n        }\n    }\n    return backend.makeTensorInfo(t.shape, resultDtype, newValues);\n}\nvar selectConfig = {\n    kernelName: tfjsCore.Select,\n    backendName: 'cpu',\n    kernelFunc: select\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar scaleAlpha = tfjsCore.backend_util.SELU_SCALEALPHA;\nvar scale = tfjsCore.backend_util.SELU_SCALE;\nvar selu = unaryKernelFunc(tfjsCore.Selu, function (xi) {\n    if (xi >= 0) {\n        return scale * xi;\n    }\n    else {\n        return scaleAlpha * (Math.exp(xi) - 1);\n    }\n});\nvar seluConfig = {\n    kernelName: tfjsCore.Selu,\n    backendName: 'cpu',\n    kernelFunc: selu,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar sign = unaryKernelFunc(tfjsCore.Sign, function (xi) {\n    if (xi < 0) {\n        return -1;\n    }\n    else if (xi > 0) {\n        return 1;\n    }\n    else {\n        return 0;\n    }\n});\nvar signConfig = {\n    kernelName: tfjsCore.Sign,\n    backendName: 'cpu',\n    kernelFunc: sign,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar sin = unaryKernelFunc(tfjsCore.Sin, function (xi) { return Math.sin(xi); });\nvar sinConfig = {\n    kernelName: tfjsCore.Sin,\n    backendName: 'cpu',\n    kernelFunc: sin,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar sinh = unaryKernelFunc(tfjsCore.Sinh, function (xi) { return Math.sinh(xi); });\nvar sinhConfig = {\n    kernelName: tfjsCore.Sinh,\n    backendName: 'cpu',\n    kernelFunc: sinh,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nvar epsilon = 1.1920928955078125e-7;\nvar threshold = Math.log(epsilon) + 2.0;\nvar softplus = unaryKernelFunc(tfjsCore.Softplus, function (xi) {\n    // Value above which exp(x) may overflow, but softplus(x) == x\n    // is within machine epsilon.\n    var tooLarge = xi > -threshold;\n    // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n    // is within machine epsilon.\n    var tooSmall = xi < threshold;\n    var expX = Math.exp(xi);\n    var result;\n    if (tooSmall) {\n        result = expX;\n    }\n    else if (tooLarge) {\n        result = xi;\n    }\n    else {\n        result = Math.log(1.0 + expX);\n    }\n    return result;\n});\nvar softplusConfig = {\n    kernelName: tfjsCore.Softplus,\n    backendName: 'cpu',\n    kernelFunc: softplus,\n};\n\nfunction spaceToBatchND(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var blockShape = attrs.blockShape, paddings = attrs.paddings;\n    assertNotComplex([x], 'spaceToBatchND');\n    var prod = tfjsCore.util.sizeFromShape(blockShape);\n    var completePaddings = [[0, 0]];\n    completePaddings.push.apply(completePaddings, __spread(paddings));\n    for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n        completePaddings.push([0, 0]);\n    }\n    var paddedX = padV2Config.kernelFunc({\n        inputs: { x: x },\n        backend: backend,\n        attrs: { paddings: completePaddings, constantValue: 0 }\n    });\n    var reshapedPaddedShape = tfjsCore.backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n    var permutedReshapedPaddedPermutation = tfjsCore.backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n    var flattenShape = tfjsCore.backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n    var reshapeInputs = { x: paddedX };\n    var reshapeAttrs = { shape: reshapedPaddedShape };\n    var paddedXReshaped = reshape({ inputs: reshapeInputs, backend: backend, attrs: reshapeAttrs });\n    var transposeInputs = { x: paddedXReshaped };\n    var transposeAttrs = { perm: permutedReshapedPaddedPermutation };\n    var paddedXT = transpose({ inputs: transposeInputs, backend: backend, attrs: transposeAttrs });\n    var resultReshapeInputs = { x: paddedXT };\n    var resultReshapeAttrs = { shape: flattenShape };\n    var result = reshape({ inputs: resultReshapeInputs, backend: backend, attrs: resultReshapeAttrs });\n    backend.disposeIntermediateTensorInfo(paddedX);\n    backend.disposeIntermediateTensorInfo(paddedXReshaped);\n    backend.disposeIntermediateTensorInfo(paddedXT);\n    return result;\n}\nvar spaceToBatchNDConfig = {\n    kernelName: tfjsCore.SpaceToBatchND,\n    backendName: 'cpu',\n    kernelFunc: spaceToBatchND\n};\n\nfunction sparseFillEmptyRows(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var indices = inputs.indices, values = inputs.values, denseShape = inputs.denseShape, defaultValue = inputs.defaultValue;\n    if (denseShape.shape.length !== 1) {\n        throw new Error(\"Dense shape must be a vector, saw:\\n        \" + denseShape.shape);\n    }\n    if (indices.shape.length !== 2) {\n        throw new Error(\"Indices must be a matrix, saw:\\n        \" + indices.shape);\n    }\n    if (values.shape.length !== 1) {\n        throw new Error(\"Values must be a vector, saw:\\n        \" + values.shape);\n    }\n    if (defaultValue.shape.length !== 0) {\n        throw new Error(\"Default value must be a scalar, saw:\\n        \" + defaultValue.shape);\n    }\n    var $indices = backend.data.get(indices.dataId).values;\n    var $values = backend.data.get(values.dataId).values;\n    var $denseShape = backend.data.get(denseShape.dataId).values;\n    var $defaultValue = backend.data.get(defaultValue.dataId).values[0];\n    var _a = __read(sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue), 5), outputIndices = _a[0], outputIndicesShape = _a[1], outputValues = _a[2], emptyRowIndicator = _a[3], reverseIndexMap = _a[4];\n    return [\n        backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),\n        backend.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),\n        backend.makeTensorInfo([emptyRowIndicator.length], 'bool', new Uint8Array(emptyRowIndicator.map(function (value) { return Number(value); }))),\n        backend.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap)),\n    ];\n}\nvar sparseFillEmptyRowsConfig = {\n    kernelName: tfjsCore.SparseFillEmptyRows,\n    backendName: 'cpu',\n    kernelFunc: sparseFillEmptyRows,\n};\n\nfunction sparseReshape(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var inputIndices = inputs.inputIndices, inputShape = inputs.inputShape, newShape = inputs.newShape;\n    if (inputIndices.shape.length !== 2) {\n        throw new Error(\"Input indices should be a matrix but received shape\\n        \" + inputIndices.shape);\n    }\n    if (inputShape.shape.length !== 1) {\n        throw new Error(\"Input shape should be a vector but received shape\\n        \" + inputShape.shape);\n    }\n    if (newShape.shape.length !== 1) {\n        throw new Error(\"Target shape should be a vector but received shape \" + newShape.shape);\n    }\n    var $inputShape = Array.from(backend.data.get(inputShape.dataId).values);\n    var $inputIndices = backend.data.get(inputIndices.dataId).values;\n    var targetShape = Array.from(backend.data.get(newShape.dataId).values);\n    var _a = __read(sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape), 3), newIndices = _a[0], indicesShape = _a[1], outputShape = _a[2];\n    return [\n        backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),\n        backend.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape)),\n    ];\n}\nvar sparseReshapeConfig = {\n    kernelName: tfjsCore.SparseReshape,\n    backendName: 'cpu',\n    kernelFunc: sparseReshape,\n};\n\nfunction sparseSegmentMean(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;\n    if (data.shape.length < 1) {\n        throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    }\n    if (indices.shape.length !== 1) {\n        throw new Error(\"Indices should be a vector but received shape\\n          \" + indices.shape);\n    }\n    if (segmentIds.shape.length !== 1) {\n        throw new Error(\"Segment ids should be a vector but received shape\\n          \" + segmentIds.shape);\n    }\n    if (indices.shape[0] !== segmentIds.shape[0]) {\n        throw new Error(\"segmentIds and indices should have same size.\");\n    }\n    var $data = backend.data.get(data.dataId).values;\n    var $indices = backend.data.get(indices.dataId).values;\n    var $segmentIds = backend.data.get(segmentIds.dataId).values;\n    var _a = __read(sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true), 2), outputData = _a[0], outputDataShape = _a[1];\n    return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\nvar sparseSegmentMeanConfig = {\n    kernelName: tfjsCore.SparseSegmentMean,\n    backendName: 'cpu',\n    kernelFunc: sparseSegmentMean,\n};\n\nfunction sparseSegmentSum(args) {\n    var inputs = args.inputs, backend = args.backend;\n    var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;\n    if (data.shape.length < 1) {\n        throw new Error(\"Data should be at least 1 dimensional but received scalar\");\n    }\n    if (indices.shape.length !== 1) {\n        throw new Error(\"Indices should be a vector but received shape\\n         \" + indices.shape);\n    }\n    if (segmentIds.shape.length !== 1) {\n        throw new Error(\"Segment ids should be a vector but received shape\\n         \" + segmentIds.shape);\n    }\n    if (indices.shape[0] !== segmentIds.shape[0]) {\n        throw new Error(\"segmentIds and indices should have same size.\");\n    }\n    var $data = backend.data.get(data.dataId).values;\n    var $indices = backend.data.get(indices.dataId).values;\n    var $segmentIds = backend.data.get(segmentIds.dataId).values;\n    var _a = __read(sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds), 2), outputData = _a[0], outputDataShape = _a[1];\n    return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\nvar sparseSegmentSumConfig = {\n    kernelName: tfjsCore.SparseSegmentSum,\n    backendName: 'cpu',\n    kernelFunc: sparseSegmentSum,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction sparseToDense(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var sparseIndices = inputs.sparseIndices, sparseValues = inputs.sparseValues, defaultValue = inputs.defaultValue;\n    var outputShape = attrs.outputShape;\n    var _a = tfjsCore.backend_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n    var sumDupeIndices = false;\n    var indicesBuf = backend.bufferSync(sparseIndices);\n    var updatesBuf = backend.bufferSync(sparseValues);\n    var $defaultValue = backend.data.get(defaultValue.dataId).values[0];\n    var outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n    return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n}\nvar sparseToDenseConfig = {\n    kernelName: tfjsCore.SparseToDense,\n    backendName: 'cpu',\n    kernelFunc: sparseToDense\n};\n\nfunction splitV(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var numOrSizeSplits = attrs.numOrSizeSplits, axis = attrs.axis;\n    var $axis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];\n    var splitSizes = tfjsCore.backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n    var begin = new Array(x.shape.length).fill(0);\n    var size = x.shape.slice();\n    return splitSizes.map(function (s) {\n        var sliceSize = __spread(size);\n        sliceSize[$axis] = s;\n        var sliceT = slice({ inputs: { x: x }, backend: backend, attrs: { begin: begin, size: sliceSize } });\n        begin[$axis] += s;\n        return sliceT;\n    });\n}\nvar splitVConfig = {\n    kernelName: tfjsCore.SplitV,\n    backendName: 'cpu',\n    kernelFunc: splitV\n};\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar squareConfig = {\n    kernelName: tfjsCore.Square,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var x = inputs.x;\n        var cpuBackend = backend;\n        assertNotComplex(x, 'square');\n        var values = cpuBackend.data.get(x.dataId).values;\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = value * value;\n        }\n        var dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n        return { dataId: dataId, shape: x.shape, dtype: x.dtype };\n    }\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar step = unaryKernelFunc(tfjsCore.Step, function (xi, attrs) {\n    var stepAttrs = attrs;\n    if (isNaN(xi)) {\n        return NaN;\n    }\n    else {\n        return xi > 0 ? 1 : stepAttrs.alpha;\n    }\n});\nvar stepConfig = {\n    kernelName: tfjsCore.Step,\n    backendName: 'cpu',\n    kernelFunc: step,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction stridedSlice(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var begin = attrs.begin, end = attrs.end, strides = attrs.strides, beginMask = attrs.beginMask, endMask = attrs.endMask, ellipsisMask = attrs.ellipsisMask, newAxisMask = attrs.newAxisMask, shrinkAxisMask = attrs.shrinkAxisMask;\n    assertNotComplex(x, 'stridedSlice');\n    var _a = tfjsCore.slice_util.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), finalShapeSparse = _a.finalShapeSparse, finalShape = _a.finalShape, isIdentity = _a.isIdentity, sliceDim0 = _a.sliceDim0, isSimpleSlice = _a.isSimpleSlice, $begin = _a.begin, $end = _a.end, $strides = _a.strides;\n    var result;\n    // ref:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/strided_slice_op.cc\n    if (isIdentity) {\n        // Optimization #1, slice is a no-op plus reshape\n        result = reshape({ inputs: { x: x }, backend: backend, attrs: { shape: finalShape } });\n    }\n    else if (sliceDim0 || isSimpleSlice) {\n        // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n        tfjsCore.util.assert(x.shape.length >= 1, function () { return \"Input must have rank at least 1, got: \" + x.shape.length; });\n        var size = tfjsCore.slice_util.computeOutShape($begin, $end, $strides);\n        // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n        var sliced = slice({ inputs: { x: x }, backend: backend, attrs: { begin: $begin, size: size } });\n        result =\n            reshape({ inputs: { x: sliced }, backend: backend, attrs: { shape: finalShape } });\n        backend.disposeIntermediateTensorInfo(sliced);\n    }\n    else {\n        var xBuf = backend.bufferSync(x);\n        var outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);\n        result = backend.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);\n    }\n    return result;\n}\nvar stridedSliceConfig = {\n    kernelName: tfjsCore.StridedSlice,\n    backendName: 'cpu',\n    kernelFunc: stridedSlice\n};\n\nfunction stringNGrams(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var separator = attrs.separator, nGramWidths = attrs.nGramWidths, leftPad = attrs.leftPad, rightPad = attrs.rightPad, padWidth = attrs.padWidth, preserveShortSequences = attrs.preserveShortSequences;\n    var data = inputs.data, dataSplits = inputs.dataSplits;\n    var $data = backend.data.get(data.dataId).values;\n    var $dataSplits = backend.data.get(dataSplits.dataId).values;\n    var _a = __read(stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences), 2), nGrams = _a[0], nGramsSplits = _a[1];\n    return [\n        backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n        backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n    ];\n}\nvar stringNGramsConfig = {\n    kernelName: tfjsCore.StringNGrams,\n    backendName: 'cpu',\n    kernelFunc: stringNGrams,\n};\n\nfunction stringSplit(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var skipEmpty = attrs.skipEmpty;\n    var input = inputs.input, delimiter = inputs.delimiter;\n    if (input.dtype !== 'string') {\n        throw new Error('Input must be of datatype string');\n    }\n    if (input.shape.length !== 1) {\n        throw new Error(\"Input must be a vector, got shape: \" + input.shape);\n    }\n    if (delimiter.shape.length !== 0) {\n        throw new Error(\"Delimiter must be a scalar, got shape: \" + delimiter.shape);\n    }\n    var $input = backend.data.get(input.dataId).values;\n    var $delimiter = backend.data.get(delimiter.dataId).values[0];\n    var _a = __read(stringSplitImpl($input, $delimiter, skipEmpty), 3), indices = _a[0], values = _a[1], shape = _a[2];\n    var outputSize = values.length;\n    return [\n        backend.makeTensorInfo([outputSize, 2], 'int32', indices),\n        backend.makeTensorInfo([outputSize], 'string', values),\n        backend.makeTensorInfo([2], 'int32', new Int32Array(shape))\n    ];\n}\nvar stringSplitConfig = {\n    kernelName: tfjsCore.StringSplit,\n    backendName: 'cpu',\n    kernelFunc: stringSplit,\n};\n\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction stringToHashBucketFast(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var numBuckets = attrs.numBuckets;\n    var input = inputs.input;\n    if (input.dtype !== 'string') {\n        throw new Error('Input must be of datatype string');\n    }\n    if (numBuckets <= 0) {\n        throw new Error(\"Number of buckets must be at least 1\");\n    }\n    var $input = backend.data.get(input.dataId).values;\n    var output = stringToHashBucketFastImpl($input, numBuckets);\n    return backend.makeTensorInfo(input.shape, 'int32', output);\n}\nvar stringToHashBucketFastConfig = {\n    kernelName: tfjsCore.StringToHashBucketFast,\n    backendName: 'cpu',\n    kernelFunc: stringToHashBucketFast,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar tan = unaryKernelFunc(tfjsCore.Tan, function (xi) { return Math.tan(xi); });\nvar tanConfig = {\n    kernelName: tfjsCore.Tan,\n    backendName: 'cpu',\n    kernelFunc: tan,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar tanh = unaryKernelFunc(tfjsCore.Tanh, function (xi) { return Math.tanh(xi); });\nvar tanhConfig = {\n    kernelName: tfjsCore.Tanh,\n    backendName: 'cpu',\n    kernelFunc: tanh,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction tile(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var reps = attrs.reps;\n    assertNotComplex(x, 'tile');\n    var outBuf = tileImpl(backend.bufferSync(x), reps);\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\nvar tileConfig = {\n    kernelName: tfjsCore.Tile,\n    backendName: 'cpu',\n    kernelFunc: tile\n};\n\nfunction topK(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x;\n    var k = attrs.k, sorted = attrs.sorted;\n    assertNotComplex(x, 'topk');\n    var xVals = backend.data.get(x.dataId).values;\n    var _a = __read(topKImpl(xVals, x.shape, x.dtype, k, sorted), 2), allTopKVals = _a[0], allTopKIndices = _a[1];\n    return [\n        backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n        backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n    ];\n}\nvar topKConfig = {\n    kernelName: tfjsCore.TopK,\n    backendName: 'cpu',\n    kernelFunc: topK\n};\n\nfunction transform(args) {\n    var inputs = args.inputs, attrs = args.attrs, backend = args.backend;\n    var image = inputs.image, transforms = inputs.transforms;\n    var interpolation = attrs.interpolation, fillMode = attrs.fillMode, fillValue = attrs.fillValue, outputShape = attrs.outputShape;\n    var _a = __read(image.shape, 4), batch = _a[0], imageHeight = _a[1], imageWidth = _a[2], numChannels = _a[3];\n    var _b = __read(outputShape != null ? outputShape : [imageHeight, imageWidth], 2), outHeight = _b[0], outWidth = _b[1];\n    var outShape = [batch, outHeight, outWidth, numChannels];\n    var strides = tfjsCore.util.computeStrides(image.shape);\n    var batchStride = strides[0];\n    var rowStride = strides[1];\n    var colStride = strides[2];\n    var outVals = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(outShape));\n    outVals.fill(fillValue);\n    var imageVals = backend.data.get(image.dataId).values;\n    var transformVals = backend.data.get(transforms.dataId).values;\n    // Ref TF implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/image_ops.h\n    for (var b = 0; b < batch; ++b) {\n        var transform_1 = transforms.shape[0] === 1 ?\n            transformVals :\n            transformVals.subarray(b * 8, b * 8 + 8);\n        for (var outY = 0; outY < outHeight; ++outY) {\n            for (var outX = 0; outX < outWidth; ++outX) {\n                for (var channel = 0; channel < numChannels; ++channel) {\n                    var val = void 0;\n                    var projection = transform_1[6] * outX + transform_1[7] * outY + 1;\n                    if (projection === 0) {\n                        // Return the fill value for infinite coordinates,\n                        // which are outside the input image\n                        continue;\n                    }\n                    var inX = (transform_1[0] * outX + transform_1[1] * outY + transform_1[2]) /\n                        projection;\n                    var inY = (transform_1[3] * outX + transform_1[4] * outY + transform_1[5]) /\n                        projection;\n                    var x = mapCoord(inX, imageWidth, fillMode);\n                    var y = mapCoord(inY, imageHeight, fillMode);\n                    switch (interpolation) {\n                        case 'nearest':\n                            val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);\n                            break;\n                        case 'bilinear':\n                            val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);\n                            break;\n                        default:\n                            throw new Error(\"Error in Transform: Expect 'nearest' or \" +\n                                (\"'bilinear', but got \" + interpolation));\n                    }\n                    var ind = b * batchStride + outY * rowStride + outX * colStride + channel;\n                    outVals[ind] = val;\n                }\n            }\n        }\n        return backend.makeTensorInfo(outShape, image.dtype, outVals);\n    }\n    var dataId = backend.write(outVals, outShape, image.dtype);\n    return { dataId: dataId, shape: image.shape, dtype: image.dtype };\n}\nvar transformConfig = {\n    kernelName: tfjsCore.Transform,\n    backendName: 'cpu',\n    kernelFunc: transform\n};\nfunction mapCoord(outCoord, len, mode) {\n    switch (mode) {\n        case 'reflect':\n            return mapCoordReflect(outCoord, len);\n        case 'wrap':\n            return mapCoordWrap(outCoord, len);\n        case 'nearest':\n            return mapCoordNearest(outCoord, len);\n        case 'constant':\n        default:\n            return mapCoordConstant(outCoord);\n    }\n}\nfunction mapCoordReflect(outCoord, len) {\n    // Reflect [abcd] to [dcba|abcd|dcba].\n    var inCoord = outCoord;\n    if (inCoord < 0) {\n        if (len <= 1) {\n            inCoord = 0;\n        }\n        else {\n            var sz2 = 2 * len;\n            if (inCoord < sz2) {\n                inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;\n            }\n            inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;\n        }\n    }\n    else if (inCoord > len - 1) {\n        if (len <= 1) {\n            inCoord = 0;\n        }\n        else {\n            var sz2 = 2 * len;\n            inCoord -= sz2 * Math.trunc(inCoord / sz2);\n            if (inCoord >= len) {\n                inCoord = sz2 - inCoord - 1;\n            }\n        }\n    }\n    // clamp is necessary because when outCoord = 3.5 and len = 4,\n    // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n    return tfjsCore.util.clamp(0, inCoord, len - 1);\n}\nfunction mapCoordWrap(outCoord, len) {\n    // Wrap [abcd] to [abcd|abcd|abcd].\n    var inCoord = outCoord;\n    if (inCoord < 0) {\n        if (len <= 1) {\n            inCoord = 0;\n        }\n        else {\n            var sz = len - 1;\n            inCoord += len * (Math.trunc(-inCoord / sz) + 1);\n        }\n    }\n    else if (inCoord > len - 1) {\n        if (len <= 1) {\n            inCoord = 0;\n        }\n        else {\n            var sz = len - 1;\n            inCoord -= len * Math.trunc(inCoord / sz);\n        }\n    }\n    // clamp is necessary because when outCoord = -0.5 and len = 4,\n    // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n    return tfjsCore.util.clamp(0, inCoord, len - 1);\n}\nfunction mapCoordConstant(outCoord, len) {\n    return outCoord;\n}\nfunction mapCoordNearest(outCoord, len) {\n    return tfjsCore.util.clamp(0, outCoord, len - 1);\n}\nfunction readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {\n    var ind = batch * batchStride + y * rowStride + x * colStride + channel;\n    if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {\n        return imageVals[ind];\n    }\n    else {\n        return fillValue;\n    }\n}\nfunction nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {\n    var $y = Math.round(y);\n    var $x = Math.round(x);\n    return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);\n}\nfunction bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {\n    var yFloor = Math.floor(y);\n    var xFloor = Math.floor(x);\n    var yCeil = yFloor + 1;\n    var xCeil = xFloor + 1;\n    // f(x, yFloor) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yFloor)\n    //               + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yFloor)\n    var valueYFloor = (xCeil - x) *\n        readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) +\n        (x - xFloor) *\n            readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);\n    // f(x, yCeil) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yCeil)\n    //             + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yCeil)\n    var valueYCeil = (xCeil - x) *\n        readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) +\n        (x - xFloor) *\n            readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);\n    // f(x, y) = (yCeil - y) / (yCeil - yFloor) * f(x, yFloor)\n    //         + (y - yFloor) / (yCeil - yFloor) * f(x, yCeil)\n    return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;\n}\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction unique(args) {\n    var inputs = args.inputs, attrs = args.attrs, backend = args.backend;\n    var axis = attrs.axis;\n    var x = inputs.x;\n    assertNotComplex(x, 'unique');\n    var values = backend.data.get(x.dataId).values;\n    var _a = uniqueImpl(values, axis, x.shape, x.dtype), outputValues = _a.outputValues, outputShape = _a.outputShape, indices = _a.indices;\n    return [\n        backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n        backend.makeTensorInfo([indices.length], 'int32', indices),\n    ];\n}\nvar uniqueConfig = {\n    kernelName: tfjsCore.Unique,\n    backendName: 'cpu',\n    kernelFunc: unique,\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction unpack(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var value = inputs.value;\n    var axis = attrs.axis;\n    if (axis < 0) {\n        axis += value.shape.length;\n    }\n    var valueRank = value.shape.length;\n    var num = value.shape[axis];\n    var outShape = new Array(valueRank - 1);\n    var outIndex = 0;\n    for (var i = 0; i < valueRank; i++) {\n        if (i !== axis) {\n            outShape[outIndex++] = value.shape[i];\n        }\n    }\n    var begin = new Array(valueRank).fill(0);\n    var size = value.shape.slice();\n    size[axis] = 1;\n    var res = new Array(num);\n    for (var i = 0; i < res.length; i++) {\n        begin[axis] = i;\n        var tempRes = slice({ inputs: { x: value }, backend: backend, attrs: { begin: begin, size: size } });\n        res[i] = reshape({ inputs: { x: tempRes }, backend: backend, attrs: { shape: outShape } });\n        backend.disposeIntermediateTensorInfo(tempRes);\n    }\n    return res;\n}\nvar unpackConfig = {\n    kernelName: tfjsCore.Unpack,\n    backendName: 'cpu',\n    kernelFunc: unpack\n};\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction unsortedSegmentSum(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var x = inputs.x, segmentIds = inputs.segmentIds;\n    var numSegments = attrs.numSegments;\n    assertNotComplex(x, 'unsortedSegmentSum');\n    var xRank = x.shape.length;\n    var segmentIdsRank = segmentIds.shape.length;\n    var res = [];\n    var intermediates = [];\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    var numIters = xRank - segmentIdsRank;\n    var $segmentIds = segmentIds;\n    for (var i = 0; i < numIters; ++i) {\n        var expanded = expandDims({ inputs: { input: $segmentIds }, backend: backend, attrs: { dim: i + 1 } });\n        $segmentIds = expanded;\n        intermediates.push(expanded);\n    }\n    for (var i = 0; i < numSegments; ++i) {\n        var scalarValue = tfjsCore.util.createScalarValue(i, 'int32');\n        var segmentId = backend.makeTensorInfo([], 'int32', scalarValue);\n        var mask = equal({ inputs: { a: segmentId, b: $segmentIds }, backend: backend });\n        var maskCasted = cast({ inputs: { x: mask }, backend: backend, attrs: { dtype: 'float32' } });\n        var mul = multiply({ inputs: { a: maskCasted, b: x }, backend: backend });\n        var sumTensorInfo = sum({ inputs: { x: mul }, backend: backend, attrs: { axis: 0, keepDims: false } });\n        res.push(sumTensorInfo);\n        intermediates.push(segmentId);\n        intermediates.push(mask);\n        intermediates.push(maskCasted);\n        intermediates.push(mul);\n        intermediates.push(sumTensorInfo);\n    }\n    var result = pack({ inputs: res, backend: backend, attrs: { axis: 0 } });\n    intermediates.forEach(function (t) { return backend.disposeIntermediateTensorInfo(t); });\n    return result;\n}\nvar unsortedSegmentSumConfig = {\n    kernelName: tfjsCore.UnsortedSegmentSum,\n    backendName: 'cpu',\n    kernelFunc: unsortedSegmentSum\n};\n\nvar e_1, _a;\n// List all kernel configs here\nvar kernelConfigs = [\n    _fusedMatMulConfig,\n    absConfig,\n    acosConfig,\n    acoshConfig,\n    addConfig,\n    addNConfig,\n    allConfig,\n    anyConfig,\n    argMaxConfig,\n    argMinConfig,\n    asinConfig,\n    asinhConfig,\n    atanConfig,\n    atan2Config,\n    atanhConfig,\n    avgPoolConfig,\n    avgPool3DConfig,\n    avgPool3DGradConfig,\n    avgPoolGradConfig,\n    batchMatMulConfig,\n    batchNormConfig,\n    batchToSpaceNDConfig,\n    bincountConfig,\n    broadcastArgsConfig,\n    castConfig,\n    ceilConfig,\n    clipByValueConfig,\n    complexConfig,\n    complexAbsConfig,\n    concatConfig,\n    conv2DConfig,\n    conv2DBackpropFilterConfig,\n    conv2DBackpropInputConfig,\n    conv3DConfig,\n    conv3DBackpropFilterV2Config,\n    conv3DBackpropInputV2Config,\n    cosConfig,\n    coshConfig,\n    cropAndResizeConfig,\n    cumprodConfig,\n    cumsumConfig,\n    denseBincountConfig,\n    depthToSpaceConfig,\n    depthwiseConv2dNativeConfig,\n    depthwiseConv2dNativeBackpropFilterConfig,\n    depthwiseConv2dNativeBackpropInputConfig,\n    diagConfig,\n    dilation2DConfig,\n    dilation2DBackpropFilterConfig,\n    dilation2DBackpropInputConfig,\n    einsumConfig,\n    eluConfig,\n    eluGradConfig,\n    equalConfig,\n    erfConfig,\n    expConfig,\n    expandDimsConfig,\n    expm1Config,\n    fftConfig,\n    fillConfig,\n    flipLeftRightConfig,\n    floorConfig,\n    floorDivConfig,\n    fusedConv2DConfig,\n    fusedDepthwiseConv2DConfig,\n    gatherNdConfig,\n    gatherV2Config,\n    greaterConfig,\n    greaterEqualConfig,\n    identityConfig,\n    ifftConfig,\n    imagConfig,\n    isFiniteConfig,\n    isInfConfig,\n    isNaNConfig,\n    leakyReluConfig,\n    lessConfig,\n    lessEqualConfig,\n    linSpaceConfig,\n    logConfig,\n    log1pConfig,\n    logicalAndConfig,\n    logicalNotConfig,\n    logicalOrConfig,\n    LRNConfig,\n    LRNGradConfig,\n    maxConfig,\n    maximumConfig,\n    maxPoolConfig,\n    maxPool3DConfig,\n    maxPool3DGradConfig,\n    maxPoolGradConfig,\n    maxPoolWithArgmaxConfig,\n    meanConfig,\n    minConfig,\n    minimumConfig,\n    mirrorPadConfig,\n    modConfig,\n    multinomialConfig,\n    multiplyConfig,\n    negConfig,\n    nonMaxSuppressionV3Config,\n    nonMaxSuppressionV4Config,\n    nonMaxSuppressionV5Config,\n    notEqualConfig,\n    oneHotConfig,\n    onesLikeConfig,\n    packConfig,\n    padV2Config,\n    powConfig,\n    preluConfig,\n    prodConfig,\n    rangeConfig,\n    realConfig,\n    realDivConfig,\n    reciprocalConfig,\n    reluConfig,\n    relu6Config,\n    reshapeConfig,\n    resizeBilinearConfig,\n    resizeBilinearGradConfig,\n    resizeNearestNeighborConfig,\n    resizeNearestNeighborGradConfig,\n    reverseConfig,\n    rotateWithOffsetConfig,\n    roundConfig,\n    rsqrtConfig,\n    scatterNdConfig,\n    selectConfig,\n    seluConfig,\n    sigmoidConfig,\n    signConfig,\n    sinConfig,\n    sinhConfig,\n    sliceConfig,\n    softmaxConfig,\n    softplusConfig,\n    spaceToBatchNDConfig,\n    sparseFillEmptyRowsConfig,\n    sparseReshapeConfig,\n    sparseSegmentMeanConfig,\n    sparseSegmentSumConfig,\n    sparseToDenseConfig,\n    splitVConfig,\n    sqrtConfig,\n    squareConfig,\n    squaredDifferenceConfig,\n    stepConfig,\n    stridedSliceConfig,\n    stringNGramsConfig,\n    stringSplitConfig,\n    stringToHashBucketFastConfig,\n    subConfig,\n    sumConfig,\n    tanConfig,\n    tanhConfig,\n    tileConfig,\n    topKConfig,\n    transformConfig,\n    transposeConfig,\n    uniqueConfig,\n    unpackConfig,\n    unsortedSegmentSumConfig,\n    zerosLikeConfig\n];\ntry {\n    for (var kernelConfigs_1 = __values(kernelConfigs), kernelConfigs_1_1 = kernelConfigs_1.next(); !kernelConfigs_1_1.done; kernelConfigs_1_1 = kernelConfigs_1.next()) {\n        var kernelConfig = kernelConfigs_1_1.value;\n        tfjsCore.registerKernel(kernelConfig);\n    }\n}\ncatch (e_1_1) { e_1 = { error: e_1_1 }; }\nfinally {\n    try {\n        if (kernelConfigs_1_1 && !kernelConfigs_1_1.done && (_a = kernelConfigs_1.return)) _a.call(kernelConfigs_1);\n    }\n    finally { if (e_1) throw e_1.error; }\n}\n\nexports.MathBackendCPU = MathBackendCPU;\nexports.shared = shared;\nexports.version_cpu = version;\n//# sourceMappingURL=tf-backend-cpu.node.js.map\n"]}